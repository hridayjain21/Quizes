### SummaryThe presented video transcript dives deep into the world of microservices development using Spring Boot, emphasizing the significance of transitioning from monolithic applications to a microservices architecture. It begins with an overview of the course, which aims to provide a hands-on learning experience for building, deploying, and managing microservices using Spring Boot. The content encompasses a wide range of topics, from building a traditional application to converting it into microservices, incorporating essential tools and concepts such as Spring Data JPA, API gateways, service registries, and distributed tracing.The video details the functioning and implementation of Service Registries in microservices, likening them to a "phone book" that aids dynamic service discovery. It highlights the inherent problems of inter-service communication via hardcoded URLs, advocating for the advantages of using a Service Registry to facilitate dynamic discovery, load balancing, fault tolerance, resilience, scalability, and service health monitoring.The instructor walks through creating a microservices architecture from scratch utilizing Spring Cloud Netflix Eureka for the Service Registry, showcasing step-by-step implementations that allow for service registration and discovery. Additionally, it addresses system failures and how service registries automatically deregister down services to maintain efficient communication.The guide also explores API management through API gateways, circuit breaking, integration with Docker and Kubernetes, and the fundamental principles of distributed tracing using Zipkin. Throughout the video, viewers are encouraged to interact, ask questions, and engage in hands-on exercises for deeper understanding, establishing a community of learners sharing valuable insights and knowledge about Spring Boot and microservices.### Highlights- üì¶ **Introduction to Microservices**: The transformation from monolithic applications to microservices is introduced, setting the stage for a hands-on learning experience.- üîç **Service Registry Purpose**: Service registries help avoid hardcoded URLs, facilitating dynamic service discovery and communication between microservices.- ‚öôÔ∏è **Hands-On Implementation**: Step-by-step demonstration on setting up a Service Registry with Spring Cloud Netflix Eureka.- üö¶ **Automated Service Health Monitoring**: The system self-updates based on service availability, ensuring constant communication integrity without manual intervention.- üõ†Ô∏è **Advanced Concepts**: Incorporation of API gateways, circuit breaking, and handling failure scenarios to build resilient microservices architecture.- üìä **Distributed Tracing with Zipkin**: Key takeaways on monitoring microservice interactions and performance optimization through distributed tracing tools.- üë©‚Äçüéì **Engagement and Community Learning**: The importance of learner engagement is emphasized, encouraging viewers to interact and seek clarification on complex topics throughout the course.### Key Insights- üîë **Dynamic Service Discovery**: Utilizing a Service Registry promotes dynamic service discovery at runtime, eliminating the complications of hardcoded service endpoints. This flexibility is crucial in environments where service instances frequently change.  - ‚öñÔ∏è **Load Balancing Capabilities**: Service Registries imbue load-balancing functions, ensuring that incoming requests are equitably distributed across multiple service instances. This functionality is vital for optimizing resource usage during peak loads.- üîí **Fault Tolerance and Resilience**: Should a service instance become unavailable, an effective Service Registry detects the failure and communicates this to other services, enhancing the fault tolerance of the overall architecture. This mechanism prevents cascading failures within the microservices ecosystem.  - üìä **Scalability and Elasticity**: As the deployment of microservices grows, the complexity of managing service interactions increases. A centralized Service Registry simplifies this process, allowing systems to scale dynamically based on traffic demands.  - üö¶ **Service Monitoring and Health Checks**: Integrating service health monitoring within the Registry provides crucial insights into system performance, allowing for timely interventions and maintenance scheduling which eventually promotes system integrity.  - üåê **Distributed Tracing**: Through tools like Zipkin, developers can visualize request flows across microservices, enabling the identification of performance bottlenecks and latency issues which are essential for troubleshooting and optimizing service efficiency.  - üß© **Community Engagement**: The video promotes interaction among learners, suggesting a community approach to solving technical challenges, enhancing the overall learning experience, and fostering collaboration.### ConclusionEmbarking on the journey of understanding microservices with Spring Boot requires practical engagement with the subject. This video serves as a comprehensive guide, bridging the gap between theoretical knowledge and practical application. As one delves into topics such as Service Registries, distributed tracing, and the overall architecture of microservices, it becomes evident how these components work harmoniously to create resilient, scalable, and manageable applications. Adopting the insights and practices discussed can significantly enhance one's ability to navigate the complexities inherent in microservice architectures, fostering both personal and professional growth in software development.














    00:00
    are you ready to embark on a transformative journey into the world of microservices with spring boot so this is a complete master class that covers everything you need to know about microservices and spring boot so in this particular course we will first learn how we can build a traditional monolithic application and then we will convert that same application into microservices we will first begin with the very basics of spring boot where we will set up things and we will dive into the magic of spring boot then we will

    
    00:38
    move Beyond Basics where we will create a couple of projects using spring Boot and then when building a monolithic application we will learn about things like jpa spring boot actuator and tools like Postman we will then understand what microservices are and we will begin converting the application that we have built into a microservice now when building microservices we will learn about Concepts like service registry distributed tracing Zipkin rabbit mq in a Hands-On way we will also cover topics

    
    01:14
    such as API gateways fall tolerance circuit breaking using rabbit mq this course will also cover things like packaging your microservices containerization using Docker and kubernetes well this Cod course has hours and hours of content that is really really valuable and will bring in a very comprehensive learning for you all and this course is the ultimate road map to master spring boot microservices so this is going to be a complete Hands-On session where we will be actually doing things in a Hands-On way

    
    01:53
    practically now if you have been watching my videos and if you haven't liked or subscribed yet I would highly highly recommend doing so because every subscriber or every subscription that I get on my channel motivates me to bring in more such amazing content for you all the support and love that I get from my viewers impacts my ability to bring in more such amazing free content for you all so I would highly recommend that you hit the Subscribe button like this particular video and turn on the Bell

    
    02:29
    notification also feel free to leave a comment to let me know what kind of videos I should bring for you all now without a further Ado let's jump right into the session hey there welcome to this class so let us start talking about this concept of service registry and why do we need it in our microservices architecture so first let's start talking about what is a service registry so a service registry is used in a microservices architecture to enable Dynamic service Discovery now in microservices interservice communication

    
    03:20
    is really important and for interservice communication we have hardcoded URLs that we can use so you can hardcode the urls and you can use those URLs to communicate with other services but this is not a good practice now this can be cumbersome error prone and this is not a good way of talking to another service so this is another approach which is with the help of service registry so what happens in case of service registry is you have a service registry which looks something like this and you have

    
    03:59
    other microservices like this over here so you have company job and review service for example and you have a separate service registry so what will happen is every microservice will register itself with the service registry and service registry will help with service Discovery so service registry essentially is like a phone book for microservices or you can call it like a database or you can think of it like a database that has been populated with the locations of different microservices that exist so service registry will know

    
    04:41
    all the microservices that exist in a particular architecture and if you want to talk to any micros service you need to go to the service registry and get the location of that particular microservice and communicate to it so this is how the service registry concept works and like I said you can think of it like a database populated with network locations of service instances now all the microservices will register themselves with the service registry so by all I mean all or whoever wants to get discovered within the network so

    
    05:21
    they will register themselves with the service registry and service registry will help with the service discovery and when the micros service shut down shuts down they can deregister themselves okay so they automatically deregister themselves whenever they shut down now let us talk about this entire process as to how the service Discovery process works so let's say you have a job microservice and you have a review microservice okay so job microservice will register itself with the service registry that exists in the

    
    05:58
    microservices architecture now whenever a the review service wishes to communicate with the job service review service will instead go to service registry and do a service Discovery request so a service Discovery request is like a request to communicate to a particular service and then service registry will help the review service to communicate with the job microservice and this way the communication happens so the benefit over here is instead of relying on the individual microservices to discover

    
    06:36
    thems on their own so instead of using hard code URLs in that place what we can do is we can have service registry which is a centralized server to which every microservice can register and whenever you have to communicate to any microservice you do a service Discovery request and then you communicate so this helps and the this is a better approach as compared to those of hardcoded URLs like you can't have hardcoded URLs everywhere okay so this is about the concept of service Discovery and service

    
    07:13
    registry now let us talk about how it will work for us so if we have multiple microservices we will be registering all the microservices with the service registry over here okay and everybody will register so whoever wishes to get discovered in the network and then whenever there is a request that is supposed to be done to another microservice service registry will help with that let us talk about why using a service registry is beneficial so there are several reasons as to why this concept is really really beneficial so

    
    07:50
    the number one benefit is dynamic service Discovery so with a service registry microservices can dynamically discover the location s of other services at runtime okay and this essentially eliminates the need for hardcoding URLs so imagine if you don't have this concept how would you communicate so if you have a one service that is being hosted on a server and then you have another service that wishes to communicate so what you will do is you will take the URL of the second service okay so the service that

    
    08:27
    you wish to communicate with you will get the URL of that and you will hardcode it into the service that wishes to communicate so that's one way of doing it but with service Discovery this need of hardcoding URLs is completely eliminated and this hardcoded URLs thing can be problematic okay in Dynamic environments where Services can be added on the Fly and removed on the fly or even relocated so if let's say you are hardcoding the UR let's say and the service location has changed so the URL will also change

    
    09:04
    IP will change of course so in that case this becomes an issue and that is why there is a need for something that manages this dynamically okay because in microservices architecture everything is Loosely coupled like multiple services are Loosely coupled and there is a possibility so if you're using IP address to communicate let's say okay you're using the server IP so there will be a requirement or a mandate that that server IP cannot change and what what if it changes so there will be errors all

    
    09:39
    over okay so if we move the server the IP changes and if you like do anything like service you added a new service you removed some service or you do anything with the microservice so the possibilities of failo with hardcoded URL are higher and it's not a good practice to go about that okay so that root is not good and that is why this particular concept exists so this is about Dynamic service Discovery is what it helps with then we have load balancing okay so a service registry can also provide load balancing capabilities

    
    10:16
    and it it does so by Distributing the incoming requests across multiple instances of a service so if you are having a microservice and let's say if there is a lot of load on that microservice you can add multiple instances of that microservice to scale the needs of the traffic okay and in that case you might need some load balancing features and that is even what service Discovery can help you with so service Discovery is beneficial in that way with load balancing as well then you have fall tolerance and resilience now

    
    10:53
    what does this means so in case of microservices architecture where everything is loosely coupled and there are different Services there can be a possibility or a scenario where a service instance fails or becomes unavailable for a certain period of time and this way how can service registry help in this okay so let us say if a service fails and other services in the network do are not aware of this failure then what will happen like there will be errors all over so other services will also try to communicate to that service

    
    11:30
    without knowing that it is down okay and in this particular scenario service registry comes to the rescue so if a particular service instance fails or becomes unavailable service registry can detect the failure and update the registry accordingly so like I said it's like a phone book so it updates that hey this particular service is down for a while okay and this allows the other microservices in the the network to know that okay this is something that we need to be aware of and we need to redirect

    
    12:06
    the request to healthy instances accordingly okay and this can improve the fall tolerance and resilience of the network so resilience is basically not failing okay and fall tolerance is essentially the ability of a network essentially to survive defaults okay so in this way since service regist is aware of service instance not being available it can update and it can be aware as to how to route the requests then we have scalability and elasticity so as number of microservices and instances grow managing and coordinating

    
    12:47
    the interactions becomes much more challenging okay so if you don't have a service registry it will be a chaos okay so you won't know who is communicating with whom so in that case if you have a central calized service registry then service registry provides a centralized mechanism to manage service endpoints and it makes it easier to scale the system up or down based on a particular demand all right so this is about scalability and elasticity then you have service monitoring and health checks so

    
    13:20
    service Registries include features that enable you to monitor the health of the registered microservices and periodically check the availability and responsiveness of the services and they have a mechanism using which they mark them as unhealthy or healthy based on some criteria that they have okay and this information is used then by the rest of the network for better visibility decision- making and managing the system so service registry indeed is really beneficial and it's a great great thing to have in a

    
    14:00
    microservices okay but now the thing is how are we going to implement service registry okay so there are several service registry Solutions out there but the most popular one that we use will be using with spring boot is spring Cloud urea so if you head over to Google here so I'll just switch over to my browser and here I'm going to say spring Cloud urea okay so you'll see this first link over here which is spring Cloud Netflix okay so spring Cloud urea essentially is a client and that is a part of spring

    
    14:44
    Cloud Netflix project and this Netflix is like the netflix.com okay so so yes this was built and developed by Netflix and it was for its own internal use and and then it was made available for everyone else okay so Netflix urea was developed by Netflix and it's a service registry and Discovery server that allows applications to locate and communicate each other in a distributed system okay so you can think of it like a centralized repository for Service registration and Discovery and it makes it easier for microservices to find and

    
    15:26
    connect with each other so you can read more about uh spring Cloud Netflix and you can see it has some service Discovery features that have been mentioned over here okay so we will be making use of the dependency for including urea server into our project okay and you can see it's mentioned a few times over here all right so yeah how it will work is whenever we include the dependency we will get a separate urea server which will act as a service registry for for our Network or for our microservices project so yeah that's

    
    16:04
    about spring Cloud urea and that's about service registry and the importance of service registry in microservices architecture welcome back so let us start implementing and setting up the service registry with the help of urea server so we are going to make use of spring Cloud urea which is a part of spring Cloud Netflix project so what I'm going to do is I'm going to head over to start. spring.io so to add jurea server into our microservices architecture we will need to add it as a separate server and

    
    16:52
    adding as a separate server will require us to create a new spring boot application and that is why we have landed on this website start. spring.io so this is our favorite website from where we create new spring boot projects so select Maven select the latest version of spring boot make sure you're not selecting snapshot version then add the group ID so I'll add the group ID as com.mx all right and artifact ID I'll keep as service Rich so I'll say service R so this is service registry okay and I'll have service

    
    17:35
    registry service registry for our microservices so description is service registry for our microservices and you will see package name autogenerated we have packaging is jar and Java 17 is what we are using okay so this is something that we have added now now what we need to do is we need to add some dependencies so I'll say add and here I need to say web so this is one dependency that we will have to add we'll have to tell spring that this is a web application one more dependency is we will say

    
    18:18
    urea so you will see two dependencies come up so urea Discovery client and urea server so since we are setting up this server we need springcloud Netflix urea server so I'll select this you can explore the pom.xml if you wish to so here you can see there are two dependencies that have been added the web and the Netflix urea server okay so I'll say close and I'll download this as zip file so after you have downloaded this as a zip file you can extract it okay so I'll say extract here once the file has been extracted

    
    19:03
    you will see this folder appear now what we need to do is we need to add this as a project okay so I'll head over to intellig idea now in intellig I'm going to add a project to this layout here so I'm going to head over to Maven here on the right hand side I'll click on this plus icon so we'll add a new Maven project I'll scroll down and here we have this project service reg so service registry I'll say okay and you will see the service registry project appear on the right hand side so it's been added

    
    19:42
    to our unified view now okay so I'll just collapse this a bit now once this is added I'm going to close all the tabs and I'm going to expand the service registry okay so we are getting an error here okay okay so the error I got was related to syncing issue and if I I I clicked on sync again and the issue was resolved okay so there was some problem with the network to get the dependencies which is fine so we'll head over now to main Java and I'll open this service re registry application now in this particular file we need to add an

    
    20:27
    annotation so we need to tell spring boot that this is a urea server now how do we tell this with the help of a simple annotation which is enable so I'll say enable urea server and I'll say enter now you can take a look at this dependency here or this import statement here so spring framework Cloud Netflix urea server enable urea server so so this is coming in from the dependency that we have added so if you go to pom.xml here we added the dependency which is for urea server so this is a dependency that we have added

    
    21:12
    okay spring Cloud starter Netflix urea server so because of this dependency we have access to this particular annotation here okay and this is The annotation responsible for enabling or converting this particular application into a jur server Now by specifying this annotation we have all the features enabled for having a service registry over here okay so now what we can do is we can head over to resources application. properties now here we need to specify some properties here okay so I'll first

    
    21:49
    say spring. application do name so we need to First give this particular application a name so I'll call call this as service registry like so then I need to say server. Port so we'll have a different port for this particular application so I'll say 8761 so this particular application will run on this particular Port okay I'll say urea do client. register and I'll say hyphen with urea so this is one property that we need to specify and one more property urea do client do fetch registry so these two properties we have

    
    22:39
    to set okay so this property says whether you need this application to register to urea okay so this particular service or this particular application itself is a service registry which is nothing but urea server okay so I need to say false because a urea server cannot register with itself so we need to set this as fall okay now fetch registry so what does this mean so does it need to fetch the information of the registry it's a registry itself no so I'll say false so we need to set these two properties to false and we need to

    
    23:20
    add these two properties which specify the service registry which is the name and the port here okay so with this we are done configuring our service registry spring boot application which is nothing but urea server and we have done this with the help of the Netflix dependency so we have added this dependency from Netflix Cloud starter project which is of urea server okay and we are making use of urea server here to get the service registry up and running into our application so we are done with

    
    23:57
    the configuration all right so if you have done this successfully so far it's great and we will run this application shortly welcome back so we have the service registry project setup and created now let us run this project so I'll go to service registry application and I'll say run so our service registry application is running as a service now as you can see here and it is running successfully okay so here in the port we have specified the port number as 8761 so let us head over to this port and let us see what we see over here so

    
    24:47
    if you come over here you see this page that has been made available to you and the page says spring urea here you have the status of of environment here okay some information and here it says application no instances available so this is under instances currently registered with urea so what this means is we have urea server up and running successfully but there are no instances that are currently registered with urea as of now and that is totally expected because we have not configured anything

    
    25:25
    to work with Ure car yet but this is how you can run the project and access this page here which gives you a gist of what all services are available with our urea server so let us start registering the first service so the first service that we register is the job microservice and to register job microservice we will have to do some configuration changes in the job microservice and for that we need to add some dependencies as well so I'll head over to Spring initializer here and I'll remove these

    
    26:04
    dependencies and if you click on ADD dependency and if you say urea so you will see two files like two dependencies over here so you have urea Discovery client and urea server urea server is to set up the urea server but this time we will make use of urea Discovery client which is for Reg string purpose so I'll go to explore now and here if you scroll down you will see this particular dependency appear over here so I'll just copy the dependency I don't need to get or download the entire project because we have the project

    
    26:45
    already set up and I'll head over to my IDE now here I'll minimize this and I'll go to job microservice here pom.xml and here under H2 database or anywhere within the dependencies tag I'm going to paste the dependency that I have copied so you will see after pasting everything turns out red immediately and that is because we need to get the dependency so this dependency is not found and how do we get the dependency so you will see this icon appear over here on the right hand side whenever you do any changes to the

    
    27:26
    pom.xml file and if you click on this you can see resolving the dependencies okay so we got an error could not find this dependency here so the reason this has failed and we got this dependency error is because we are missing one more thing so if you head over to start. spring.io here if you if I zoom in let me zoom in a bit and here if you scroll down so here we have the dependency like urea client and if you scroll down you also have the dependency for spring Cloud so this is something that you need to add okay so I'll copy

    
    28:09
    this so under dependency management this needs to come in okay so we'll head over to our pom.xml and if we scroll down here okay so we don't have dependency management so we need to add this after dependencies and before build after dependencies and before build over here like so so let me resync now okay so we even need to add the cloud version so here we are making use of this variable we are saying we need to specify the cloud version here and if you scroll up here is the tag that specifies the cloud version so I'll get

    
    28:52
    this tag and I'll scroll up here and we'll add the tag here okay so this specifies the spring Cloud version the Java version is also specified and we are using the spring Cloud version over here like so so to resync I'll click on this Maven and I'll click on reload all Maven projects okay so you should see the error go away and everything should sync perfectly fine okay so remember when you whenever you are adding this like this urea client to your project you need to add spring Cloud as well like this tag over

    
    29:34
    here and you need to add this tag as well okay this specifies the spring Cloud version that your project will use and this is because spring Cloud starter Netflix urea client is part of spring Cloud project okay of course Spring Cloud Netflix project but you need spring Cloud as well all right so this was not needed when we did this for service registry and the reason is because we downloaded the entire project so everything was set up okay but this is needed and once youve done this you have all the dependencies that you need

    
    30:10
    to register job microservice as the client okay now what we are going to do so we need to add some properties now over here okay so these are the properties that we had added for our urea server but we need to go to job microservice SRC main resources and application. properties here okay so here we will add I'll say urea okay and these are all the properties that we'll need for urea server okay so to register this as a client what properties do we need so a couple of properties that we'll need is

    
    30:50
    these okay so I'll just paste this over here so here we are saying urea client register with ureka instead of false we will have true because job microservice needs to register with urea so this is true does it need to fetch the registry yes it needs to so I'll say true for both now how does job micros service know where urea server is so where is urea server running urea server is running on this particular port on Local Host so we need to give this address so if you go to our browser here we have urea server up and

    
    31:30
    running over here okay so what I'm going to do is I'm going to come to this application. properties and I'm going to say urea client. service URL dot I'll say default Z like so and here I'll paste the URL and I'll add urea in the end okay so this is the URL which will be used by our micros service to register as a client and we have specified two properties here we are telling the job microservice to register as client with urea and also to fetch the registry okay now let us reboot our job microservice

    
    32:18
    okay so what I will do is I'll go to the services Tab and I'll click on job microservice and rerun so this will start running our job microservice and let us wait for it to completely boot up so it's running now successfully now so you can see over here some logs appear okay you can see Discovery client Discovery client okay and here if you see if you scroll down okay you can see over here registering the service so the service is registered let us see here so here if I refresh okay so the application is

    
    32:59
    unknown okay and why are we getting unknown in logs also we saw unknown a bit and there's a reason for this the reason is we don't have a name for our job application okay which is not good so we need to add a name over here so to add a name I'll just scroll down and here I'm just going to say spring. application dot name and I I can say job hyen service okay like so and now once the application name is set okay you can even move this to the top somewhere over here okay and let me rerun this particular service so I'll go to

    
    33:43
    Services Tab and I'll rerun the job application now let us see what the logs look like so ideally in place of unknown you will have job service everywhere okay because that's the application name now so yeah you can see quite a few logs appear so you can see this is the Netflix Discovery Discovery client initializing urea resolving urea end points okay there are some more logs and if you scroll down okay there are some checks that are happening and here getting all the instance registry info from the urea

    
    34:21
    server okay so it's fetching the registry and here like com.net netflix.is discovery. disovery client the response status is 200 fair enough so if you scroll down here so registering application job service with urea with status up so our application has been registered as per the logs with urea server with this particular name job service okay and there are some more logs that appear okay and then the server starts so if you head over now here and if you restart you will see this particular application up okay and this is the URL

    
    35:07
    of this particular application and it's called job service so we have successfully registered our first service with urea so the registration is successful okay you're getting this alert which is fine okay so this is a warning that is coming up because urea is not able to ping some of the instances service instances which is fine so we can ignore this but the main part is we have successfully registered the job service so that's about how you can register a micros service to urea server welcome back so now it's time to

    
    35:52
    register the company micros service with the urea server and compy microservice will be registered as a client so we have already followed this process for job microservice and what I would request you all is to take this up as a challenge so try to do this yourself and try to register company microservice with the urea server so there are a series of steps that you need to follow which we have already taken a look at so try going Hands-On on this and what I would request is you can pause the video

    
    36:26
    right now and and come back and watch the solution so welcome back I hope you all had a chance to pause the video and attempt this yourself if you were able to congratulations if you were not able to that's perfectly fine the goal of this is to get you Hands-On with coding okay so if you're not able to that's perfectly fine so in order to get this done or in order to get or register company microservice we need to first start with dependencies okay okay so I'll head over to Spring initializer we'll copy the spring Cloud

    
    37:02
    version okay and I'll just paste this below the Java version so the Java version is mentioned here I'll add this here and then let us add the dependency for the so this entire tag the dependency management for spring Cloud okay so I'll go over here and just before below dependencies I'll add this okay and and then I'll add the dependency for the Netflix urea client so this is something that we will need so that it registers successfully okay so here I'll add this dependency now once you're done making changes to p.

    
    37:43
    XML refresh or reload so once you reload the mavin changes dependencies are bought in and what you can do is I'll just go to jobs application. properties and I'll call copy all these properties okay and then in the company microservice I'll go to main resource application. properties and here I'll paste the same properties okay but here we also need to add name okay so what I'm going to do is I'll pick up this name over here and I'll paste it over here and here instead of job service I'll change this to company

    
    38:26
    service like so I'll hit save okay and now it's time to run our application okay so this should work perfectly fine now one thing I want to make a note over here is we have just added the dependency here okay and we are just adding some properties to application. properties okay and the entire mechanism of registering this application with urea server is taken care under the hood okay now this is what autoconfiguration of spring boot in action okay so here we are not doing much we are just telling spring boot

    
    39:07
    that hey I need this dependency to be added okay and why would you add this dependency so you would add this dependency if you want your application to be registered with the urea server right now if you're adding this dependency so you spring boot knows that okay so it needs to register this with the urea server and that is when it starts looking for these properties that hey where is urea server you need to tell me and what all I need to do and what is the name of the application so if the application name is not there it

    
    39:41
    will register it as unknown okay so if I comment this so let me comment this and let me try to run the application without configuring the properties okay so I'll go over here and let me rerun the company micros service office so let us see what happens so the application is up and running okay and if you scroll up over here let me scroll up so here you will see this message registering the application with company service registering the application company service with urea with status app okay

    
    40:19
    this is something weird right now so if you go over here and if you refresh this urea page you will see company service appear over here and if you come to our source code we have actually commented these properties so what is happening actually over here so if you comment this out and if you run the application it will still register and this is because of the auto configuration so what happens is by default the values for these are provided so this is the default value that is provided even if

    
    40:52
    you don't add this this register with urea property is also also set to True by default and fetch registry is also set to True by default now if it's set to true and if it's autoconfigured by default why would you explicitly specify this so you should explicitly specify this because it's a good practice and in future if you make use of spring boot profiles so there is this concept wherein you can have different application. properties file for different environments so in that case it's best to have these definitions

    
    41:31
    across different properties files for different environments so that you know which environment is pointing where so you might have different environments like Dev prod and so on even QA you might have a QA environment so that's the best practice that you should follow from day one okay and this was like spring boot Auto configuration in picture or in action I should say now if I save this and if I run this again I'll absolutely get the same output okay so let me rerun okay so it's rerunning so

    
    42:07
    essentially it's really good so I'm teaching you the concepts but it's really good that you experiment with things okay what happens if I comment out a certain thing what happens if I modify a particular thing this is really really important when you're are learning programming because it helps you understand what's exactly happening under the Hood because right now there are Frameworks and everything makes your life so much easier but what's happening under the hood that is something that you need to understand and how will you

    
    42:36
    understand by experimenting and tweaking the code so yeah the service is up now if you go over here and if you refresh you will see company service appear over here so yeah we have successfully registered two microservices with urea hey there welcome to this class so far we have two of our microservices registered with the urea server now let us understand how we can make use of service names to communicate with our microservices so the entire goal of introducing urea server was to make use of service names okay so here in the

    
    43:19
    browser if I try to access the jobs API so here I have Local Host Coolin 808 to/ chobs this is going to work with no problems but what happens if I change this to job service so if I say job hyphen service so let us see what happens so this is not going to work okay and even if you copy this so if I copy job service here and you can see it did not work now if I copy the job service and if I head over to let us say Postman here and if I pick paste it over here okay so let me remove this extra part

    
    44:02
    and if I send this this is also not going to work okay now why doesn't it work because accessing the service via its service name directly via browser or Postman is not typically possible because urea does not act as a router okay so urea is a service registry and it is used or intended to be used by the microservices within the system and not by the external clients like web browser or Postman so if you want to access your microservices via the service names in the browser or Postman you will need to

    
    44:38
    set up something like a Gateway or something like that so Gateway will handle all the requests and it will do all the routing okay so this is not going to work if you try to access it so I'm just going to press control Z here okay and I'm just going to revert this to Local Host and get this working okay so this is about communicating with microservices externally all right using the service name of course now let us see how the communication would work within microservices so let's say if we communicate to company service from job

    
    45:13
    microservice okay how is that going to work with the help of service name so let us say if I switch over here and here if I say here in job service implementation if you go to job microservice in job service implementation we are already communicating with the company microservice here using Local Host so let us say if I change this to company hyphen service like so so I'm using service name now now let me rerun the server so what happens with this so I'll tell you what will happen this is not going to work and let us test this okay

    
    45:53
    so we have the service register properly and now if you head over here and if you try to get the jobs you get no result 200 okay now this worked because if there are no jobs we are not communicating with the company microservice so this worked now if I add a job we have a job with Company ID one now if I say get jobs this is going to break okay and this is not going to work so there is a reason why this does not work so the reason is because we are using an instance of rest template over here okay so if you switch over to the

    
    46:34
    code you're going to see all the errors here okay and if you scroll up at the top you're going to see unknown host exception okay and there's a reason for this so the reason is we are making use of rest template to make the call now rest template instance here is not load balanced so we need to get a load balance instance of rest template to be able to make a call to this particular service with the help of service name okay so how do we do that now so in order to do that we need to create a new class over

    
    47:13
    here so I'll create a new class in job package I'm going to call this class as app config okay like so here and here I'm going to have a definition so I'll say public I'll have a method here rest template like so so this is going to return an instance of rest template I'm going to say rest template and this is simply going to return new rest template okay now what is the benefit of doing this this is going to be load balanced so we are going to add this load balanced annotation over here as you can see okay

    
    47:54
    load balanced and I'm going to tell that this is a bean now what does this mean so specifying Bean tells spring framework that it needs to manage this object or it needs to manage the objects of this class and here I'm going to specify configuration so what happens is load balanced annotation configures the rest template to use load balancer client under the hood and this is a client that is capable of using service IDs registered with urea to locate the services okay so in that situation load balance annotation is needed and it's

    
    48:34
    critical when you're working with spring cloud and urea for service Discovery okay so we are making use of this and this annotation allows spring Cloud to create a proxy for the rest template that is intelligent enough to understand the service IDs from urea and to load balance the requests across instances of different Services okay or across instances of a particular service so you get better capabilities or a rest template that is much more intelligent in that case okay so here now what I'm going to do at the top I'm going to say

    
    49:14
    we create an instance of rest template I'm going to first say autowired okay and I'm going to say rest template here and rest template like so so we created an instance of rest template and we are saying autowired so this autowire what this Auto means is we are telling spring framework to provide us the instance of rest template on runtime and this is possible because we have mentioned or specified this as a bean so Bean means spring is going to take care of managing that okay so I'll scroll down here we don't need this rest

    
    49:56
    template so I'll just comment this out and now we are set so we are using the intelligent version of rest template to call our micros service so let me rerun this so we'll rerun this and we will see the output as to how it works so is up and if you head over to service registry you should see the registration is successful because you're seeing the name here okay now let me try getting all the jobs of course it will be empty so we need to add a job and we need to send the request so this time it will work

    
    50:35
    perfectly fine as you can see so you're getting the results which means the communication or the inter service communication between different microservices is working with the help of service IDs or service names whatever you want to call it so yeah this is these are some important Concepts that you need to remember and understand about urea server and Inter service communication okay and it's important that you experiment a lot with the code and that is what we did all right so I hope you have a clarity now as to how

    
    51:08
    this works now one thing I wanted to show you is here we have registered job service and Company service okay so if you want to D register you have to just stop the service and this name is going to go away from here okay so if you want to unregister or deregister a particular service with urea server you have to just stop the service and it will deregister itself so that's about the communication and load balanced rest template thank you hey there welcome to this class so far we have two microservices registered

    
    51:53
    with our urea server so now now I would want you to take up a challenge wherein you would register the ratings micros service with the urea server as well so we are aware of the steps that we need to take and this will be a good practice for you so I would request you all to pause the video right now and get this rolling so welcome back I hope you all had a chance to do the solution so let us get started with the solution ourselves so the first thing we need to do here is we need to add add all the

    
    52:26
    dependencies like we have done for the other two microservices so I'll get the cloud version tag over here and I'll set it in reviews micros service so I'll close everything else I'll open reviews microservice pom.xml and I'll even open up application. properties and I'll close this so here I'm just going to scroll to the top and just after Java version I'll add the springing Cloud version now we need to add the dependency over here so the dependency is spring Cloud starter Netflix urea client okay okay so I'll

    
    53:10
    add this over here so I can add somewhere over here and also we need to add this depend dependency management tag for spring Cloud okay so I'll go over here and just after dependencies I'll paste so we have made few changes to pom.xml and I'll hit refresh so this refresh should work perfectly fine now we need to head over to application. properties and what I can do is I can open up the application properties of any other microservice that we have configured to work with urea and I can like get some tags from there okay

    
    53:55
    so so I've opened the job microservice here okay so what we need is we need to copy this entire thing over here like so so we are aware that this is known as this is like to make this particular service aware of the urea server endpoint we are telling register with urea true and fetch registry as true we need to specify the service name so we'll add the service name otherwise our application will be registered as unknown okay so the service name can be review service so the name is added okay now what we can do is let me restart

    
    54:39
    this particular service okay so let us see the output and let us see whether it successfully registers or we get any issues we should not get any issues so if you scroll down here okay so you should see this message over here if you scroll down registering application review service with urea with status app now if we head over to the urea page and if you refresh you should see review service with its endpoint appear over here so the service has been successfully registered so this is how you can get review service

    
    55:18
    registered with jurea server hey there welcome back so what are we going to do in this lecture is we are going to update the get request to get a single job so as of now if you add a job over here and if you try to get a job we getting the job object but what we need to do is instead of Company ID we can even get the company object so along with Company ID we'll have the company object as well so this is something that we need to do and we will be making use of service Discovery and Inter service

    
    56:00
    communication these are the two mechanisms that we are going to do Hands-On and we're going to implement this okay so without further Ado let's get started so I'll switch over to intellig and I'll close everything so I'll close all the tabs I'll switch over to jobs microservice and within jobs I'll straight away go to the file which which I need is controller and the implementation okay so here in controller if you scroll down you have this get mapping now this is a get mapping that is responsible for getting

    
    56:38
    the jobs by ID so what we are going to do is we are going to go to this service method here which is being used get job by ID and this is the method that we are going to modify over here okay so what is the modification we need to do so we need to add company object to the response so instead of job we need to have job and company and we already have a dto class for this so this is job with company dto so this is what we are going to return so to get all the jobs we were returning a list object of this class

    
    57:20
    but we don't need to return the list instead we are going to only return in this object okay and the reason is because we are only fetching one job so I'll add this over here okay and now what I need to do is here I'm getting the job okay so I need to remove return from here okay and I need to accept job into a job object like so all right and now we need to transform this job into a job with company tto object now how do we do that so we have already done this and we have created a method for this so this is the

    
    58:02
    method which is job with which returns job with company dto and it converts a job to this particular object and it manages everything like it does the query to the company service and all so having this method makes life much more easier as you can see okay I can call it from multiple service methods and multiple math here so I can simply say return and I can say convert to dto and I can simply pass the job object that is it so our job is done here now we are getting these red marks and this is

    
    58:40
    because in the service class if you go here we are returning the job object so we need to say job with company tto and if you come back the red marks go away now there is one more place where we will be getting the red marks and that is in the controller okay so the reason we are getting this in the controller is because we were accepting the job object here but now we have changed this so we can simply change here we can say job with company dto and here also we need to say job with company dto okay so this will be job with

    
    59:26
    company DD object it's important that you rename the objects as well and the reason for this is it's simple so that you know okay what is this object holding so if you call this object as job and if someone else is looking at your code you will think or that person will think that this object is holding job but actually it's not it's a instance of job with company dto okay so I'll say job with company dto here as well and I believe we have solved it we have all the red marks gone so what happens is whenever we get a get

    
    01:00:02
    request we head over to the service class and we call this method within this method we are getting the job the instance of job with the help of this ID which we got from the controller and we are converting this job into dto and how are we doing this we are doing this with the help of this method me which we already wrote earlier and this is a method which takes the job object it sets the like it creates the object of job with company dto class it sets the job inside it fetches the company and

    
    01:00:43
    for that it retrieves the company ID here and then it sets the company over here and then it simply Returns the object so we are simply making use of this method here which is enabling us to convert our chobs to D and we are simply returning the output of this method here okay so this is the entire mechanism let us rerun our service so I'll rerun the job micros service let me rerun and let us see if we are getting any errors so ideally we won't get any errors because I believe we have done everything

    
    01:01:19
    correctly but still when it comes to programming you never know so yeah that application is running and here we can try getting jobs we'll create a job job added successfully you have one job added now let us try to get a job with ID one so earlier we were getting only the job object now you will get job and the company object as well so we are getting the response and the thing is working perfectly fine so now we have an API with job and Company details and I hope you all have a clarity as to how the communication

    
    01:02:05
    Works in microservices architecture with the help of urea server welcome back so here now I'm on Postman and I have this query executed this helps me get a single job from my job's microservice and as a result I'm getting the job object as well as the company object now the thing is I don't like this response structure okay so I want to restructure this a bit I don't want this job keyword over here I don't want this in the form of nested Json over here so this is a Json within an external Jason okay how do I change this

    
    01:02:53
    so to make this changes you can head over to the dto class so here I'll open the dto now here since we have added the objects of both the classes they are being converted into Json over here instead what I can do is I can go to the job class so from the job class I can copy all the properties I can exclude Company ID here and I can just add them over here okay now let me remove these Getters and Setters and let me add the Getters and Setters okay so I'll add the Getters and Setters for the newly added

    
    01:03:38
    Fields like so so you can see this class has been modified now okay we don't need to or we will need to make any changes here so let me see okay so we are setting the job so here we won't be able to set the job so so this error says that this Setter does not exist and it's absolutely correct it does not exist so what do we need to do so with the help of this particular thing we were able to set the job now what we can do is to solve this we can have a mapper created now what is the role of mapper over here

    
    01:04:16
    and why do we need it so we need a mechanism to map job and companies with the job with company dto okay so this is a dto that we have created and we need a way to map the company objects and the job objects to this particular dto and that is what the role of a mapper is so what I'm going to do is let me head over to the project I'm going to say new Java class and I'm going to say mapper do job map mapper so what I'm doing is I'm creating a new package called mapper and within this package I'm creating job mapper

    
    01:05:04
    class and I'll hit enter so you will see job mapper appear over here and here I'm going to have a definition of a method which is going to do the mapping for us so I'm going to say public static so after static we will have the return type so I'll say job with company tto here and I'll say map to job with company dto like so okay now here I'm going to have the parameters so I'm going to say job and this is going to be the job object and then we are going to have company which is company object like so

    
    01:05:49
    and I'm going to have open and close Square Braes okay now let me close this this and let me reformat the code okay so now what we can do over here is we need to create an object here okay so I'll say job with company dto and I can say job with company dto here is equal to new job with company T like so and here I'm going to start mapping everything okay so I'll say job with company dto dot set ID so we need to set the ID then we need to set the title so there a job title we need to set the description so we need to set

    
    01:06:37
    one by one all the parameters here okay location Max salary and we also need to set the main salary and let me see if anything is missing so I'll say set max Min ID we don't need so we need to set the companies compan is missing okay so these are the parameters that we need to set so I'll say job dot get ID okay so this is done I'll say job. get title this is also done job do get description I'll have job. get location job do set max salary and job dot get main salary and I can even have job dot get company or set

    
    01:07:29
    company sorry okay so we don't have job dot but instead I'm just going to pass in the company object okay so this is a company object that we are accepting okay and now I'm just going to return this object so I'm going to say job job with company tto like so and we are done so this mapper is created now what we need to do is we need to use this mapper over here so I'm going to delete this line here okay and here what I'm going to do is I'm even going to remove this line so let us remove that line too now here after we

    
    01:08:10
    get the company object I'm going to say job with company dto I'm going to create the object is equal to job mapper dot map company with dto and I'm I'm going to say sorry I'm going to say job comma company like so okay and I'll end this with a semicolon okay so this should be fine now let me move this to the next line okay so this is much more readable now and what I've done is I've removed everything so I've made this code a bit light so we are fetching the company object using the job object and we are

    
    01:08:51
    passing the job and Company to a new mapper that we have defined and this is a mapper that exists here okay and with the help of this mapper we are mapping the job and Company objects to that of tto okay so this way you can now imagine like you can modify this to any structure because you have a mapper now and it does the job of mapping if you do any changes over here in the structure you have to just change the mapping here that is it and it will take care of everything okay now now what I can do is

    
    01:09:25
    I can simply rerun this application so let me redeploy chob and this should result in structure changes in the response okay and that is what we wanted so application is up and running okay registration status 204 and if you go over here in Postman this was the response that we were getting earlier okay now if I send the request again we won't get any output okay we got an error so let us take a look at the error that we got let us understand job is null okay so we need to handle the null case as well okay so

    
    01:10:09
    we need to say we need to handle null which we have not handled but the mechanism is working so if I create a job and if I try to get a job here you can see the structure has changed now okay so you can see the structure is working perfectly fine and there are no issues as such so we have modified this to a better output or a better end point and this is applicable also for this because the dto is same so if you try to get all the jobs you will see this is also updated now and this is because the dto

    
    01:10:46
    is same behind the scenes so this is about how you can restructure the response to match your requirements and this you can do with the help of dto so it's getting fun and exciting I hope you're all enjoying so that's about this class and I shall see you all soon thank you hey there welcome back so right now we have our microservices up and running now the thing is if you go to the jobs API and if you fetch the job jobs okay we don't have any jobs so let me add a job okay so there's this one job added

    
    01:11:31
    let me add a company also so there is one company that exists so I'll try fetching the job so here if you fetch the job you're getting the job details as well as the company details now but what I want to do is I want to even add the review details okay so we don't have that added yet so let us work towards adding and bringing in review as the part of the jobs API so I'll switch over to intelligent now what we need to do is there are there is a series of steps that we need to do so for company we went to jobs microservices

    
    01:12:11
    and here in external we created the company class and this is a class that represented the company object and then we mapped or we added company into the dto object here so dto class and then with the help of mapper we created a mapping okay and then there was some functionality that was written in the service class over here which helped us fetch the company and do the mapping so this was the process that we followed for company we need to follow a similar process for review so what I'll do is

    
    01:12:51
    I'll go to the review microservice and let us see what all elements we are storing for any given review so we have these things that we are storing here for the review so I'm going to copy this now let us head over to external package in the job microservice and here in the external package I'm going to say new and I'm going to say new class and I'm going to call this class as review okay so this class is created now what we can do is we can paste in the properties that we copied from there now

    
    01:13:29
    here I don't need to store or show the company ID so we can get rid of this so we can just have ID title description and rating over here all right now what we need to do is we need to have Getters and Setters for this so I'll generate some gets and Setters there you see so the review class is now set now as a Next Step what we need to do is we need to add review to job with company dto so here in job with company dto I'm going to add review here so here I'm going to say private review like so and I'm going to

    
    01:14:14
    have a review here now what I can do is I can generate Getters and Setters for this okay so I'll go to the end like so and here I'll generate gets and Setters I'll select review so we have this set now okay now what we should also do is we should rename this dto so this says job with company dto but actually now we have enhanced this dto to also include review information so we can just call it job dto because this shows the job information along with the company that has posted the job and the

    
    01:14:55
    review of the company so I'll just right click on the class here and I'll go to refactor and I'll say rename so here I'll just say job dto and I'll delete this so this is a new name I'll click on refactor I'll keep all the settings as default so you will see some checkboxes over here and I'll say refactor now what it will do is it will refactor everything all right so wherever we are using this class it will refactor and it is also asking us a couple of details here so if I'm able to expand this you can see so it is telling

    
    01:15:38
    us intellig we have created a few local variables for this particular class and we are calling that local variable as job with company dto and this is most likely in the service implementation okay so here this is how we have implemented it so since we are changing the name of the class do we also want to rename the variable name to job dto and yes of course we want to do that all right so I'll say select all and I'll say Okay so the refactoring is done so if you go to job service implementation

    
    01:16:15
    class and if you scroll a bit you will see the class name has been changed everywhere and also the local variable object name so this is a local object that we had created so this is also renamed to reflect or match the new class and this is also true in the controller so if you go to controller you will see Chop dto Chop dto here which is really good and this is also the local object that we have created and this is also renamed so intellig makes our life easy this way okay so imagine like without intellig if you're

    
    01:16:51
    coding here and you renamed a class you will have red marks everywhere and you have to go and see hey we're all like this is not working now so I need to change even I I'll have to change the inputs so inputs are also automatically managed by intellig itself so everything is renamed automatically whenever you change an object and that's the magic so here in if you were not using intellig you would have to come and manually change this okay so now this is done we have have renamed this now what we need

    
    01:17:25
    to do is we need to head over to the mapper so here in the mapper we need to do the mapping but before mapping I'd say here in the service implementation we need to get the review as well okay so here since we are getting the company we need to so every company has a company ID and with the help of that company ID you can get the review so now now here we need to call the review API so if you take a look at the review API so let us go over here so whenever you fetch a review from the company you get a list so there can be

    
    01:18:08
    multiple reviews against a particular company okay and how we have handled this is here we are getting a single object okay so we won't be using get for object we will be using Exchange so I'll say rest template dot so I'll say exchange here okay and here I'll pass in the URL so I'll copy the URL from here like so so this is a URL now instead of Local Host I need to use the service name so the service name is review service so I'll say review service like so and here this needs to be dynamic so what we are going to do is

    
    01:18:53
    I'm I'm going to remove this like so and I'm going to copy this here and here I'm going to say space and let me say job. get Company ID so here I'm passing in the company ID okay now exchange method requires some parameters so this is the URL that we have passed in and we need to specify the method as well so I'll say HTTP get I'll specify null as the third parameter and I'll specify this over here so I'll say new parameterized reference type and I'll say list here okay and this list is of the type review so this is what we

    
    01:19:43
    are getting as the response okay and I'll keep this to empty and I'll put a semicolon okay now here what I'm I'm going to do is I'm I need to accept the response so I'm going to say response entity like so and here I'm going to say review response like so and response entity has list and it's a list of review type so what have we done over here now okay so we have not made use of get for object because we we will need exchange method from rest template and this is used to get the list of review objects now

    
    01:20:32
    exchange method is much more versatile than get for object and it's useful when the response type is a generic collection so here you have a generic collection type and this is where exchange is useful okay now get for object is particularly useful whenever you know that the response that you're going to get get is going to be a single object but when you get list as the return type from the API it's better to use exchange now what we have done is we have passed in a few parameters okay so the first parameter is the URL here so

    
    01:21:09
    you can see the URL that I have specified I have specified the service Name colon this is the port and then I have like I'm calling the reviews API and I'm passing in the company ID here okay now so this is the dynamic URL that is crafted then I'm specifying the method type over here so this can be get postp put or anything okay but since this is a get request I'm specifying get over here we have null mentioned over here so this specifies the request entity that we need to send to the server and in this case there is no

    
    01:21:47
    request body so since the request body is null we have specified null over here then we have have the parameterized type reference over here this captures the generic type information of the expected response so we are telling that the response is supposed to be in this format okay this is how it is working and then we are accepting the response over here now what we need to do is we need to get the review response so I'm going to say list and I'm going to say review and here I'm going to say reviews is equal

    
    01:22:23
    to review response. get body okay so from the response we need to get body that we need to convert to this reviews which is of list type okay so this is done we have the list of reviews that we are fetching from the API call and we are doing this API call to the review micros service now what we need to do is with company we are mapping job and Company right so now what what we need to do over here is we need to pass in reviews as well over here like so so this will be passed to this particular

    
    01:23:02
    method okay so this step is not needed actually so I'll just comment this out okay so we are already doing the mapping within this particular method so I commented this out and we are passing reviews also now so I'll go to this method here now and I'll add reviews over here so I'll say list and it is of reviews type okay and I'll say reviews like so now what are we doing with the reviews so we'll scroll down and here I'll say job d dot set review okay and I'll pass in reviews okay so we are getting an error

    
    01:23:49
    here because we're passing in the list so if you go go to job dto here we have specified that a single job will have only one review but actually that is incorrect so we will have the list of reviews so I'll just make that modification here okay and I'll call this reviews and with this change the Getters and Setters will also get updated so I'll say generate getter and Setter and I'll regenerate this so how this works is one job is associated with one company and then that company can have a list of

    
    01:24:26
    reviews like of course many users will post in the individual reviews so there will be a list of reviews right now here what we need to say is we need to say set reviews and we are done okay so this is updated now what we will do is we'll head over to services and we'll restart the job microservice and the reason for this is is because we have only made changes to the job micros service and not to any other micros service so we'll wait till the application is up and running so it seems that it's up and

    
    01:25:04
    we'll head over to postman here so we won't have any jobs because we have restarted so I'll just add a job and I'll try to fetch the jobs so now if I try to fetch the job you see reviews are empty so we need to add some reviews against Company ID 1 so I'll say Company ID one review number one description is also one and I'll add this now let me add one more I'll say two and I'll say two now let us add now let us call the jobs API so now if you call you will see the reviews also getting populated okay

    
    01:25:49
    so what we have done is we have added review reviews into the jobs microservice and reviews are also now being a part of the response that we getting with the chobs API so this is how you can work with different microservices now to outside world whoever is calling the jobs API he's not aware of the inner details okay he does not know like how many microservices are being called in the background okay you can even mask this URL so you can have something like a Gateway or something that you can set up okay and that thing

    
    01:26:25
    will route the request to the respective API so all that can be done but the main point over here is to show you how you can communicate effectively and we are also making use of service registry which is urea server so keep that in mind all right so that's about this class and I shall see you all soon thank you hey there wel welcome to this class so let us start talking about behind the scenes of urea server registration process so we have a couple of microservices and then we have a service registry which is urea server in our

    
    01:27:08
    case so a micros service will register itself the other microservice will send a service Discovery request and it will do that to communicate with that particular microservice so this is how entire process works now for this to work every microservice in the microservice architecture needs to register itself with the urea server now the question is how does urea server keeps track of all the microservices and how does it manage everything so the number one thing is registration so each microservice instance will register

    
    01:27:46
    itself with the urea server and the registration does happen with the help of hard bit signal and this signal is being sent to urea server at regular intervals so how does it work so it works with the help of hardbeat signal and during the registration process the microservices provide information such as the host name IP address Port metadata health status and so on so all this information about them is being sent to the urea server for registration now after after initial registration so this is not the end so this was just the

    
    01:28:26
    registration process now after initial registration the micros service is responsible for periodically sending the hardbeat signal to the urea server and this signal is an indication that micros service is still active and functioning properly okay so because of this signal the urea server also knows that hey this micros service is up and running and it uses this to to keep track of the services that are up now when are these heartbeat signals sent now the intervals between the heartbeat signals is

    
    01:29:04
    configurable and can be adjusted based on the requirements so whatever requirements you have you can even specify a custom duration all right now urea server does hardbeat monitoring so jurea Ser will monitor the heartbeat signals from from each registered microservice instance and if urea servers stops receiving heartbeat signals for a particular micros service for a specific amount of time it will Mark the instance as down or out of service and urea server will maintain the list of all the available and

    
    01:29:43
    healthy microservice instances based on the received hard bait signals so this is about urea server and how it Mak makes use of this concept hardbeat signal and hardbeat monitoring to keep track of all the microservices in the network now hardbeat mechanism ensures that urea server has an upto-date view of registered microservices and the health status okay so now let us do an experiment so I have a few microservices up and running here as you can see on intellig and they all are registered with service registry so if I go here

    
    01:30:23
    and if I go to urea so this is the urea's page and if I scroll down you will see like there are three microservices that have been registered and urea server is also up and running so this is working perfectly fine now what I can do is I can simply shut the urea server so urea server is up and running I'll simply shut the urea server and now now if you go to any of the microservices you will see start seeing some stract trees so let us wait for a while and essentially you will see the heartbeat mechanism in action

    
    01:31:05
    because this is not working okay so if I refresh this the server is down okay and here now if you go let's say we go to review so we see some stack Trace now okay so you can see so this stack Trace has started coming in okay so you can see over here com. netflix.is Discovery transport exception cannot execute any request on any known server okay and if you scroll down it is saying it was not able to send the hardbeat okay so it is sending the hardbeat to the urea server and it is not able to so you see one more

    
    01:31:46
    storace and it tried to send again okay and you'll see this again and again okay so as long as it tries it is going to print all this as a stct Ras and you can go in the job also so here also you will see the same thing okay so if I say control F and if I search for Heart Pet and let us say if I search in company microservice okay so okay I need to search on this site so I'll say heart beat you can see a lot of things that have been highlighted with this keyword hardbeat was enabled to send the

    
    01:32:27
    hardbeat and this is for all the applications okay so you will see this coming in for all the application if I search for job also so here if I search for job so let me say heartbeat and you can see send heartbeat is the function or the method that is being used and it's throwing an except option here okay and you will see this message here was unable to send the heartbeat so this is from job service so this is the proof that this is how it works and now if I turn this on okay so let's say I turn on

    
    01:33:09
    the review and if I scroll down in job microservice there is literally an exception in the end so service was up and running now if I refresh we don't have any instance is up and running and now slowly everything will come in so you can see company was registered so if you scroll down here you can see it got registered registration status 204 which means that it got registered for job it's not yet registered reviews let us scroll down and see what's up with reviews it's registered so jobs is pending okay it

    
    01:33:46
    got registered too so now if you go over here okay you can see see all the three microservices have been able to register themselves so this is how this heartbeat mechanism works and with the help of this Jura server is able to keep track of all the microservices that are there in the network and this is really helpful and this entire mechanism is known as heartbeat mechanism all right so that's about behind the scenes as to how urea server works hey there welcome back so let us start talking about open Fain so what is open

    
    01:34:32
    Fain and why should we use it so Fain is a declarative web service client that is designed to make writing HTTP clients easier now what does this mean so to make regular HTTP request in an application you might have to de deal with a lot of boilerplate code okay so for example we have a microservice and in order to call another microservice we need to do an HTTP request because we'll be making use of HTTP protocol so in that scenario you will be using rest template now the thing about rest template is there is a lot of

    
    01:35:11
    boilerplate code that you need to write again and again for example this is what the source code for doing a simple call to another microservice look looks like so here you are making use of rest template object and you're making use of this method and you're saying get for object and you're passing in the URL now you have also passed in some parameters like you are expecting the response to be masked or wrapped into this particular class object okay so the return type that you'll get will be a

    
    01:35:47
    company object here now the thing is if you have to make multiple connections you need to write a lot of boiler blade code and you need to make connection you need to handle retry by yourself you need to process the responses and so on now what does Fain do is it abstract all these away and allows you to write HTTP request as if they were simple method calls so without Fe this is the source code and if you integrate open fan into your project and start using it this is what this line of code will become

    
    01:36:22
    so now here you have a client created and you are just saying get company and you have passed in this parameter so this is like a normal method call that you are doing and in the background open Fame will do the job of communicating to the microservice and retrieving the company object and giving it to you so it becomes much more easy and you don't have to deal with like a lot of stuff a lot of boilerplate code is reduced and also so you don't have to type in the URLs again and again so everything is

    
    01:36:56
    now managed in the company client over here so this is how open fan makes your life easier whenever you are making use of different web services now why use open fan so the number one reason is easy to use so Fain simplifies htttp API calls by creating a sort of proxy and then it implements HTTP requests behind the scenes so all of this is abstracted from you and it just makes things look a lot more easier than you would be doing the normal way another benefit is integration with urea so just like rest template Fain can

    
    01:37:36
    seamlessly integrate with urea for service Discovery then we have built-in load balancing with ribbon so open fan has built-in support for ribbon which is an another Netflix project and this provides the client side load balancing okay the next benefit is support for fallbacks and circuit breakers so with Fain you can easily integrate histrix which is another Netflix project and this project can provide fallback options and circuit breaking capabilities so this is the reason why you should use open fan now

    
    01:38:15
    let us compare Fain and rest template so Fain and rest template both serve the same purpose and they both do the job of simplifying HTTP requests in the spring application but they do so in slightly different ways so rest template for example is older more traditional way of making HTTP requests it is robust and flexible solution and it does offer a lot of control but it can also lead to a lot of veros code especially when you're dealing with complex requests so this is a very simple request that we have done

    
    01:38:52
    over here but if you're dealing with a complex request the code with rest template can go a lot more purpose and cumbersome now on the other hand you have Fain over here wherein you have written some code using open Fain and Fain is a modern solution that takes a different approach and instead of creating a template that you fill in with specific Fain creates a proxy based on an interface you define and this results in very clean and simple code so it may not offer the same level of control for complex scenarios as rest

    
    01:39:30
    template but still it's a really good choice for modern web applications so this is about open Fame and rest template also I wanted to mention that open Fame is also developed by Netflix and then it was later included in the spring Cloud family of projects so that's about open fan thank you you welcome back so let us enable fee clients in our microservices project so I'm going to head over to the project structure and I'll head over to job service implementation class now over here we are making use of rest template

    
    01:40:13
    over here so we need to make use and we need to replace these calls to microservices with the help of Fame clients so for that we will need to add a dependency into our project and to add the dependency let us head over to our favorite website so I'll say start. spring.io now here in the dependency section I'm going to say add dependency so you can search for open fan over here and you're going to see this option come in and you have to select so you you can read over here that f is a declarative

    
    01:40:54
    rest client and it creates a dynamic implementation of the interface that is decorated okay so what I will do is I'll go to explore okay so this is the gradal dependency that has been added I'll change to Maven and I'll go to explore now we have the maven bomb. XML so what I will do is I'll copy this entire thing and I'll switch over to my project and within jobs microservice I'll head over to pom.xml here and here somewhere in the dependency section I'll just add this dependency that I have copied so I have

    
    01:41:38
    this dependency in and whenever you make any changes to pom.xml we need to reload the mavin changes so I'll hit reload and mavin changes are being resolved so you can see resolving dependencies of the project so this is done now what we need to do is we need to enable open fan and we need to tell spring boot that we need to enable Fain clients in our application so for that we'll head over to our main application file which is job Ms application here you will find this annotation spring boot application

    
    01:42:20
    so just before this or just after this you can add this annotation called enable Fain Cs and you can add this so you can see this import statement will be added at in the import list and this annotation will tell your application that hey we are making use of Fain clients so please enable them now what we can do is we can start defining Fame clients so if you head over to job service implementation here we have two API requests that we are doing one is to company service and another one is to review service so we can replace these

    
    01:43:06
    calls with the help of rest template so these calls are being done as of now with the help of rest template so we can replace these calls that are being done with the help of rest template and we can make use of open fan here so I'll go over here and I'll create a new package so I'll say new and I'll say package and I'll call this package as clients so we are going to have clients defined over here now the number one client that we need is company client so I'll say company client and we need to declare this as an

    
    01:43:44
    interface so just make sure you select interface over here and I'll say enter now here in company client I I have an interface declaration so I need to add a or I need to add an annotation so I need to say Fain so you can see this annotation come in Fain client so this annotation tells spring boot that this is a Fain client and then here as a parameter you can say name and the name of the service is what you can specify over here here so I'll say company service like so so this is defined now over here what I need to do

    
    01:44:31
    is I need to create a method okay so I need to declare a method so I I'll say get company so here if you go to the implementation class here we are making an API call to this particular URL and we are getting the company object as has the response right so we need to create a method we need to say get company and this method will take a parameter because our API takes one parameter which is the company ID right so whatever Dynamic parameter we are passing in the API becomes the parameter of the method and whatever is the return

    
    01:45:13
    type of this API becomes the return type of the method so here I'll say get company and I'll say long ID like so okay and this method will return company object like so okay so this is done now we need to specify the URL as well over here okay so what kind of request should this client do to this particular microservice or this particular service company service so we need to say get mapping so here we are creating mappings and I need to specify the URL over here so I'll say companies slash I'll say

    
    01:46:03
    ID okay so this is a structure we have companies slash ID over here right so we have added the same thing over here now ID we have added into curly braces and this is because that will be dynamic and how do we tell like from where we are getting this ID so we will be getting this ID from path variable like so okay you can even specify the name over here of the parameter which I'll do so yeah so this is the entire definition of the interface so we have defined an interface which will do the API calls

    
    01:46:44
    for us and it will make use of open fan all right so this is what you need to do if you need multiple services or if you need to call multiple URLs from this particular service you need to add multiple methods and you need to specify the mapping and the method over here all right so that is what you need to do and the job will be done so we have now defined company client so we can go to the implementation class and now what I can do is I can simply remove this entire thing okay and I need to say

    
    01:47:19
    company client dot I need to say get company so get company is the method that we created and here I need to say job. get Company ID so this is what we need to do but the question is from where do we get the company client so to get the company client what we need to do is we need to create an object of company client and that is something that we can do over here so here I can say private company client like so and I've created an object of company client and I can add this over here so I can say

    
    01:48:06
    company client like so and this dot company client like so we have created an object of company client and the error is gone now we need to do the same for the review Service as well so what I will do is I'll create one more interface here and I'll call this interface as review client so I'll say review client and I'll mark this as an interface now here I'll say so I'll add similar things as to what I have added over here okay so I'll copy this first annotation and I'll I'll add it over here okay now instead of company service

    
    01:48:54
    this is review service like so and here we have this particular method and I'll come over here and I'll add this over here now there are some changes that we need to do depending on which API we are calling so we are calling the reviews API slash reviews so in the end like after the post name we are passing in reviews so the path is reviews and then we have company ID which is going in as a request parameter so what we can do is we can say slash reviews and here instead of path variable we can have

    
    01:49:37
    request parameter and this request parameter can be Company ID like so and here I can say Company ID like so okay now now this will be get reviews okay and this will return a list which is of reviews type okay like so so yeah so we have created an interface which is review client it talks to review service and we have created a get mapping which accepts a request parameter called Company ID and what is the output of this method we get a list of all the reviews that belong to a particular company all right so this

    
    01:50:28
    is done now in a similar way to company client we need to create an object of this particular interface so we'll say private review client and I'll create an object here and here I'll say review client okay like so and here I'll assign this so I'll say this dot review client so we are done doing this and now here what we can do is we can just do away with this entire thing okay and I can simply say so list of review and here I'll say reviews is equal to review client dotg reviews and here I can say

    
    01:51:24
    job. get Company ID like so okay so this is done and we can do away with this as well okay so you can see like how we have simplified this particular thing okay and like it's it's the code has reduced considerably okay and we are relying now on the fame clients which we have created which are interfaces and they will do the job of calling the rest API on our behalf so let us test this and what we can do is we can rerun the job application so I'll rerun this and let us wait for it to get started so now our application is

    
    01:52:09
    started and let us head over to postman here so I'll open Postman and here let us try calling chobs so you will get an empty array let us create a job so job is created successfully now let us try getting all the jobs and you can see we are getting all the jobs along with the reviews so reviews and ratings already exist okay because they they've already created and we just created a job and we can see like the communication happening properly okay now there are few things that you need to make a note of okay so

    
    01:52:51
    if you go over here and if you go to app config we had created app config class in the earlier sections okay and we had defined app config when we were planning to make use of rest template and the reason we had defined this because we needed a load balanced version of rest template and that is because we were not able to work with or get this working with these service names okay now with open Fame you must have noticed we have not added any load balance annotation or any such thing so we have simply created

    
    01:53:29
    the interface we have specified the microservices name and everything the URL as well and also all the parameters and we are done so we don't need to like Define all of this with open fan okay and as for rest template like we can get rid of this Bean now okay so this is a bean that we had defined and we can simply remove this Bean entirely if we are moving to open fan entirely okay so this won't be needed it you can keep this only if you are using this in the other parts of the application where you

    
    01:54:08
    are not ready to replace those API calls with open fan yet okay then we can keep this rest template pin and remember that Fain provides a more high level way to call HTTP services and it includes things like automatic Json conversion error handling and more okay now open fan as you have noticed also reduces a lot of boilerplate code that we were earlier writing and it makes the code easier to read and even maintain okay so here we had hardcoded the URLs right now imagine now if any company service or

    
    01:54:48
    any name changes okay so this name changes from company service to something else so you have to just make change at one place it's organized you have all the clients defined in the package okay so it's easier to maintain and that's why many developers in the microservices world prefer using open fan when they work with microservices okay also keep in mind the load balance annotation is not used with Fain clients client side load balancing is done automatically with open fan and when you use the Fain client annotation okay it

    
    01:55:24
    takes care of the load balancing for you okay now F or open F under the hood uses ribbon now what is ribbon so ribbon is also used by rest template when you annotate it with load balanced okay and it is being used to function properly so in app config when we said load balanced it was like we had ribbon being used internally okay so that is why when you switch to open fan you don't need in fact rest template Bean with the load balanced annotation anymore because the fame clients are load balanced and it

    
    01:56:06
    handles everything for you automatically so that's about open fan and how can you implement it in your project so let us start talking about this fascinating topic that is really crucial in modern web application architectures which is distributed tracing so in monolithic applications tracing was a simple process so if you want to track a request from its initiation to its end all you need to do was to log each step with a single application okay and what I mean by tracing over here is the process of

    
    01:56:48
    tracking a request from from the beginning till the end that is what tracing is so when we were building monolithic applications it was easy to trace a request you could use logging and all to trace what's happening however as we move to microservices architecture things became a little bit more complex okay and the landscape has become significantly different so instead of single large application we now have numerous smaller ones and each are responsible for different part or different kind of functionality that

    
    01:57:23
    they would offer to the application now there is also a possibility like these applications might be written in different different languages so you might have one micros service in Java another micros service in Python and so on like you don't know okay and even the database might differ so one might use PA SQL one might use MySQL another one might use mongodb okay and everybody is on different server or container now when you make a request in such distributed system it typically goes through several of these

    
    01:58:00
    microservices now imagine a scenario where something goes wrong like a request is lower than expected or is failing altogether or something is happening with that request which is not expected so what would you do in such scenarios you begin investigation but investigation in case of Monolithic is simpler but how would you do this in case of microservices like there will be several questions in your head right like which servic is causing the delay or which service is giving you the errors where is the

    
    01:58:31
    request failing okay now what you need to do is in such scenarios is you have to go and access the individual logs for each service and this becomes an amn task like if you have like 50 or 30 or hundreds of microservices like this this is impossible okay like so basically there is a need essentially to get a view of the request as to how it's traversing through different microservices and what is happening with that request okay and we need to get a view of this with every microservice so if a request is going through multiple

    
    01:59:11
    microservices what is happening when it's going to each microservice okay so that detail we need to have and this is a problem that that distributed tracing solves okay so what is distributed tracing so distributed tracing provides a method for you to track request okay so essentially it enables you to trace your requests from start to end or from its Inception and as it travels through each microservice and until it's completed okay so this is what distributed tracing is and it gives you a very like it gives you a view of

    
    01:59:49
    what's Happening with the request and with this you can solve a lot of problems you have a holistic view or a Hawkeye view of what is happening with your request and where your request is creating errors now what are the problems that distributed tracing helps us solve so the number one problem is the request visualization so distributed tracing allows you to visualize the flow of the requests as they propagate through different services and components in a distributed system okay it helps you understand the dependencies

    
    02:00:24
    and what kind of interactions there are there is happening with different services within the microservices network and it also gives you a clear picture of how your request is traversing your architecture okay so this is a number one problem second problem it solves is to identify performance bottleneck okay so since you are now able to trace the request across across different services with distributed tracing you can now identify the performance bottlenecks and even Trace latency issues okay so you can

    
    02:01:00
    analyze the duration of each step in the request flow so for example if your request is touching upon five microservices you can check the duration of each step like for first micros service second third fourth and so on okay and you can make a note or pinpoint the services or components that are contributing to the delays or high response time so this way you have an identification method using which you can know the culprit okay and with the help of this you can take the right actions you can like inform the

    
    02:01:38
    appropriate teams and you can enhance the performance of your overall system so this is the second problem then the third problem we have is air error analysis and Dearing so in micros servic architecture there is a possibility that an error might occur now it can be challenging to identify the root cause as to which service caused that error what happened to that particular service and why the request was not fulfilled so with distributed tracing you can easily identify the error as to where the error is happening

    
    02:02:15
    and you can capture the complete trace of the request okay okay and you can also include the errors any encountered during the way and so on okay so it allows you to trace back the sequence of events and identify the service or the component that was responsible for the error that you have caught and because of which your request was not fulfilled so that's another problem that distributed tracing solves then it also enables you to track dependencies so this is another problem that is really good and it's solved by microsof

    
    02:02:49
    services so this is another problem that is really good and it's solved by distributed tracing so microservices architecture often have complex dependencies between the services so there is a possibility that one service might be dependent on a response from another service so with distributed tracing you can get a view of like what sort of dependencies exist in your architecture and by visualizing the request flow and tracing dependencies between the services you can identify how changes in one service will impact

    
    02:03:24
    others and you can even detect any cascading failures if they happen in your architecture so it becomes really helpful this way so the next problem that distributed tracing sols is of performance optimization so with distributed tracing like we discussed you can identify the areas of system that can be optimized and by analyzing the request flow timings of various steps you can can identify opportunities to reduce the latencies optimizing resource usage and also improving the overall system performance okay now this can also help

    
    02:04:00
    you with capacity planning and scalability so you can get some insights into how the performance of Individual Services and overall system is and you can use this information for capacity planning and scalability efforts so by understanding the load and performance of different Services you can allocate more resources to a particular microservice that might be having more load and is acting a bit slower so you can add more resources there and you can scale the service so that the overall system throughput increases okay so

    
    02:04:37
    these are the problems that uh distributed tracing solves over and above it also helps you set slas okay so if there are slas that you have set like some slas for latencies and uh time that a request should take this particular method of distributed tracing enables you to maintain those slas as well okay and whenever any incident occurs in microservices architecture distributed tracing helps you there to assist in root cause analysis okay so so this is about distributed tracing and how it can be helpful in microservices architecture

    
    02:05:17
    so that's about this class I shall see you all soon thank you welcome back so let us start talking about Zipkin so when it comes to distributed tracing distributed tracing is of course a key tool for maintaining troubleshooting and optimizing distributed systems and it gives us the visibility of what is happening with our complex applications now now what is Zipkin so Zipkin is a crucial tool when it comes to distributed tracing so Zipkin is an open-source distributed tracing system and with the help of

    
    02:06:01
    Zipkin you can gather timing data needed to troubleshoot latency issues in service architectures so it's a tool that enables you to trace your request from the beginning till the end so it provides a lot of things like it provides the timing data with the rise of microservices architectures these days tools like Zipkin have become incredibly valuable so let us talk about what is Zipkin and how it works and we will also talk about the components that exist with Zipkin so these are the different components that Zipkin has okay so let

    
    02:06:41
    us say we have a microservice which is company microservice and here you will have a collector you have some storage search and then in the end you have visualization so this is what is Zipkin will comprise of so with collector this is where your application will send the trace data okay so for tracing you need to collect data and this is where your application will send the trace data and The Collector will accept the data over the transport modes like http Kafka or even rabbit mq okay then we have storage

    
    02:07:23
    so once the data is collected the data needs to be stored somewhere and Zipkin offers a variety of storage system like MySQL Cassandra and even elastic search then you have search so Zipkin provides an API and a web interface to search for traces in the storage that you have so you can find traces based on different crit criterias like name annotation or time and then you have visualization so once you have found a trace Zipkin helps you visualize the trace in a way that makes sense to you and it shows you a

    
    02:08:03
    diagram of how your request has flowed through the system where time was spent and what was happened when an issue occurred so it gives you a Hawkeye view of what is happening with your request in a sense okay and it gives you a lot of information also along like the time how much time was spent on each thing and each microservice so this is how Zipkin works so here we have only one microservice that is sending data to collector but we can have multiple microservices that exist in the microservices architecture

    
    02:08:41
    and everyone can send data to collector which is within Zipkin so this is about Zipkin and how it works and these are the different components that exist and enable Zipkin to function properly now let us talk about two different things in Zipkin trace and span so what is a trace so a trace is a description of a transaction as it moves to a distributed system so you can think of Trace as a tree of work that is done based on a request okay you can think of it like a journey of a request okay so let me give you an

    
    02:09:24
    example so you have a client that is requesting something now let's say to fulfill that request you need to interact with three microservices so for example we have job microservice company microservice and the review microservice so to fulfill this request you need to interact with three microservices so the request will go through three micros services and this entire journey is known as a trace okay and then you have another concept which is known as span so what is a span a span on the other hand unlike trees is a

    
    02:10:03
    basic unit of work so for example sending an HTTP request is a span as is sending a response okay so here when interacting with different microservices the request is performing a unit of work so this would be one unit of work then here you will have second unit of work and then with review microservice you will have a third unit of work so this is one span this is second span and this would be the third span now a span and a trace are represented by IDs so for Trace you will have a trace ID okay which represents

    
    02:10:41
    the entire request from start to end and span will be represented with the help of span ID and it represents the individual unit of work now span will also include metadata about the work like the time it started the time it ended and any annotations or anything to describe the events that occur when the span was active and so on okay so if I have to give you a Hawkeye view of how this entire thing works is when a request enters a system so let's say this request came in from this from client into the system

    
    02:11:19
    and at that moment there is a new Trace that is started now that Trace has a trace ID and as the request passes through each microservice like for example job company and review so for each micros service a new span is created to represent the operation that is performed by that micros service and each span is linked to its parent span performing it Trace tree so you have Trace ID at the parent level or a trace at the parent level and then you have multiple spans that show the different unit of work that has happened and like

    
    02:12:02
    I said span will have different kinds of information like start time end time duration and different metadata about the operation okay now spans and traces are collected and stored and analyzed by distributed tracing system like Zipkin and it gives you insight into the performance and behavior of the microservices so if you are wondering how Zipkin is able to show you the working of the request across different microservices so it is because of span and Trace so now you can imagine you have Trace which is which represents the

    
    02:12:41
    entire request journey and span which represents the individual work so with the help of this data you can store it and you can create a nice view that can represent and that can show different requests that are happening and how they are happening in your system so this diagram here that you're seeing provides a simplified representation of the concept of trace and span and and it helps you understand what they do in the hindsight so in summary Zipkin is an essential tool in the world of distributed services and it provides a

    
    02:13:17
    crucial visibility into the performance of distributed system and helps developers like us to troubleshoot and optimize their applications so that's about Zipkin hey welcome back so in this lecture we are going to go Hands-On with Zipkin and we are going to explore Zipkin by installing it and we are even going to like set up it on to our system so so to begin with let's head over to browser and let us search for Zipkin here now the moment you search for Zipkin you will see this official website here of Zipkin doio so you can

    
    02:14:04
    click on the first link and you will be taken to the Zipkin official website now you can see Zipkin is a distributed tracing system okay you can read about how it works and this is what the interface of Zipkin looks like okay so you can see here this is an example request so it has post slocation SL update SL V4 so this is a request post request here you can see the duration 10 services and you can see total spans were 13 Trace ID was this and you can see the request Journey okay so this gives a complete like visual

    
    02:14:46
    representation of your request and if you select anything it gives you some more information and more metadata as to what happened and what what like what was the start time the value address and so on okay now there is also dependency tab which shows you the dependency of different services that exist in your application okay so what we are going to do is we are going to click on quick start and here we're going to get started with the installation so now installing Zipkin is has three options

    
    02:15:24
    okay when it comes to installation we have three option we can do it using Java which is like using jar file here then you have a Docker option okay and running from source is also another one which is using git okay so you can go with either of the approaches so if you want to try the jar version you can click on the latest release over here and this will give you the jar version of sekin so what I did is I just downloaded this jar file and what I can do is I can go over here and open the folder so this

    
    02:16:01
    is a jar file that has been downloaded like Zipkin server you can see over here now you can open the terminal and you can run this command you can run this command Java hyphen jar Zipkin dojar and it will just run this particular jar file and it will give you access to Zipkin so if you want to see this in action I can like open up Powershell here okay and I can head over or switch over to my directory so I can say desktop spring boot desktop courses spring boot here and here if I do LS you can see I have the Zipkin server Char

    
    02:16:43
    over here okay so I'll just zoom in a bit so that you get some better visibility I'll clear the screen and you can say Java hyphen J and you can just say sepin server so this is a jar name so you can just type in said and press tab so this will give you the name and if you press enter you should see something like this so you might see this firewall access and I'll say allow access so Zipkin is trying to access the network over here okay so if you see the logs over here so we have just typed in One S simple

    
    02:17:24
    command here okay Java hyphen jar and this is a way of running jar file with the help of java you see this Zipkin like like some icon logo comes in and then you can see it's being served at Local Host Port 941 and you can access it from here so if I press control this becomes a clickable link and you can see the dashboard over here so this is the Zipkin interface it's fairly simple and it's relatively easy to navigate and use it okay so the main thing over here is this search bar here okay so the search

    
    02:18:04
    bar is important wherein you can search for things with the help of Trace ID okay and you also have a way to search over here so you can search using service name maximum duration minimum duration so this is really nice yeah like you can filter requests that are taking so much of duration and so little of duration and you can even look at all the requests for a particular service name okay so this enables you to give like to get more insights as to what is happening with your system okay now you

    
    02:18:37
    will find the trace over here whatever traces are coming in okay if you click run query you will see all the traces here and if you click on any of the trace you will see a very nice UI that we just saw over here okay so this interface is what you will see when you click any of the TR and then you have dependencies tab which show you the dependency of different components within your microservices architecture okay so this interface is fairly simple all right but for now we are running it with the help of Jar file

    
    02:19:14
    which is one option that I showed you so we won't be using this approach instead we can go ahead with the talker approach so I've just shut down the server okay so to set down the server you can press so on command line or Powershell I pressed in control C or contrl C okay so if this is running so I pressed in control C and it stopped the server and if you're on Mac you can press command C okay so this is how you can uh stop and start the server using jar now there is another option which is to make use of Docker so you

    
    02:19:55
    can simply get this command here okay and we will head over to the terminal so this is a terminal and I can paste in this over here and make sure you have Docker up and running so I have Docker running here okay so I'll just run this and it says unable to find the image locally so what it does is it downloads the image from the internet okay or from the docker Hub and you're getting this latest image being downloaded so this will take some time depending on the network connectivity but you have Docker

    
    02:20:32
    like Zipkin running on Docker up and running so I can say Docker PS so here I can type in Docker PS like so and you should see Zipkin over here like you can see yeah and like we did early on you can just refresh this page and you should be back like this dashboard is back okay so this time we are running Zipkin within the docker container all right so we'll be using the docker approach okay because we have do already configured Docker and if you have not installed Docker I would highly recommend you to do so so for now

    
    02:21:11
    we are using Docker but what I want to do is whenever you make use of Docker we switch to Docker compose because with Docker compose it's easier to manage multiple containers in your application all right so we have our Docker compost file defined here okay so this is a Docker compost file which has different Docker like images that are being pulled so what I'll do is I have the setting created here which is for Zipkin so I'll copy this and I'll paste it over here so Zipkin will be available in our application okay as with the help

    
    02:21:52
    of talker compost so I'll P this and we are done okay so yeah we have this configured now and if you wish to you can simply remove this image okay so you can say Docker stop and you can stop this particular container you can copy the container ID oh so I you should say Docker stop and let us paste the container ID so this is a container ID for Zipkin and this will stop the container okay so you can see the container is stopped now okay now you can remove the image so you can say Docker RM and let

    
    02:22:37
    me get the image name so you can say Docker images so this will give you all the images that exist on your system so I'll copy the image ID and I'll say Docker RM and I'll paste the image name okay so it's not RM it is RM so RM was not the command it was RMI but right now we are getting an error that we are not able to remove this image because it is being used by some container so what I can do is I can remove the container first like I can say RMI and this container for which I got the ID I'll get this removed but

    
    02:23:15
    we're getting this error that no such a exist okay that's weird so what I will do is I'll just force remove Zipkin so I'll say RMI hyphen f okay and you can see this is deleted now so now if you see if you say doer images you're not going to get the uh open Zipkin image over here so this was the open Zipkin or Zipkin image so you're not going to see that image here okay so this is gone so now we can manage or we are ready to manage this with Docker compose so what you can do is you can say Docker compose down or

    
    02:23:57
    you can say directly Docker compose up so let me save this and let's see what happens so you can see when you say Docker compose up okay so it's running but the thing is we didn't run it in detach mode so that's the mistake we did okay so what I can alternatively do is I can quit okay and I can run it in detached mode like so okay so you have the containers up and running as you can see okay so there are three containers now PG admin post Chris and Zipkin so now you can come over here if you refresh

    
    02:24:38
    you're going to see this okay and this is working perfectly fine okay so what we have done is we went a little bit Hands-On with Zipkin we tried different ways as to how you can use and set up Zipkin onto your system and Docker is our preferred approach so we'll be using Zipkin within Docker container going forward hey there welcome to this class let us start talking about micrometer and what it is so what is micrometer so micrometer provides insights that help you keep keep tabs on your application's performance so

    
    02:25:20
    essentially it's a tool that helps you check your application performance now let us talk a bit more about this how micrometer helps so micrometer helps you collect different metrics about your application and these metrics are measurements or data points that provides insights as to how your application is performing and they can include things like response times error rates resource utilization and so on now collecting these metrics can be a complex task because there are different tools and systems available for

    
    02:25:56
    monitoring and Metric collection and each tool may have its own way of collecting metrics and storing them so this is where micrometer comes into picture and micrometer essentially acts as a middleman or bridge between your application and the metric collection system so it provides a simple and consistent interface for you to instrument or measure different aspects of your application the key benefits of micrometer is that it offers a vendor neutral interface okay this means that you can use micrometer to instrument

    
    02:26:36
    your application metrics and then choose the metric collection system that you prefer or that works for you the best according to your needs and micrometer supports various popular metric collection system like Prometheus graphite data dog and so on so with the help of micrometer you can abstract away the complexities of interacting with different metric collection system and you can focus on instrumenting your application with the metrics by using a consistent API okay that micrometer provides so in summary micrometer

    
    02:27:14
    simplifies the process of metric collection for your application so in summary micrometer simplifies the process of collecting metrics for your application now one thing that I wanted to talk about is how is micrometer different from tracing systems like Zipkin or sluth so while micrometer and tools like Zipkin are instrumental in like observing your application but they serve distinct but complimentary roles okay so micrometer is a metric collection library and it measures things like how many requests have been

    
    02:27:52
    made how long do they take on an average what is the distribution of the request duration and so on it provides the metrics in a way that can be scraped and stored by variety of monitoring systems okay so you have micrometer which is collecting metrics and then behind the scenes you can use any monitoring system you want and it will give you a bird eye view of your application performance on the other hand Zipkin it is a distributed tracing system and it tracks the path that the request takes as it

    
    02:28:27
    travels through different microservices in your system and it provides you a detailed view of a single request showing you how long each step took and what service was responsible for that delay or that particular step on the way okay so this is what about micrometer and Zipkin is so while micrometer provides an application Level view with aggregated metrics over time distributed tracing tools like Zipkin provide a request level view so so there's a difference aggregated metrix level view with micrometer and request level view

    
    02:29:05
    with distributed tracing tools like Zipkin okay and Zipkin enables you to trace the request level view tracing the path latency of individual request and not application as a whole okay so they both are essential for different reasons and together provide a comprehensive view of your application's performance and behavior so that's micrometer for you all right so now the time has come wherein we should integrate Zipkin with our spring boot microservices project so we already have have Zipkin Docker image

    
    02:29:48
    added here in Docker compose and you can run Zipkin in multiple ways like you can have Docker image running in zip of Zipkin you can have like a jar file running of Zipkin and so on but we are choosing the talker approach now what we need to do is we need to start integrating Zipkin so in order to do that so we have not yet integrated we have just added Zipkin to toer compose and this would just enable Zipkin to work as a standalone service but we need to start sending the data to Zipkin so that we could view how request is

    
    02:30:26
    flowing through our system okay now to do integration we need to first go to pom.xml so let us open the pom.xml of this first project which is company now to add the dependency we will head over to our browser now here in the browser I'm going to go to start. spring.io and I'm going to remove this open fan over here and I'm going to add the dependency and I'm going to Simply type in Zipkin so after adding this dependency just make sure you have selected Maven and just hit explore now here we will see the

    
    02:31:10
    dependencies coming up that are needed for Zipkin to function properly so the dependencies we need is like micrometer tracing Bridge Brave and Zipkin reporter Brave so these are the two dependencies that we will need but before talking about these dependencies I wanted to add a thing over here so here you will notice micrometer is being used when we are integrating Zipkin so in the earlier versions of spring boot we used sluth so spring Cloud sleuth was being used to add add Zipkin into our project and to

    
    02:31:49
    enable distributed tracing so you can see over here spring Cloud sluth provides spring boot Auto configuration for distributed tracing so earlier when you had to enable distributed tracing in your application you need to add this library but right now you can see this message over here that with the latest version you can check this version here so the core of this project got moved to micro meter tracing project so in order to enable distributed tracing in your application now you need to work with

    
    02:32:25
    micrometer okay in your springboard application and you can see all the details over here when you click this particular micrometer tracing link okay so if you are curious you can just go through this link and take a look okay and you can see over here these are the dependencies that we are seeing over here so micrometer tracing Bridge Brave and here we have okay Bridge wave is not here so here you are seeing reporter Brave and that is what you're seeing over here so Zipkin reporter Brave okay so yeah this

    
    02:33:03
    is an update that I wish to share with you and we will be using micrometer so we will be using in a sense we will be just adding the dependencies so I'll copy these dependencies these two so micrometer tracing bridge and I'll head over and I'll paste these two over here so there are two dependencies one is the tracing Bridge Brave and Zipkin reporter Brave okay so what do these dependencies do so let us also talk about this so micrometer tracing Bridge Brave is a bridge library that connects micrometer with brave okay and

    
    02:33:45
    micrometer is a metric instrumentation library for jvm based applications and brave is a Java tracing Library which is compatible with Zipkin so this is a bridge that connects micrometer to Brave and then you have this another dependency which is Zipkin reporter Brave so this is the reporter which sends the tracing data to Zipkin and Zipkin is like we know distributed tracing system it will gather this data and it will show you with the visualization that you need to work with your services okay so these are two

    
    02:34:23
    dependencies that we have added and this is how they help us now we'll sync this now the thing is after adding this dependencies spring boot autoconfiguration comes into picture and spring boot autoconfiguration realizes that we have added these dependencies so of course we need to send data to zkin server and it will start sending sending data by itself we need to do some configuration in properties that is all nothing more than that now here in our project we are making use of open fan as well okay so we are not making use of

    
    02:35:01
    open fan in the company project but we are making use in job project but I'll add the dependency here as well so we need to add one more dependency if you are using open fan so the dependency name is Fain micrometer okay so you need to say group ID as IO dot GitHub dot open Fain so this is the auto suggest that we got so instead of Fain bomb here I'll just get this removed and I'll say Fain hyphen micrometer okay so and we'll skip the version tag okay so yeah and now we'll just sync this so This should just fetch

    
    02:35:46
    all the dependencies all right so we have configured this and we need to add this dependency because if we are using open fan which is a declarative web service client then whatever requests are being sent using open fan should be sent to Zipkin as well so for that we need to add this Library as well okay so this is done so now since we have done the changes in the dependencies we now need to do the configuration which will dictate as to how the data is being sent to distributed tracing system so I'll

    
    02:36:22
    head over to application. properties here for this particular microservice and here I'll say Zipkin so I'll add a few properties okay so here I'll say management dot tracing dot sampling dot probability okay and and I'll specify this as 1.0 so with this property we are telling to trace each and every request that goes on okay so in production based environments you might not want to trace each and every request that is flowing through your system because sending data receiving data storing data this will

    
    02:37:09
    all take some process okay this is a process so this might slow down your system so in production grade applications you don't trace everything so you will reduce the sampling rate okay so you can reduce it to 6 or something like so that will trace the 60% of the request okay but since we have specified 1.0 it will Trace each and every request and the reason we are doing this is because we are still building the application and we are learning okay so there is a possibility that if you are working in a

    
    02:37:42
    production grade environment you will see a different different sampling rate over here okay so I've specified this over here you can even mention the Zipkin based URL okay so you can say management do Zipkin do tracing endpoint and you can specify the Zipkin URL over here okay but I not specifying the end point because the default one is usually picked because Zipkin runs on the default Port over here so 9411 is the default Port so that is a default that even if you don't specify it's okay so I'll just have one property mentioned

    
    02:38:26
    over here which is the sampling rate okay and we are done with the integration so integration involed two steps okay one is understanding and adding the dependencies and then configuring the properties okay so I realized I just made a small mistake in the spelling here so it's prob probability okay so I'll say probability over here so this is a spelling just make sure you get all the spellings right otherwise you will land in errors okay so yeah that's about integrating Zipkin with your springut

    
    02:39:07
    application hey there welcome to this class so we have integrated Zipkin and we are now sending the Trace data to the distributed tracing system so what I want you to do is I want you to now integrate this for Job Service as well as the review microservice so you can take this up as a challenge it's a simple process wherein you need to First configure the dependencies like we did for company microservice and then you need to configure the application. properties so pause the video right now and take this up as the challenge and

    
    02:39:45
    configure the other two micros servers so welcome back I hope you have configured this I'll show you how you can do this step by step if you have not been able to so what we need to do is we need to add the dependencies first so I'll copy these three dependencies so the first dependency is tracing Bridge Brave and the other one would be reporter Brave and then Fain micrometer so I'll copy these three and I'll paste it in the pom.xml of job app okay then I'll head over to review I'll open the pom.xml there and I'll paste

    
    02:40:28
    the remaining dependencies as well okay here I had already copied the dependencies and I paste it now what I can do is I can go over here to the maven icon and since we want to reload multiple Maven projects because we have made changes into palm. XML files so either you can go to individual pom.xml files and reload like this or you can just click on M in and say reload all projects so this will reload everything and you must have seen the progress at the bottom okay now the dependency configuration is done now we need to

    
    02:41:07
    configure the properties so I'll simply copy this property here okay I'll close the pom.xml files and now I'll open the application. properties for both the applications so this is for job and then I will have one open for review like so now what I will do is at the end I'm just going to paste the property that I have copied so I'll paste it over here as well as in the job micros service so we are done configuring both the microservices to to work with Zipkin hey there welcome back so now we have configured our projects like all

    
    02:41:58
    the microservices to work with distributed tracing systems like zkin we have added all the dependencies and we have configured the properties now it's time to test our changes so I'm going to restart all the applications review job as well as the company okay okay so everything is restarted now now we can head over to urea server and just make sure that everything is up and running okay so all the microservices are up as per urea server now you also need to make sure that Zipkin is up and running okay because Zipkin is where we

    
    02:42:46
    will be testing the changes okay so now what I will do is I'll switch over to postman I'll first switch over to companies and I'll create a couple of companies so one and two and then I'll create a couple of reviews here so I'll create one two and one review I'll create against Company 2 so it's done now I'll switch over to jobs and I'll create one job and I'll try getting the job so you can see the job Jason we have one job one company and a few reviews okay now what we need to do is we need to head over to

    
    02:43:30
    Zipkin and say run query so we are not seeing any Trace information or any request information which means we are missing something so what are we missing so I guess I figured out the problem here so here when we added Zipkin to our dependency list okay and when we said explore here we copied these dependencies right but we didn't copy the actuator so we need to have actuator as well for this two function so what I'll be doing is I'll be copying the actuator dependency and we'll head over to our project here okay and I'll close

    
    02:44:14
    everything and I'll open the pom.xml for all three microservices so this is for company jobs and then for reviews as well okay and let us add this dependency to all three microservices so this is one this is two and this is three here now we need to reload all the changes and to do that I'll head over to this Maven icon and I'll reload everything okay so you will see job company and review all three are being resolved in terms of dependencies so this is done now we have actuator added as dependency for all three so actuator

    
    02:45:01
    is important and that is why when we added this dependency here for Zipkin this was Auto added okay so just keep in mind whatever is generated with start. spring.io like spring initial it makes sure it gives you everything that is needed for something to run so here we are using Zipkin so it also gave actuator as a dependency which was missed so we added this now what we need to do is we need to restart our applications again so I'll restart this so I'll say restart review restart job and restart company as well okay and we

    
    02:45:44
    can test the status or we can check the status in the urea dashboard okay so if you hit refresh so company I believe is not restarted let me restart company as well so company is restarting let us see what's happening okay so the company is restarted and Let me refresh this so you will see company service also come in over here okay so all our microservices are up and running Zipkin is also toop and running now let us head over to postman and let us close all let us keep everything open and let us try what we

    
    02:46:23
    tried again so I'll create a couple of companies I'll send post request twice so two dummy companies and I'll post a review against Company ID 1 okay and I'll create one more review against Company ID 2 and I'll post a job now I'll try fetching everything so you can can see this Json response that we are getting here now what we can do is let's switch over to Zipkin and let us say run query okay so here is where now the magic starts so you're seeing all the requests that we did so this was review service wherein we created the

    
    02:47:04
    review this is the post request for company service where we created the company this is the post request for review service again where we again created the review and then for job we created the jobs okay and then I again created a review so there are three reviews essentially that I created and one job and one company okay so all that you can see over here and if you click on this like the drop- down arrow you can see review service is what we are interacting with okay and at the top you'll see the final

    
    02:47:44
    API call that we we did to get all the jobs okay and you can see different information like rout start time spans duration and so on okay so this is sorted by duration and not by start time okay so if you want to sort by start time you can sort it that way too so you will see company review and job service then okay so what I wish to show you over here is take a look at this span over here so this has a span of five so five spans are there rest everyone has span of one which means they were only

    
    02:48:22
    interacting with one microservice so of course if we are creating reviews we are only interacting with the review microservice okay but here we interacted with three microservice and has a span of five if you click on show you will see this nice detailed view which gives you an overview of what's happening with every microservice and every call that happened to each and every microservice now with this view you can get a nice information so you can see job service get took 132 milliseconds then company

    
    02:48:58
    service with Company ID here it took 44 milliseconds then we have job service again which took this much time and then reviews took this much time and in total the request took this much time three services were interacted with a span of five and this is the Tre ID okay and you can see different information on the right hand side as well like annotation and this is all the metadata which includes start time end time and so on okay the request method was get status code was 200 so this is amazing okay and

    
    02:49:35
    if you go over here again run query okay you can view this as well so you can just experiment over here you can say show and you'll see see this is just interacting with one micros service okay so this is a nice overview you can like filter over here service name and I can say let give me service name for only company okay and I'll say run query so I have filtered with job service and you have only two requests that are going to job service so this way you can filter requests as well to a particular service and you can examine

    
    02:50:12
    that particular service as to what is happening and you can play around with different filters here like Max duration if I want to filter out the requests that are taking a lot of time okay I can do that minimum duration I can do that service name I can do that absolutely independencies tab if you run query here it generates this dependency diagram where in job service is dependent on company and review service so this is based on the request that we are triing so from job service we are triggering a request to company service

    
    02:50:47
    and again from job service we are triggering a request to review service okay you can modify the date time as well over here and play around with this this data like you can even upload Json if you wish to and you can play around with filters here as well so indeed it's an amazing tool okay so you can see like how service if service goes down also you can play around with this so let me like take one service down so I'll just turn down the review service let us stop review service and let me trigger the

    
    02:51:23
    postman request okay so we got an error of course we have not handled the error but we got an error and now if you go over here and if you run the query okay you will see this was the request that we triggered and it has a red mark If you go to show you will know okay this request fil failed so you will know why it failed okay it went to job service company service also but it didn't go to review service so probably that service is down right yes so this is how you can play around with Zipkin and Zipkin can

    
    02:52:02
    give you lots of information which can be critical in managing your microservices you can also use buttons like expand all and collapse all this is just like user friendliness of Zipkin so that's about Zipkin and how you can use it to work with different microservices I hope this was valuable and I shall see you all soon thank you hey welcome to this class so let us start talking about the common problems that might occur with distributed tracing and how can you even troubleshoot them so the number one

    
    02:52:43
    problem that I always hear is the missing Trace problem so what is this problem so here sometimes you might not see the traces that you were expecting to see in Zipkin okay so you are doing a request to your microservices but you are not seeing the trace in Zipkin and this could be due to various various reasons out there so one reason that I could think of is it could be because of network issues it could be because your sampling rate is low so when we configured Zipkin we have to specify a sampling rate so if the sampling rate is

    
    02:53:20
    too low like very few requests will be sampled for Zipkin so just make sure your sampling rate is a bit appropriate if you want to see some request flow into Zipkin another reason could be spans are not being reported correctly or Zipkin is not properly configured so to troubleshoot this issue you can make sure that your services are up and running correctly ly and are indeed producing some traffic then you can verify your configuration settings particularly those related to sampling rates and Zipkin and

    
    02:53:55
    Reporting also you need to make sure that Zipkin server is properly configured and it's up and running and lastly be sure to check for network connectivity and make sure that the span is reaching your aspkin server so these could be few steps that you could take to solve this missing Trace problem let us talk about best practices and Performance Management with distributed tracing so the number one point that I would like to mention is about the use of consistent naming conventions for your services so be sure to have

    
    02:54:33
    consistent naming conventions for your services because this helps in easier identification and also helps with readability so if you are building an application and let's say if that application scales up tomorrow and you have then tons of microservices out there and if you're not following a proper naming convention it would be a mess so it would be very difficult for you to understand like which request is coming from which microservice and what was the name that you had given to a particular microservice so it's better

    
    02:55:06
    if you are building from scratch it's better to have a proper naming convention in place so that it's easier when things scale up and naming conventions are particularly important because in Zipkin you see everything by name the next best practice should be to secure your Zipkin Sero so tracing data can contain some sensitive information so ensure you have secured your Zipkin server properly another point that I want to mention is an informational point so you need to know that distributed tracing

    
    02:55:43
    comes with a performance impact now what does this mean so since you're tracing your requests that are like happening in your microservices architecture this tracing involves some extra computation and the network calls that happen like we store data and we we are sending data essentially to sekin so all of this involves extra computation and therefore it's important to manage the tradeoff between the detail of the data and the performance impact so this is one key thing to keep in mind now the

    
    02:56:18
    thing is how would you control this so one way to control this is to adjust the sampling rate so you don't need to trace every single request especially in a environment where there is a lot of traffic coming in so you can lower your sampling rate so in our example we had set the sampling rate to one which was tracing all the requests but you can reduce the sampling rate and it can still give you a representative picture while reducing the performance impact and you can even have a view of what is

    
    02:56:50
    happening with different microservices however beware that lower sampling rate might also mean that you miss some of the infrequent issues and the right sampling rate often depends on the use cases and the nature of your system and also what you want to track so this is about best practices and the things that you are supposed to keep in mind but distributed tracing is one of the amazing things that comes in with microservices and it helps you a lot so that's about this class I shall see you all soon thank

    
    02:57:31
    you let us start talking about configuration Management in microservices so what is configuration management so configuration Management in the context of software engineering ing is the practice of managing and controlling the configurations of different systems and in case of microservices it simply means managing and controlling the configurations of different microservices so this is a practice of handling changes systematically so that the system maintains its Integrity over a period of time now configurations may include

    
    02:58:10
    details such as database connections so if your application is wanting to connect to a database they might be having some database connection configurations they might have external service URLs like if they are consuming some Services externally they might have some caches related setting and more like so these are different configurations that exist and they allow your service to work and function properly now there is a challenge when we talk about configurations so as the number of micro mic Services increases

    
    02:58:45
    in your architecture managing individual configurations can become a complex task and it's really hard to keep track update and hard to synchronize this across all the services also if the configurations are embedded within the applications or scattered across multiple places it becomes even more daunting and difficult to manage and deac so there is a need and a room like there is a need for a centralized config server and This Server can be a central place for managing all the configurations across your all

    
    02:59:24
    microservices it simplifies the configuration management and it increases the operational efficiency of the system so this is what is configuration management and the need for a config server so let us talk about how configuration management will work so let's say we have three microservices job microservice company microservice and the review microservice and then you have a separate config server which is hosted somewhere now all these microservices will do the job of fetching and retrieving the

    
    03:00:02
    configuration from the central server okay so this is a central server that saves all the configurations that are needed by each micros service and this config server can have configurations for different environment as well like for example you might have a Dev environment or a prod environment or a QA environment so different environments have different configurations that are typically needed by microservices and this config server is capable enough to handle that let us talk about some features of

    
    03:00:36
    config server the number one feature would be centralized and versioned configuration now config server interfaces with a version control system like git and this way all the configurations are versioned and changes can be tracked very easily you can even roll back the configurations if you wish to so this is one feature of config server Dynamic updates so most config server support Dynamic updates meaning that you can change the configuration in the server and the services can refresh to get the

    
    03:01:11
    new configuration without needing to be restarted okay so this is another aspect then you have the aspect of security so config server can also encrypt and decrypt the information or configuration properties that you are storing to ensure that sensitive data is secured so if you have any passwords or anything that you want to encrypt that is 100% possible application and profile specific configuration so a config server can even have the profile spe specific configuration like Dev test prod and so on so different

    
    03:01:47
    configuration files for different environments so these are the features let us talk about the benefits of having this so the number one benefits is like the single source of Truth so config server provides a single source of Truth across multiple microservices leading to consistent configurations across all services secondly it allows you as a developer to easily manage and update the configurations since it's now centralized and it also enhances the security and control since things are now centralized so you have you can

    
    03:02:24
    Implement better security practices and even have better control over the configuration and lastly it it makes it easy to deploy and scale your microservices okay because you have a central config server where you can manage your configurations very easily so this is about the the configuration management and what it means in the world of microservices hey there let us start talking about spring Cloud config server so what is spring Cloud config server so this is a part of spring Cloud project and spring Cloud project is a suit of

    
    03:03:10
    tools specifically designed for building and managing Cloud native applications so spring Cloud config server provides a way or provides a centralized external configuration management backed by git or SVN and it uses a version control system which helps us effectively track and manage the configurations across different environment and microservices so this is the official page of this particular service here so if you search for spring Cloud config and you will land on this official website which is

    
    03:03:47
    of talks. spring.io and you can take a look and read more about this project here so let us talk about how does this work so here is a diagram to illustrate the working of spring Cloud config server so let's say you have three microservices job microservice company and review and you have a cloud config server which you have set up and this is a separate server which is is responsible for managing all the configurations in your microservices architecture so what happens is spring Cloud config server

    
    03:04:22
    uses git in the background for storing and managing the configuration files now all these microservices can interact with the spring Cloud config server and it is going to store all the configurations and manage them in a centralized place which is what we see here which is kit so config server is essentially like a middleman as you can see so when a micros service starts it asks the config server for its configuration and config server what is going to do is from where it will provide the microservices about the configurations

    
    03:04:59
    so it will reach out to G and it will give the relevant configuration to that particular micros service and then the micros service starts also if you have to refresh the configuration changes the config server can notify the microservices or the microservices can ask the config server for fresh configuration and in that case config server will fetch the configurations again from the git so git is being used behind the scenes by Spring Cloud config server to store and manage the configurations now there are some

    
    03:05:36
    benefits when it when we talk about the cloud config server the number one benefit is storing configurations so it does a job of storing the configurations and providing them so it also serves the configuration so it provides the configurations to the microservices whenever requested refreshing the configuration so refreshing is also one of the features so if there are any changes in some of the configurations you can hit refresh and you can do this refreshing with the help of spring boot actuator so

    
    03:06:11
    not all configurations can be refreshed so some configurations can be refreshed and for some configurations you might need to do a restart like a microservices restart for example if you're changing some configuration like uh the database host URL okay so in that case you might need to restart your micros service because like it's a major change you are simply like changing the database that microservice is pointing to so you might need to do a restart but for other configurations you can simply

    
    03:06:44
    manage with refresh like for example if you're changing the application name so you can hit refresh and there is an endpoint in actuator from where you can refresh and the configurations are refreshed easy integration with spring boot so since it's a part of spring Cloud project the integration with spring boot is fairly simple and easy it also supports different environments and it provides encryption and decryption facilities so these are the benefits and how spring Cloud config server works so in summary spring Cloud

    
    03:07:20
    config server provides a centralized version controlled and secure way of managing configurations across your microservices architecture all right so that's about spring Cloud config server welcome back so let us begin setting up our config server so so to begin with we are going to need a new spring boot project wherein we will be adding everything that we need for that project to act as a config server for our microservices Network or microservices architecture so what I can do is I'll head over to our favorite

    
    03:08:03
    website which is spring initializer and here let us select Maven and here I'm going to say com do a markx here in the place of artifact I'll say config server like so okay so artifact is set and I'll add a description which is optional you can add like I'll say config server and I'll have packaging is jar Java version 17 selected and I'll come to dependencies over here so here in P of dependencies I'll say config so you will see config client so this is to specify the client that connects to Spring Cloud config server to fetch the

    
    03:08:51
    configuration so we are not going to add a client we are going to add a server because there a server that we are creating so Central management for configuration why get SVN okay so I'll select this also we will be registering this particular server with urea so I'll say urea Discovery client as well over here okay so this is what we are going to add and uh yeah let us download all of this you can explore this if you wish to so you can take a look at the dependencies that are created but I'll just go ahead

    
    03:09:27
    and download so this is downloaded here you can see the zip file and now I'm going to extract it over here so we have the extracted version here now what we can do is let us head over to intellig now here in intellig I'm going to go to this Maven tab here so we need to add this newly created project into this project view here so I'll go to Maven I'll say add Maven projects and I'll select config server over here so this is a project I'll say okay and we'll wait so there will be some processing that you see and you

    
    03:10:10
    will see the project appear over here so it is resolving the dependency right now so let it do that and I'll collapse this okay now I'll open the config server here and I'll head over to pom.xml so we have all the dependencies specified now what we need to do is we need to add some properties here in order to get it registered with our urea server so the properties that I'm going to add is let let let me copy this from some other microservice so I'll go to the review micros service and under resources I'll

    
    03:10:51
    copy these couple of so I'll copy this okay so I'll go over here and I'll paste this over here and I'll also copy the application name here so here now I'll update the application name I'll call this as config server like so and we are all set I believe so what we can do now is I will just start this application so I'll go to config server application and I'll see okay so one thing we missed or it is pending so we need to add an annotation over here so I need to say atate enable so you can see this

    
    03:11:35
    annotation here which is enable config server okay so this is coming in from this particular package here which is spring framework Cloud config server and this tells spring boot to treat this particular application as a config server so with this annotation we have now enabled the config server and we have configured everything for this application to work as a config server there is one more thing pending which is we need to configure the get repository for this particular application or the server so that that is something we will

    
    03:12:14
    do soon so that's about this class and I shall see you all soon so we have the config server application created and now is a good time to start setting up our get repository because we'll be needing a get repository using which our config server will fetch all the configurations be in the hindsight so let's head over to to our browser now here I am on github.com so this is something that we will be using to set up a git repository and if you have a git account you can say sign in or if you don't have you can

    
    03:12:57
    hit sign up and you can sign up with GitHub okay so I have logged in to GitHub now depending on whether you have signed up or signed in the journey would be different for both and you will land up on the this homepage and you should see this icon at the top left to create a new git repository or you can even create a repository from here like from the top right so you can use either of the buttons and we will need a git repository to start working with so I'm going to call this git repository AS

    
    03:13:33
    application config like so just make sure that the name is available you can add an optional description you can keep the repo as public so that our application can access and you can hit create repository so the repository will be created now what we need to do is we need to create a properties file which will be read by the config server and this file will be used by config server to provide us with the configurations so I'm going to say so on this page I'm going to click on create a new file okay and you will see this editor

    
    03:14:16
    open up and you can enter the file name as application. properties like so okay and here I'll add a simple configuration so I'll switch over to any of my microservices and you can open any configuration file so I'll open this application. properties and let us copy a configuration this configuration here which is the name and I'll paste it over here okay and I'll hit commit so when we say commit so application so when we say commit the file will be created and you can see this file here and here is what the

    
    03:14:59
    content of the file is so we are done setting up the git repository and we have even created a configuration file which will be then used by our server to provide conf configurations so we now have the kit repository setup with the application. properties file created now let's start using this application. properties file into our config server so here in intellig I will have to make the config server to point to the particular git URL and make the server aware that that this is the URL from where you are

    
    03:15:45
    supposed to fetch the configurations and for that I have a property which I am supposed to add in the config server application. properties okay so here you have to say spring so I'll say spring. cloud. config dos server dog. URL so this is the property that we are going to use and now here so instead of URL I'll use URI so URI is the property and now here you need to paste in the URI so I'll copy this and I'll paste the entire URI over here so just make sure you're just copying the repository URL so this is my

    
    03:16:33
    account and then this is my repository okay so we need to add this and let me also show you what happen happens if you don't add this so if I comment this out so this is commented now and if I run this server so let me run the server so if you run this server okay so here you will see an error okay so the config server won't start and it will say if you're using a git profile you need to add the URI okay so git URI needs to be configured and that is what we are configur ing over here so what it means is config server

    
    03:17:16
    is looking for the URI from where it is supposed to fetch the configurations so we have set this all right now we need to go over here and we need to restart the server okay so we need to uncomment and restart and with this let us head over to our browser and let us refresh the urea server so you will see config server appear in the list now what we can do is we can start accessing the URL here so I'll click on this and you will see this head over to actuator okay so we don't want to go to actuator but we need to go to Local Host

    
    03:17:57
    colon 8080 and now here we can access the configurations now how do we access this so we can say Local Host 8080 and you can see applications here and slash default so what this is going to do is this is going to return the default configurations of the config server so here you can see profile is default and here you are seeing the property sources that are being fetched so this is the name of the like repository this is what you had given in the application. properties file and it is fetching this

    
    03:18:41
    okay and this this is the property that is coming in from the GitHub URL now if you make any changes over here so for example I'm seeing job service over here if I change this to job service temp or toob service demo let's say and if I commit the changes now if I refresh you will see the new property being reflected okay so this is how the configurations have been externalized all right and you can see how we are able to fetch this so now here we are making use of the default profile so you will ask one thing over here why have we

    
    03:19:25
    specified application in the URL it's because application is the file name okay application is the file name and properties is the extension so we have said config server URL slash file name slash d profile so default is the profile right now and you can see the profile appear over here now if you want you can add multiple profiles okay and these files can serve different profiles how would you do that so you can go over here and what I'm going to do is I'm going to add a new file here so I I can go to my

    
    03:20:04
    repository I can say add a file create a new file and I can specify the file name so I can say application now I want this to be development environment file so I'll say Dev application hyphen dev. properties okay this is a file I am creating and I can say commit here you can even add the configuration if you wish to okay so I'll go to application. properties and I'll add the name here okay so here in the repository I'll go to application Dev I'll say edit and I'll add this particular configuration here that I have

    
    03:20:52
    copied now instead of demo I'll say Dev over here and I'll commit the changes so we have this property being added which is job service Dev now what will happen is if we go to this URL if I refresh you will see job service demo this is because we are accessing the default now if I say Dev over here and if I refresh you will see profile is Dev now and you are seeing this Dev profile also being fetched here okay so you can see the name come in over here now here when you access this URL you are also seeing another tag over

    
    03:21:37
    here or one more Json which is of default so default will also come in but you are getting PR as well sorry not prud Dev as well now what we can do is we can replicate the same process for let's say prod as well so I can go to application config I can say create a new file and I can say application ien prod dot properties like so and I can enter instead of T I can say prod I'll commit the changes and now here if you access prod so let me say prod here you will see prod also coming in okay so this is

    
    03:22:29
    right now being fetched from the prod file that we have just created over here okay so this way you can manage your configurations and right now what is happening is config server is is accessing the GitHub URL and depending on what profile you are asking it to load based on that it's loading the relevant profile and the relevant profile meaning it has all the configurations that that particular environment would need to serve well so this is about how you can map your config server to the GitHub

    
    03:23:10
    repository hey there welcome to this class so let us start moving forward with the spring Cloud config server so right now we have the spring Cloud config server which is able to fetch the configurations from the git repository now of course it is able to fetch the configurations but now we need to make use of this configuration from the config server into our microservices so how are we going to do that so for that we need to do some configuration and we need to add a new dependency to our microservices so we'll head over to

    
    03:23:49
    spring initializer project and I'll just delete all of this all the dependencies and I'll say add a new dependency and I'll say config so here you will see config client and this is a client that connects to a spring Cloud config server to fetch the application's configuration so it's pretty clear from this description here as to what it does so after adding the dependency just make sure you have Maven selected and the latest version of spring boot although the spring boot version won't matter because we'll be just copying the

    
    03:24:28
    dependency so you can scroll down here and here you're going to see this dependency which is of spring Cloud starter config so what we need to do is we need to copy this and we need to head over to our IDE and here what I will do is I'll close all the tabs and I'll go to let's say job microservices and here within the job microservices I'll add that dependency and now I'll hit refresh so after making changes to mavin we have reloaded the mavin changes and this should resolve all the dependencies

    
    03:25:12
    without any issues so this is done so all the dependencies are added now now what we need to do is we need to do a little bit of configuration so we need to inform our microservices as to from where it is supposed to pick up the configurations and for that we need to add a small property over here so I'll say config server like so and I'll say spring config do import is equal to config server and I'll add the URL of our config server so the URL in our case is Local Host 8080 so I'm just going to copy this and

    
    03:26:06
    I'll come over here and I'll paste this over here so I'll just remove the for Slash from here we don't need them like so so we are seeing spring config import so import the configuration from config server and what is the config server so this is the config server all right and what do we have in this config server we have the name field so what I can do is I can simply disable the name field here like so okay and now what we are going to do is we are going to t test by getting our application name changed so it is job

    
    03:26:46
    service demo over here so I can make it default so this is the default configuration file or default application. properties I should say so in Dev you have ending with Dev and in prod you have the one ending with prod which is fine so now what we can do is we have commented this now we can restart the micros service so I'll say job microservice let me rerun this okay so we got an error because of the URL here so we need to add forward slash over here and let us try running this after adding the same and now you

    
    03:27:32
    will see our application is up and running so removing these forward slash was a mistake you should keep it over here okay we have it here as well so that was a mistake from my end but here we have the application up and running now you can head over to urea and we can say refresh and now you will see over here the application name is job service default and this is coming in of course from our kit repository where we have specified default here okay now you can head over to logs and you can say contrl

    
    03:28:10
    F here and you can say fetching config so you can see this lock Trace over here so here what happened is when the application was started it started fetching the configuration from the server at Local Host colon 80 and this is a URL that we have specified in the application. properties so it fetched the configuration and it applied the configuration also you can see the profile that was applied was was default here okay if you want you can add your a different profile if you wish to so here so I can add one more property I can say

    
    03:28:51
    spring. profiles do active and I can say def okay you can add any profile for which you have configuration created and if I restart the application you will see this time the profile that will be applicable will be Dev and not default so we will wait for that St Trace to come in so if you scroll up here okay you can see here the configuration was fetched and you can see over here Dev is the profile okay and if we head over to urea if I refresh you will see job service Dev appear over here and you

    
    03:29:37
    can even try this with prod okay here you can even change this to prod and you can restart so this is how you can fetch different profiles and you can work with different profiles so essentially if you have different environments so let's say you have different environments like prodad Dev QA and you have different database URLs and different username passwords for these environments so what you can do is you can have different URLs and different settings created on git and you can fetch them from there

    
    03:30:11
    here okay so it will work this way so this is about how you can change the profiles now I wanted to talk about one more thing over here which is optional so there is one more property that you can add to this particular setting over here so you can specify if you want to make this import of the configuration from the config server as optional okay now how do you specify this as optional so let me give you an example let me shut down or config server so what happens if our config server is unavailable so if I shut down my config

    
    03:30:52
    server and if I restart our job application let us see what happens so you will see we got we got an error here and if you scroll up here you will see IO error which is of course there is no like this is not accessible now right because our config server is down and if you scroll up here you will see this message so could not locate property source and resource is optional resource is not optional so here it says that you have not specified this particular resource which is this particular resource which is not available right

    
    03:31:35
    now and since it's not optional so I I'm not starting the job job service so you can mark this particular thing as optional so you can say optional colon and now if you try to run this also let's say before running we will have this name thing uncommented so because we had commented this so I'll start the application and now if you go at the top here you will see the application is starting here you will see fetching the config from this particular server but this server is not available okay so it

    
    03:32:18
    will try a couple of times here you can see it tried three times and then it will went ahead okay so it tried a few quite a few times you can see not even three times so after this it just went ahead with starting the service now the service is up and running and if you see the name it is simply known as job service because the configuration is not being fetched right now and we are using the local application. properties so this is one scenario that you might want to handle in your microservices

    
    03:32:52
    architecture that what happens if config server is not available so this helps you handle such scenarios all right now if config server is available so if I make this service available again and if I restart the job service so you will see things working as normal without any issues as such okay so job service is also starting now and if you head over to urea service you will see the name is now being fetched from the getup repository so if I refresh I have config server up and running if I refresh again you have job service Dev

    
    03:33:35
    up and running and this is coming in from the git repo and not from the local file here so this is the significance of optional parameter here is what I wanted to highlight and this is very important like if you want to so what will happen typically is if you have multiple microservices and a single centralized config server and if that fails everything goes down so this is not right well you need to have optional parameter as long as you can and that is one benefit of uh getting your microservices Loosely coupled

    
    03:34:12
    so this is about how you can connect or set up Spring Cloud client with your microservices hey there welcome to this class so let us start moving forward with the spring Cloud config server so right now we have the spring Cloud config server which is able to fetch the configurations from the git Repository now of course it is able to fetch the configurations but now we need to make use of this configuration from the config server into our microservices so how are we going to do that so for that

    
    03:34:55
    we need to do some configuration and we need to add a new dependency to our microservices so we'll head over to spring initializer project and I'll just delete all of this all the dependencies and I'll say add a new dependency and I'll say config so here you will see config client and this is a client that connects to a spring Cloud config server to fetch the application's configuration so it's pretty clear from this description here as to what it dos so after adding the dependency just make sure you have Maven selected and the

    
    03:35:36
    latest version of spring boot although the spring boot version won't matter because we'll be just copying the dependency so you can scroll down here and here you're are going to see this dependency which is of spring Cloud starter config so what we need to do is we need to copy this and we need to head over to our IDE and here what I will do is I'll close all the tabs and I'll go to let's say job microservices and here within the job microservices I'll add that dependency and now I'll hit refresh so after making changes to mavin

    
    03:36:20
    we have reloaded the mavin changes and this should resolve all the dependencies without any issues so this is done so all the dependencies are added now now what we need to do is we need to do a little bit of configuration so we need to inform our micros service as to from where it is supposed to pick up the configurations and for that we need to add a small property over here so I'll say config server like so and I'll say spring config do import is equal to config server and I'll add add the URL of our

    
    03:37:12
    config server so the URL in our case is Local Host 8080 so I'm just going to copy this and I'll come over here and I'll paste this over here so I'll just remove the forward slash from here we don't need them like so so we are seeing spring config import so import the configuration from config server and what is the config server so this is the config server all right and what do we have in this config server we have the name field so what I can do is I can simply disable the name field here like

    
    03:37:52
    so okay and now what we are going to do is we are going to test by getting our application name changed so it is job service demo over here so I can make it default so this is the default configuration file or default application. properties I should say so in Dev you have ending with Dev and in prod you have the one ending with prod which is fine so now what we can do is we have commented this now we can restart the micros service so I'll say job microservice let me rerun this okay so we got an error because of

    
    03:38:35
    the URL here so we need to add forward slash over here and let us try running this after adding the same and now you will see our application is up and running so removing these forward slash was a mistake you should keep it over here okay we have it here as well so that was a mistake from my end but here we have the application up and running now you can head over to Ura and we can say refresh and now you will see over here the application name is job service default and this is coming in of course

    
    03:39:15
    from our kit repository where we have specified default here okay now you can head over to logs and you can say control F here and you can say fetching config so you can see this lock Trace over here so here what happened is when the application was started it started fetching the configuration from the server at localhost at8 and this is the URL that we have specified in the application. properties so it fetched the configuration and it applied the configuration also you can see the profile that was applied was default

    
    03:39:56
    here okay if you want you can add your a different profile if you wish to so here so I can add one more property I can say spring. profiles do active and I can say t okay you can add any profile for which you have configuration created and if I restart the application you will see this time the profile that will be applicable will be Dev and not default so we will wait for that St Trace to come in so if you scroll up here okay you can see here the configuration was fetched and you can see over here Dev is the profile

    
    03:40:41
    okay and if we head over to urea if I refresh you will see job service Dev appear over here and you can even try this with prod okay here you can even change this to prod and you can restart so this is how you can fetch different profiles and you can work with different profiles so essentially if you have different environments so let's say you have different environments like Brad have QA and you have different database URLs and different username passwords for these environments so what you can do is you can have different

    
    03:41:20
    URLs and different settings created on git and you can fetch them from there okay so it will work this way so this is about how you can change the profiles now I wanted to talk about one more thing over here which is optional so there is one more property that you can add to to this particular setting over here so you can specify if you want to make this input of the configuration from the config server as optional okay now how do you specify this as optional so let me give you an example let me

    
    03:42:00
    shut down our config server so what happens if our config server is unavailable so if I shut down my config server and if I restart our job application let us see what happens so you will see we got we got an error here and if you scroll up here you will see IO error which is of course there is no like this is not accessible now right because our config server is down and if you scroll up here you will see this message so could not locate property source and resource is optional resource is not

    
    03:42:40
    optional so here it says that you have not specified this particular resource which is this particular resource which is not available right now and since it's not optional so I I'm not starting the job service so you can mark this particular thing as optional so you can say optional colon and now if you try to run this also let's say before running we will have this name thing uncommon Ed so because we had commented this so I'll start the application and now if you go at the top here you will see the application is

    
    03:43:23
    starting here you will see fetching the config from this particular server but this server is not available okay so it will try a couple of times here you can see it tried three times and then it will went ahead okay so it tried a few quite a few times you can see not even three times so after this it just went ahead with starting the service now the service is up and running and if you see the name it is simply known as job service because the configuration is not being fetched right now and we are using

    
    03:43:59
    the local application. properties so this is one scenario that you might want to handle in your microservices architecture that what happens if config server is not not available so this helps you handle such scenarios all right now if config server is available so if I make this service available again and if I restart the job service so you will see things working as normal without any issues as such okay so job service is also starting now and if you head over to urea service you will see the name is now being fetched from the

    
    03:44:41
    GitHub repository so if I refresh I have config server up and running if I refresh again you have job service Dev up and running and this is coming in from the git repo and not from this local file here so this is the significance of optional parameter here is what I wanted to highlight and this is very important like if you want to so what will happen typically is if you have multiple microservices and single centralized config server and if that fails everything goes down so this is not right well you need to have optional

    
    03:45:17
    parameter as long as you can and that is one benefit of uh getting your microservices Loosely coupled so this is about how you can connect or set up Spring Cloud client with your microservices hello and welcome so let us start talking about what is an API Gateway so before we talk about API Gateway let us do a recap of the basic premise of microservices so in microservices architecture the monolithic application is broken down into small Loosely coupled services and each service corresponds to a specific business

    
    03:46:06
    functionality and can be developed deployed and scal bu independently so here you have three microservices okay and they all serve a specific business purpose and they are independent now as you can imagine when we have numerous Services interacting with one another and client applications the complexity of managing these interactions increases significantly and this is where the API Gateway comes into play so now since we have multiple microservices we have a problem so what is the entry point for

    
    03:46:44
    our application and how should we interact with it so each and every microservice will have different service URLs from where they serve their specific functionality but for a user a user does not care about your underlying structure so for user your application is a single entity as a whole and it has to function as a whole behind the scenes you can have multiple services serving each functionality that is fine but for a user the application is a single unit and not multiple microservices tied

    
    03:47:19
    together so the question for a user or from a user perspective is what is the entry point for me into your application because everybody has their own host URLs so I need a single entry point and that is where API Gateway comes into picture so you can think of API Gateway as a special type type of reverse proxy or something that Roots the request from the client applications to the appropriate microservices and it acts as a single entry point for the external client request now this simplifies the

    
    03:47:56
    client side experience and it also hides or masks the internal complexity to the external world so API Gateway serves this particular purpose and they are very useful when it comes to microservices architecture so let us talk about some of the advantages that we have with API gateways so the number one advantage is the encapsulation so API gateways encapsulate the entire system architecture and provides a level of abstraction between the client applications and your backend microservices this means that changes

    
    03:48:35
    made to the microservices such as adding new microservices modifying existing services and even changing the service locations can be done without impacting the client so imagine like you have a microservices architecture and you change something and somebody was accessing that URL from outside the architecture like for example a client or an external application or something so that application will break provided it's dependent on that service so you need to mask these changes and for the out side

    
    03:49:10
    World it should be like nothing has changed in your system so how do you handle that and API Gateway can help you with that so with this Advantage API Gateway encapsulates the entire internal system architecture the next Advantage would be to handle cross cutting concerns like security load balancing rate limiting and analytics now these things are important when it comes to microservices or building any application so essentially you can have API Gateway handle all of this and basically the microservices can be free from such

    
    03:49:46
    things okay so you delegate all of that responsibility to API Gateway the next Advantage would be authentication of incoming request so this is also part of security which we spoke about so API Gateway can also authenticate incoming request and after authentication the valid requests are only provide given to the service okay okay so this allows to have a authentication on the entire microservices network it can even aggregate responses from different microservices so let us say client needs something and you need

    
    03:50:26
    to collaborate with multiple microservices in the hindsight for getting that response so API Gateway what it can do is it can communicate to multiple microservices collate the response and give it to the external client so this can be done by API Gateway and it can help you reduce the number of trips or round trips between client and server and this can greatly improve the performance and the user experience particularly in mobile applications where Network latency can be a significant issue so this way API

    
    03:50:59
    gateways play a crucial role and the role of API Gateway is really crucial in simplifying the client side of interactions and managing different concerns so this is the importance of API Gateway as to why it's needed in microservices let us start talking about the functions of API Gateway so there are a few core capabilities that API Gateway brings to your microservices architecture the number one is request routing so the primary function of API Gateway is to Route request to appropriate microservices and it acts as

    
    03:51:44
    a single point of entry and routes each incoming request to the right service this not only simplifies the client side but also abstracts the complexity and the details of the underlying services for the client load balancing now this is another feature or the ability of API Gateway where an API Gateway often incorporates load balance B ing to distribute traffic across multiple instances of a particular service now this helps improve responsiveness and availability of applications so if a service is scaled

    
    03:52:23
    up by adding more instances the application the API Gateway can distribute requests evenly across all instances the next one would be authentication and authorization so security can be one of the major concerns when it comes to microservices or any application in fact so API Gateway can authenticate the client credentials and then forward the request to the right service rate limiting so this is one more ability that API Gateway can help you with so API Gateway helps you protect your services with the

    
    03:53:01
    help of rate limiting so essentially what rate limiting means is limiting the number of requests a client can make to any given service in a given amount of time that is what rate limiting is and this is done to prevent overuse abuse or prevent any attacks on your services then you have request and response transformation so if you need to transform your request or response so API Gateway can act as a middleman and once it gets the request it can transform the request and send it to the respective site aggregation of data from

    
    03:53:38
    multiple services so API Gateway can aggregate the data from the multiple services or microservices that exist and it can unify the response and send it to the client so this is about the capabilities of API gateways and you can see it performs a variety of functions that can make it easier to manage a microservice architecture it provides a central place essentially where majority of the functions are handled and they can common across different services so this is about API Gateway now what are

    
    03:54:15
    we going to do and how are we going to implement API Gateway so here is how we are going to implement API Gateway into our microservices project so we have the microservices network or the microservices here so these are three microservices one is the review microservice then we have job and then we have company these microservices have their own database okay and they all communicate with the config server urea server and the Zipkin server now we are going to add another layer of API Gateway which will be responsible for

    
    03:54:53
    routing the external requests so whenever you request anything in your application whether it's a mobile app or from it's from a client which is on a desktop so these requests are given to API Gateway and handled by API Gateway and then API Gateway will route those requests to the appropriate microservices depending on what the client is asking for so this is the function that we are going to implement and this is what our architecture is going to look like so excited so let's jump into the details welcome to this class so let us

    
    03:55:39
    start talking about how are we going to actually Implement an API Gateway into our microservices architecture so we are going to take help of spring Cloud Gateway so if you search for spring Cloud Gateway on Google you're going to land on this URL which is the first URL here and it is the official website of spring.io so this is the official page of spring Cloud Gateway all right and it's a part of spring Cloud project as you can see here so we will be using this and you can take a look at different features as well that it has

    
    03:56:17
    to offer us so you can see it offers a circuit breaker integration it is built on Spring framework five and it is able to match routes on any request attribute and it offers predicates and filters as well so we are going to work on this and we're going to integrate this into our application okay and how are we going to implement so this is what the architecture will look like so you will have this microservices here we will have three microservices is what we have right now along with their own copies of

    
    03:56:53
    database along with a config server urea server and Zipkin server with which they communicate and then we are going to have a spring Cloud Gateway setup like this which is going to take care of all the request so without a further Ado let's get started so now let us start setting up the application Gateway for our microservices architecture and we are going to make use of spring Cloud Gateway so let us head over to Spring initializer and here I'll change the artifact and name over here so I'll say

    
    03:57:40
    artifact as Gateway and name is automatically changed so description is this is Gateway so I'll just have description as Gateway you can have any description you want that's perfectly fine you have package name automatically generated packaging jar and Java 17 just make sure you have selected mavin here and a valid or relevant spring boot version now I'll remove this from here so I need to start adding the dependencies so what are dependencies that we would need for our Gateway project so the first dependency I'm

    
    03:58:21
    going to have is urea so I'm going to register this particular service with urea I'm even going to have the Zipkin dependency so Zipkin is another dependency that I wish to have over here okay and then I'm going to say Gateway so you can see here spring Cloud routing which is Gateway and this is an simple and effective way to Route apis so this is what I have added now if you go to explore here you're going to see the palm. XML being generated and this is the dependency that we are adding for this project to act as a Gateway so this

    
    03:59:06
    is a dependency that will do the magic so this is added now what we can do is we can download the entire Source over here so I've downloaded the file and here you are going to see gateway. zip so I'm going to unzip this file here extract here you will have the unzipped version and now let's import this into intellig so here in intellig I'm going to go to Maven and and I'm going to add this project to this particular view so I'm going to select Gateway here and this project gets imported so now we have a

    
    03:59:49
    project here in this particular view all right now what I will do is I will go to the application. properties so we have all the dependencies set I'll hide this sidebar so we have all the dependencies set we need to head over to application. properties to do the relevant configurations and I'll get some configuration from Job Service here okay so I'll copy all of this and I'll paste the configuration here okay we will remove everything that is irrelevant for example this is irrelevant the database

    
    04:00:25
    part we don't need this even postgress SQL part is irrelevant here okay now here I'm going to call this as Gateway like so and this is going to run on Port 8084 so this is going to run like any other spring boot application but it is going to do the job of routing the request to the relevant service whenever a request is coming in from the external client so now here we have some settings related to urea which we are going to keep as it is we have Zipkin sampling rate as well which is fine we have

    
    04:01:05
    config server so we don't need config server here in this particular application. properties file so basic configurations are done now we need to set some routing logic so I have the routing logic written in a notepad file over here okay so we need to add this to our application. properties so I'll copy this and I'll paste it over here so I'll say Gateway like so so this is a logic related to the Gateway routing now what does this mean over here so here we are setting routes which means this is a

    
    04:01:45
    logic as to how the request from a Gateway is routed so for example we have this first route set over here and this has three parts one is ID URI and the predicates so you can see this is the first route and you can see this with the help of index now the ID over here is company service the URI is this and here we have added the path okay so ID is nothing but the unique identifier that is given to the route okay and this field can be anything as long as it's unique amongst all your routes okay so here we have everything unique so

    
    04:02:29
    company service is unique job service is also unique then we have the URI part wherein this is the address of the backend service that this route will forward request to for instance this particular service company service so any request to this service will go to this route then you have predicates so this is a list of conditions that an incoming request must meet to match this route and each predicate will have such pattern over here which is used for matching and if the match is true then the request is forwarded to this

    
    04:03:05
    particular micros service and then you have more routes that we have defined over here okay so essentially here in terms of predicates we are specifying in this format okay and this is like a inbuilt predicate sort of thing so here you can see here we are using two stars for pattern matching and this is a wild card that matches any sequence of characters so for example company SL1 SL2 anything will be matched to this particular route as long as it has come company in it okay so that is what this

    
    04:03:41
    means same goes for job and same goes for review so if you take a look at our jobs review and Company microservices so if we go to the controller here so in controller the entire controller is mapped to/ jobs okay and then the rest of the part keeps on changing okay so what we have done is we have said slash jobs here okay so if you scroll up here we have slash jobs and here we have SL jobs so that is how it matches but I noticed a small mistake over here so here we are saying jobs so here also we should have jobs so it's

    
    04:04:23
    plural and let me check the same for review as well so I'll head over to review here also I'll go in review controller you will see it's reviews so essentially it's PL plural over here so we need to change it to plural and not keep singular so I'll go to company as well and we'll just verify so here also it's companies so we'll keep this plural okay so so yeah this should work now and I have specified the port as well so this is the setup done for spring cloud AP Gateway okay so we have the project

    
    04:05:11
    setup and we have the necessary configurations done that we need our gateway to function properly so that's about this class I shall see you all soon thank you so our Gateway server is set up and configured now what we can do is we can add some configurations to our application. properties of Gateway way to enable some behind the scenes so what I would be doing is I would be switching over to notepad here and I have some properties written here so I'll copy these properties and I'll paste it over here

    
    04:05:53
    like so now what do these properties mean so these properties are used to set the logging level of various components of our application so this first part logging level root is equal to info this sets the default logging level for all the loggers in our application to info and this means that any logging statement by default with the level of info one or error will be output in your application's log okay and then we have the next statement over here which says like logging level spring framework

    
    04:06:31
    Cloud Gateway route definition locator is set to info now what does this mean so this particular line sets the logging level specifically for Route definition locator class in the spring Cloud gateway to info okay now we have the third line as well which is which sets the logging level for spring Cloud gateway to dat of trees So within this aug. springf framework. cloud. Gateway all the classes will have the logging level of Tres and this is very detailed level of logging that includes debug set

    
    04:07:07
    statements as well so this is what we are setting in okay this is going to help us understand what is happening under the hood so we have the configuration done for Gateway and our Gateway is ready so what I'm going to do is I'm going to head over to our main application and I'm going to run Gateway so we are going to have Gateway added over here as a a service and now if we head over to our browser and if you head over to urea server and if I refresh we will see Gateway being added as one of the

    
    04:07:51
    services that exist in our microservices architecture now so now since we have the Gateway up and running it's now time to test this so I'll switch over to postman here and what I'm going to do is I'm going to create a new collection over here and I'm going to call it as Gateway now what will this collection have this collection is going to have the URLs that will point to the API Gateway what URLs should I take over here so I'm going to expand the company microservice over here so this company

    
    04:08:27
    microservice collection and I'll duplicate The Collection or duplicate the API to create a new company I'll duplicate the API to get a new company and I'll move them both over here okay so we'll use this duplicate method because this will save some time like we just have to change the port number so this will help us save some time so that we can move faster and here I'll take two so I'm taking only two requests into Gateway so we'll be testing Gateway with only two requests so we'll do a post request and then

    
    04:09:08
    we'll do a get request so that will give us enough idea as to how Gateway is working so I've moved them both and these both are copies so review is done now we can do for job so for job microservice I'll duplicate this one and here I'll duplicate the get one so this one and then the get one here right so now I'll collapse everything I'll close this now let us change the port and everything for all the requests so we'll start with the companies okay so I'll say 8084 SL companies and I'm going to copy

    
    04:09:53
    this URL and add it over here okay so this is modified and I can hit save now I can even trigger this particular API and get the company created so let us even do that so as say send and you will notice that we have sent the request from 8084 and you will see that the company is created over here now the moment we triggered this API request if you head over to intellig and if you select Gateway application over here and if you scroll up you will see lot of logs that we have enabled over here okay so one log that I

    
    04:10:37
    so so here you can see the match happening so 8081 8084 SL companies okay and if you scroll up here so you can see this line over here so pattern SL compies star star matches against this value SL companies and this is how the forwarding works so essentially whenever request comes into Gateway the pattern is matched against the configuration that you have specified and then it is forwarded to the relevant URL okay so you can see and learn from these logs here so we will get back to postman now here in Postman I'll start modifying

    
    04:11:17
    my other apis also so I'll just copy or let us copy this entire port number and I'll update this here and also I'll copy the entire URL and paste it over here now if I try to get companies this API is also going to work okay so I had one company already added and I added one more now here if you go to reviews we need to do the same thing in fact we need to do the same for all the requests over here okay so I'll just do this for everything now this is a get request and we have one review existing over here

    
    04:11:58
    okay but you can also play around with the post request if you want to so I'll just trigger a post request as well so here I'll say send and you'll see review being added successfully from the Gateway port and let us do the same for jobs as well so I'll say 8084 here okay so I'll have to type in it seems and I'll copy this URL and I'll paste it over here like so and for this URL also I'll change this to 84 and I'll copy Cy this and I'll paste it over here so we are done with the changes now let me post a job so

    
    04:12:43
    I'll post a job and you can see job has been added successfully and I can get the job so you can see we're getting like job company reviews and everything and there are a couple of jobs that have been added here okay so indeed it is working perfectly fine there are no issues as such all right what you can do is you can right click over here and say close all tabs and say save changes to all the pop-ups that come in so it will save all the requests for you in Postman all right now I wish to show you one

    
    04:13:22
    more thing over here so if you go to so here we have urea server running now I wish to show you Zipkin as well so you can say sekin here and you can go to this dashboard all right and you can say run query now you will see few requests that we have triggered just now and this was the request that we triggered last and this is from the chob API I believe right so if you say show over here you can see how the request flowed so the request first went to the API Gateway and then from there it went to jobs company

    
    04:14:03
    service review Service Company service review service and then we got the final result so all the requests are now being routed via Gateway and you can take a look at different requests over here if you take a look at company request so this is the API request to create a company and we went through API Gateway here so you can see Services it touched is two total spans that exist were three and this was the trace ID all right so you can go over here here and you can just play around and see so every

    
    04:14:41
    request is now going through Gateway if you say expand all you will notice this okay so Gateway is indeed in action and now the benefit over here is you have this single URL Local Host colon 8084 and you can give this URL to anyone okay and this URL SL jobs is for jobs microservice slash company is for company microservice SL reviews is for review micros service but this detail that there are different microservices for different functions is only for you like you don't need to expose this to the entire world right so there is one

    
    04:15:18
    single URL over here and if you deploy this onto a server or something you can have a domain name mapped over here and then it will work seamlessly so external users don't won't know actually what is happening behind the scenes because there is only one URL that that is taking care of of everything so this is API Gateway in action for you I would request you all to play a bit around with this one and go Hands-On a little bit and understand as to how this is working so that's about this class thank

    
    04:15:51
    you and I shall see you all soon hey there welcome to this class so we have our spring Cloud Gateway server ready and we have already done some configuration that we need for Gateway to function properly now here I wanted to talk a little bit about HTTP versus lb so HTTP is the standard HTTP protocol wherein you use this as a part of the request and all the request that you trigger go through the HTTP protocol okay and the services using HTTP are located directly using the URL and you specify the host and Port there so this

    
    04:16:40
    is something that we are aware now what does lb mean so lb stands for load balanced and this is specific to Spring cloud and it indicates that the service should be located via a load balancer so let me give you an example here we have a job service and we are using HTTP over here so let me remove this HTTP and I can have lb over here now lb means load balanced is what I mentioned now when you use load balanced in a URI it means that Gateway would use the spring Cloud's service Discovery mechanism to

    
    04:17:19
    locate an instance of the service okay and usually when you use lb you cannot use the host and the port number but instead you have to use the service name over here or the service ID so here if we go to urea this is the service name that we have so I'll copy this and I'll come over here and I'll paste it over here now why would you do this over HTTP so I'll tell you one reason so here HTTP is good if you have a single instance of microservices running but when you have multiple instances for example let's say

    
    04:17:56
    you have 10 instances of one microservice running then in that case you need to load balance the request now what I mean by load balanced you need to make sure that the requests that are coming to that particular microservices are distributed evenly across all the instance that are active right now so for example for job service if you have 10 instances up and running so let's say this service is getting a lot of traffic and we have added multiple instances and in that case which instance should get the traffic so

    
    04:18:31
    that is something that is decided by load balancer but to configure it you need to give this over here so you need to have lb colon the service ID so in that case the disc Discovery will happen with the help of service ID now under that service ID there can be 10 instances running and the request will be distributed evenly so here with HTTP you are specifying a specific instance over here so I want my request to go to this instance but here you are just saying I want my request to go to this service now it does not matter how many

    
    04:19:11
    instances for this particular services are running because in this case there will be one more instance or there might be one more instance of company service running but there is a possibility that that instance is running on a different port so that won't be utilized or that won't be called so when you use service ID that is the benefit that you get now let us test this so we have load balanced this particular thing okay and what I will do is I will run one more instance of job microservice over here

    
    04:19:44
    but the question is how do you run one more instance so you can't just right click and rerun you don't have any option here so instead you need to go here at the top you need to say edit configurations you need to select the configuration for job microservice so here these are all the Run configurations for our services so I need to to D at this so I'll say copy the configuration a duplicate is created and now I'll specify a distinct name for this particular configuration here so let's say our job microservice is

    
    04:20:20
    running at 8082 so I can run this at 9082 like so now how do we run this so in order to run this we will have to pass some extra parameter okay and why do we have to pass this so I'll just say apply and I'll say okay so here if you come to the job service properties you will notice that we are we have specified the port number over here all right but the instance that we are running now we want a custom Port so we don't want to go with 8082 Port so we need to overwrite this during the runtime how do we do that so in order to

    
    04:21:03
    do that you need to click on modify options you need to say add VM options and here you need to say hyphen T server dot Port is equal to 90 82 so this is an extra parameter that you are passing during runtime and that will be taken care by intellig okay now I need to hit apply here just make sure that you hit apply and you say okay now you have one run configuration over here so you need to select that and you need to say run now the moment you do that you will see a new run configuration or a new

    
    04:21:48
    service appear over here and hopefully there should not be any errors okay so you can see the registration is successful 2 not4 and the application is up and running okay so we have now two instan of job microservice running so I'll switch over to urea now and let us refresh and see what happens so here for now without refresh you are seeing one service ID and one instance over here which is running on this port if I say refresh can you see there are two instances now that are up and running okay now if you go to

    
    04:22:32
    postman I can actually call any of the in inst so I can hardcode the instance port number and the host over here and I can call so if I do a call to 8082 it will go to the first instance of jobs if I change this to 9082 it will go to the second instance of job but we don't want to handle this okay round robin so what we will do is we'll send the request through Gateway so now here if I say get job the job is empty of course so I'll create a job and I'll try getting it so here now you will see from the user

    
    04:23:14
    standpoint I'm interacting with the Gateway URL and for us I don't know like we don't know like in back end how many instances are running okay so I just need to interact with Gateway and the request is load balanced which means that depending on the load Gateway is going to distribute the requests that are coming coming to different instances depending on the traffic all right I hope this is making sense so the job of making sure that the load is distributed evenly is taken care by Spring Cloud

    
    04:23:50
    Gateway over here and you can go to your browser open Zipkin and you can say run query and you will see over here so you can go over here you can select this and you can see this particular request is so if you select the jobs URL here so here we are not seeing the port yet but idly if you see the port over here you would have got the idea as to how it's working but what I want to show you is for us from the user standpoint it's working perfectly fine and we are not aware of what is happening so here you

    
    04:24:30
    can see the port number see 8084 and if you send a lot of requests you will see some request request going there as well so it is distributed depending on the load okay so we don't need to worry about this but we have Zipkin and all the tools to get an idea of what's happening so in general if you use HTTP you know the exact host and Port of the target service and you know it won't change but when would you use lb or load balanced if you want to use the service Discovery and load balancing mechanism of spring cloud

    
    04:25:07
    which is more flexible and robust in microservices architecture so now I'll come back to our project and we will update this for everybody so we can like change this lb colon or I'll just copy lb here and we'll make everything load balanced and now I need review service I'll copy the review service here like so and I'll paste it over here I can go for the company service as well and I can paste it over here so I'll paste it over here done now I can restart all my services and test the changes so it should work perfectly

    
    04:25:56
    fine but now we have moved from HTTP to load balancing for our microservices so that's about HTTP and lb thank you so we now have all the requests being routed via our API Gateway and we making use of spring Cloud Gateway for this now there is one thing still left so if you head over to our browser here if I head over to urea urea URLs is still some other port number and it is not yet going through Gateway way so what you can do is you can even route urea server from the API Gateway that we have configured now how would you do

    
    04:26:45
    this so to do this I'll head over to our configuration file over here which we have created for API Gateway so right now I'll switch to Gateway application. properties and I have it open here so here we need to add a few more routes to configure the urea server so I have those routes written over here so I'll simply copy them so I'll copy this first three lines and let us add these first three lines so what have we added so we have added urea server here we have pointed it to this URL so this is a URL where

    
    04:27:28
    our actual server is running and then we have specified the path where we want to access so if I copy this path and if I head over to the browser and if I say Local Host 8084 so I'll say 80 84 and if I go to urea SL main I'm going to get an error and this would give an error because the request is redirected to urea SL main on 8761 Port so it's being redirected to slash main over here like so we don't want to do that okay okay now how do we tell the route to transfer the request to the root URL over here so if you look at the

    
    04:28:13
    configurations over here what we have done is if the request is coming on 8084 SL jobs it is simply being routed to 8082 SL jobs so this path is not changing over here for any of the microservices that we have but for urea server there is a need for us to change the path over here now how do we do that so we can do that with the help of filters over here so we need to take this filter thing over here and I need to paste this over here so this tells that whenever the request is being routed it does not need to be routed to/

    
    04:28:55
    urea SL main but instead it is supposed to go to/ root URL when you are calling 8761 or when you are routing the request to 8761 that is what it means okay now let us try running this and let us see what the output looks like so I'm going to restart my Gateway application and let us wait for this to turn up meanwhile we'll head over to urea server and I'll hit refresh so it's not there yet and it's there now so Gateway is up now now what I can do is is I can refresh this URL so Local Host col 884

    
    04:29:41
    urea main so you can see here we are seeing the urea server as well over here okay so it is working perfectly fine okay in case if you don't see the CSS and HTML being loaded so I have one more piece of code also written over here so you can simply add this to load all the static files okay so what you can do is here at the bottom you can add this as well if the static files are not being loaded now what I mean by Static files is files like JavaScript CSS and some basic things or basic elements that

    
    04:30:21
    beautify a particular web page so if that is not being shown to you you can add this as well so essentially your file would look something like this okay so you would be adding these two things into your file all right and I've added this even if I restart it would work perfectly fine for me but for me I'm seeing the CSS already being loaded so that is not a problem here now but if I refresh the connection is refused because the service is not yet started so Gateway is down so if I refresh from here now you can see we are

    
    04:31:00
    seeing the urea server being loaded from the Gateway URL and this is amazing because now you have a single URL for everything so if someone is doing some Administration related work and if he needs to access urea server he does not need to go to the actual urea URL but instead you as an application developer can configure the gateway to show urea server as well so there is only one URL now that is being exposed to the outside world isn't that amazing yes it is so that's the power of spring Cloud Gateway

    
    04:31:37
    that's all from my side thanks a lot hey there welcome to this class so let us start talking about fall tolerance and understand what it is and why is it important when it comes to microservices so in distributed microservices there will be scenarios where something or the other fails and it's really important to manage these failures and this is where fall tolerance comes into picture so what is fall tolerance so fall tolerance can be defined as the ability of a network or a system to continue operating without any

    
    04:32:24
    Interruption so this is what fall tolerance means now the question is why does this matter much to microservices so in microservices world we have different systems so it's a distributed system where each service is running on its own and there is a possibility that one service might fail so there are three microservices as you can see over here and it's part of an architecture and to outside world it is one single application it is not three different systems it's just single system that exist now what happens is usually the

    
    04:33:05
    these microservices will be communicating with each other and in such scenarios there can be possibilities that one service fails so let's say microservice 2 fails now because of that all the calls that would go to microservice 2 would fail and this would result in entire system collapse which is not good so this means that our network is not fall tolerance so if something goes wrong our Network work or our application should actually continue operating so how do you make your architecture or application fall

    
    04:33:44
    tolerance so this is where the need of this concept comes into play and let us talk about some needs so if we have to highlight some of the needs number one thing would be fault isolation so failure in one microservice should not lead to complete failure of entire application so if one micros service fails the failure should be restricted only to that micros service and that is where this false isolation comes into play and this is one of the reason why we need fall tolerance the network latency so microservices communicate

    
    04:34:24
    over a network and there can be possibilities where there can be Network failures and there will be several issues wherein the network call might just not happen and in that particular case we need to take care of the network latency and this could lead to failure there could be deployment issues so since microservices are deployed separately so if you have three micros Services those three will be deployed separately as separate application now because of deployment there is a likelihood that there are some issues that have

    
    04:35:04
    encountered during the update of a microservice and because of this that particular micros service might be down for a little while now this is where the problem comes in so how do you handle such scenarios so this is where fall tolerance also matters increased complexity if there are several microservices in your architecture or your application it could lead to increased complexity and it could also lead to unforeseen failures which you cannot gauge as a developer and this is where fall tolerance again is important

    
    04:35:40
    lastly we have elasticity and then we have tolerating external failures so elasticity talks about how well can microservices often scale independently based on demand okay so if you make your microservices resilient enough your microservices can scale easily without causing any disruptions and then tolerating external failures so in this particular case microservices might interact with external services or apis or databases like for example I might be using Twitter API or I might be using some API

    
    04:36:20
    which allows me to convert a text to PDF or something like that so it could be any external system that I am interacting with and if that system goes down then that microservice which is using that particular system will be impacted and in this particular case like you need to handle these things gracefully so these are the needs as to why fall tolerance becomes important when you're building a distributed system it becomes really evident like you need a concept like this when you are building something as complex as

    
    04:36:54
    microservices so this is about fall tolerance and why something like fall tolerance matters when you're building something as complex as microservices welcome back so let us start talking about resilience 4G and we will also discuss resilience 4G modules features and we will even cover some techniques when it comes to adding resilience to your network so before I talk about resilience 4G I wanted to spend some time talking about what you mean by this word resilience so what is resilience ience resilience is ability or capacity

    
    04:37:39
    of something to recover quickly from difficulties so when we talk about microservices fall tolerance in our network is really really important so fall tolerance in our architecture makes sure that we are resilient enough to failures and this is where the concept of resilience comes in so resilience exists to add fall tolerance in our microservices architecture and there are a few techniques patterns that helps us deal with failures that happen in our system because we need to ensure that our system can handle these

    
    04:38:17
    failures gracefully of course when you're building microservices you cannot avoid failures so not only microservices when you're building any kind of systems like failures can just happen it just comes with it but the best part is you should be able to handle them gracefully and this is where these techniques come in so let us talk about some techniques there so the number one technique is retries so whenever you have a request to a microservice that fails due to some temporary issue like and issue can be

    
    04:38:51
    like Network timeout or resources unavailable or something what you can do is the client who is making the request can automatically retry the request a certain number of times okay so if I make a request to microservice B okay and I'm micros service a so if B is down or there is some issue with B now I made a call to microsof is B and the call didn't went through so I can decide to retry the request for certain number of times and these retries can help improve the chances of a successful request

    
    04:39:31
    especially when the failure rate is due to some temporary issues like Network latency or something like that so there is a possibility that if I do a second or a third retry the microservice is up and running and my request is successful so this is about retry and this is one of the techniques that exist so this way we have avoided the fault that would have happened in our Network or our architecture and we have made our system resilient so this is one of the technique another technique I want to

    
    04:40:06
    talk about is rate limiting so what is rate limiting so rate limiting controls the number of requests that a microservice can handle within a specific time frame so it prevents the overload on the service and ensures that there is a fair usage of the resources within that microservice so every microservice or every system that you have has a capacity and rate limiting makes sure that the requests that are going to that particular microservice in a particular time frame matches the capacity and it

    
    04:40:41
    does not overshoot the capacity so rate limiting is useful for protecting against some excessive traffic or potential attacks like denial of service okay so this is about rate limiting you have bulk heads so bulkhead is a pattern it's about isolating different parts of the system to pre prent a failure in one component from affecting others and in microservices this means dedicating a separate resource for different services and if one service experiences High load or fails it won't impact others so this

    
    04:41:21
    is bulkheads then you have a technique called circuit breakers now what is circuit breaker so circuit breakers monitor the health of the microservices and they prevent the cascading failures so if there is there are two micros service let's say micros service a and micros service B and if B fails so because of the failure of B it won't impact a so if there is a request that is going to B circuit breaker will make sure that it handles gracefully now how this is handled is when a service repeatedly fails or experiences High

    
    04:41:57
    latency or something the circuit breaker trips and the subsequent requests to that particular service are redirected to any fallback that you must have declared or the error response okay and this avoids overloading or struggling service or provides a degraded but functional experience and it makes sure that the application does not breaks so this is about circuit breakers then you have fallbacks now what are fallbacks so fallbacks are alternative actions or responses that are provided when a microservice is unavailable or it fails

    
    04:42:33
    to just respond now now fallbacks can be predefined okay so you can have default values or like default responses from Cas cach a or some secondary data sources and this way you can create fallbacks for your service so fallbacks ensure that users receive some response even when the primary service is unavailable and this helps prevent failures which would have occurred if fallbacks were not present so this is one way of handling or one technique of handling failure then you have timeouts now what are

    
    04:43:08
    timeouts so timeout is the amount of time a client who is making a request will wait for a response from a micros service okay that is what timeout is so if the service does not respond within the specific time period the client can take the desired action like which is defined such as retrying the request or using any fallback so alternative path can be anything depending on the microservice but yeah you can retry essentially or you could have fallback or anything like that so this is what timeout

    
    04:43:43
    is then you have graceful degradation now what is this technique So Graceful degradation refers to the ability of a microservice to continue functioning with reduced functionality when facing issues or high load so non-essential or resource intensive features can be disabled or simplified to m maintain essential Services only okay so this is what graceful degradation is and this helps prevent failures and ultimately makes sure that our architecture is able to tolerate faults and ultimately makes

    
    04:44:20
    our architecture resilient enough now how do you implement all of this so this is where we can talk about resilience 4J so resilience 4J is a lightweight easy to use for to to an Library okay because managing these patterns that we just spoke about can be a challenging tasks and that is where resilience 4J comes in so resilience 4J is a simple Library which you can add to your project it is very lightweight and has minimal dependencies and is specifically designed to be used with spring boot applications so this is the best part so

    
    04:44:59
    resilience 4J also has key modules such as retry circuit breaking trade limiter and so on okay now we discussed why it's a good choice so it has easy integration with spring boot so it has a starter Library which you can add to your project and you are ready to go then it is built for functional programming Paradigm and this is a programming Paradigm that is introduced in Java 8 and this makes this Library great fit for modern applications all right so this is why it's a good choice now let us talk about some of the resilience 4J

    
    04:45:37
    modules that I would like to introduce you all to so the number one is the retri module we have rate limiter then we have bulkhead and circuit breaker let us talk about retry module so it is not uncommon for a network call or a method invocation to fail temporarily and this failure could be because of Network glitches or any other issue so rather than failing immediately we might want to retry the operation a few times before giving up and this is where retry module from resilience 4G comes into picture so

    
    04:46:16
    retry module enables to easily Implement retry logic in our application so you just need to do some configuration and add a annotation and you are good to go then we have rate limiter so when we have a service that can handle only only a certain number of requests per time period so we need to ensure that we do not exceed that limit otherwise the service will be overloaded and it will go down and this is where rate limiter comes into picture where rate limiter allows you to enforce these restrictions

    
    04:46:52
    and protect our services from too many requests then you have bulkhead module this module is based on bulkhead pattern and it isolates failures and prevents them from cascading through the system okay so the idea here is to limit the amount of parallel executions or concurrent calls to prevent system resources from being exhausted then you have circuit breaker module now this module is used to prevent a network or a service failure from cascading to other services so this way you can add resilience to your

    
    04:47:30
    network so if a circuit breaker trips or opens then this particular module prevents the further call to that particular service and ultimately it makes your architecture fall tolerant so this is about resilience 4J their modules and some of the techniques that we have learned in this lecture hey welcome back so let us start talking about what is circuit breaking so what I'm going to do is I'm going to head over to google.com in my browser and I'm going to search for resilience 4J so resilience 4J and the moment you Google this I'll

    
    04:48:19
    zoom in a bit so you are going to see this first link which is resilience 4g. readme.io dos so just hit this link and I'll visit this URL and you will see this documentation open up app okay so this is the official website of this particular Library here and you can read more about this particular Library like it's a lightweight fall tolerance Library designed for functional programming okay so you have a lot of information here you can just go through if you wish to okay it talks about the core modules that this library has and

    
    04:48:59
    on the left hand side you have a sidebar where you can see core modules like circuit breaker bulkhead rate limiter retry and so on okay so you can just explore this website but what we are going to talk about now is circuit breaker so I'll just head over to the circuit breaker and you will see this link open up over here now you can see a diagram over here so now what is circuit breaking so circuit breaking is a mechanism that is used in microservices architecture to avoid cascading failures across multiple Services because of that

    
    04:49:39
    one service now why is it called circuit breaker because it implements the mechanism that is similar to that of electrical systems so in electrical system you have a circuit that is that can be closed so if it's closed the electricity flows and if it's open the electricity stops flowing okay and that is how this particular thing works so here you can see there are different states so you have closed State open State and half open state so closed State meaning the system is healthy and there is nothing that has failed now

    
    04:50:20
    what happens if anything fails so if anything fails there is a failure rate that is associated so you can see failure rate happens and then there is a threshold that is configured with the system so if the failure rate goes above a particular threshold the circuit moves from close to open so this means like this transition from close to open means that something is wrong in the system and the subsequent calls to that particular microservice won't be done because there is an issue so what I mean over here is

    
    04:50:58
    let's say you have microservices a and microservice b and if a is making call to B and let's say if B is down and if there are like multiple failures which are above the threshold then all the calls to the microservice B won't happen because the circuit would move to open State okay and that is what circuit breaker is so now it's moved to open now how does it move back to closed and how are we permitting calls then so if it's in open there is a weight duration so you can see over here after weight

    
    04:51:32
    duration so there is this weight duration for which it stays in the open State and after weight duration is done the circuit breaker then moves to half open now what does half open mean so in half open State a certain number of calls are allowed so a limited number of calls are allowed to pass through the circuit so what this means is if I was making call from microservice E to B and the circuit moved to open State now after certain wait time it moved to like half open and in half open state if my

    
    04:52:10
    system is configured to permit three requests in half open state so only three requests will be permitted to that of microservice B and because these three requests are permitted system gets a chance to understand if this particular microservice B is back up again and if it's back again what happens is the circuit breaker State then moves from half open to close state so here you can see failure rate below threshold so if it's back up again the failure rate drops to a value below threshold and then the circuit changes

    
    04:52:46
    back to closed so essentially how this works is if there is a failure in a micros service there is a circuit breaker that exists which makes sure that the call is not sent to the microservice which has failed so it controls essentially the a failure and it makes sure that failure is contained to that particular microservice only and not a system as a whole so that is what circuit breaker is and this is how the circuit breaker works so this diagram is really important and it demonstrates how the states transition depending on what

    
    04:53:25
    happens in the system okay so this is about circuit breaker hey there welcome back so let us start talking about how can you integrate resilience 4G with spring boot so to do that I'll head over to our favorite website which is spring initializer and I'll select Maven here and I'll click on ADD dependencies and I'll say resilience 4G over here so you can see this dependency come up and you can hit explore so you will see this particular dependency has been added so this is a dependency to implement circuit breaker

    
    04:54:16
    into your application as you can see so I'll copy this and we will head over to our project so now in this project what I'm going to do is I'm going to add this particular configuration that I have copied to p home. XML of jobs so I'll go to the dependency Tab and I'll paste the thing that I have copied now here I'll add one more dependency so I'll say dependency and I'll say group ID is or. spring framework. boot so I'll select this and here okay so it got populated so Maven plug-in got autop populated so

    
    04:55:05
    I'll just remove this and I'll say spring putot starter and I'll get aop so I'm adding this dependency to add a support for aspect oriented programming okay so I've added this and yeah everything looks okay now I'll hit reload M changes and this should resolve all the dependencies and and your application should be up so what we have done is we have configured resilience 4J to work with job microservice and in the subsequent lectures we will start implementing its working hey there welcome back so let us

    
    04:55:58
    start configuring the circuit breaker into our application so what are we going to build actually is we have multiple microservices so we have job microservice communicate to company microservice and it does so VI the controller so here if you go over here so so not in control actually we should go in the implementation class here and here you can see we are calling the company service here okay so here if you go to map company with d we we are mapping the company objects and we are calling the company as well as reviews

    
    04:56:40
    in fact using this method call over here and this is with the help of company client so job microservice is interacting with company microservice so we are going to implement a circuit breaker with job and Company for this particular communication all right now what are we going to begin with is we are going to begin starting our microservices so just make sure your microservices are all up and running you should also see the status of all the instances over here now let us try accessing the actuator so I would want

    
    04:57:21
    you all to go to the job microservice select pom.xml and make sure that the dependency for actuator is added here and this is because we will will be using it to monitor the health so if you go to job microservice here we will go to Local Host we will say 8082 and I'll say actuator now here if you go you will see the health endpoint that has been enabled so I'll just open this health endpoint now you are not seeing much of the information about health so we need to enable the detail heal information

    
    04:58:05
    which will enable us to get different application metrics so let us head over to our intellig idea project and I'll switch over to application. properties here for job micros service and I'll scroll down here and I'll add a comment here I'll say actuator okay and I'm going to add some actuator configuration so I'm going to say management. Health dot sorry not Health I'll say management. endpoints do web. exposure do include is equal to health okay and then I'm going to copy the same thing here and instead of web

    
    04:58:54
    exposure I'm going to just say health dot show details and I'm going to add always over here so what these two property does is these this is exposing the health end point in the actuator and this is adding a lot more details to this particular endpoint and the reason for this is we want to show much more information about our application Health like how many number of requests are happening how how many are failings and so on okay so we will be using these metrics to monitor as to what is happening with our our

    
    04:59:33
    micros service okay and we'll be understanding whether circuit breaker is actually working okay so I'll head over here so without those configurations we had only up okay okay we have not restarted the micros service so what I need to do is I need to select job and I need to say rerun over here so okay so the micros service is restarting so we'll wait until it restarts and we'll check the status here in urea so the job service is up and running now let us head over to actuator SL health and let us see if detailed

    
    05:00:18
    information has come up so I'll hit refresh okay so we are not getting the detailed information it still says status up let us see what mistake we are making here okay so I should remove s from here so so it is management. endpoint do health. showy details so this was a mistake there was a s over here which I removed and I'll rerun this application so just make sure if you're are adding this you don't have any typos okay because if you have any typos it won't work as expected so just be sure of that now I'll head over to my browser

    
    05:00:59
    and let us hit refresh okay so the refresh is done and you can see the detailed information about your application now all right now what we need to do is we have the actuator Health endpoint enabled and this health endpoint will enable us to see the circuit breaker details as well all right and that is the reason why we have enabled this so now we need to start configuring our circuit breaker so in order to configure the circuit breaker what I'm going to do is I'm going to add add few configurations into

    
    05:01:35
    my application do properties and I actually have these configurations added here in this notepad which I'm just going to copy so I'll copy all of this for resilience 4J okay and I'll get it pasted over here all right and I'm also going to copy this part okay so this is the actor configuration so these two points we have already added okay okay and this is the third one and we'll go through what what each thing means but for now I'll just copy this in the end okay and I'm going to go to write here and I'll say

    
    05:02:16
    here now I'll remove these two which we had added previously all right now let us understand what this means okay so there is a meaning in everything and every property means something on the other so here what we are doing is we are are specifying some configuration to create a circuit breaker so this property says register Health indicator all right but first of all we are creating a circuit breaker with the name company breaker here okay this is the name so when we say company breaker. register Health indicator is equal to

    
    05:02:53
    true so this property registers a health indicator for company breaker circuit breaker okay so company breaker is the circuit breaker instance that we are creating here so you can see circuit breaker do instances do company breaker so this is the instance that is being created and it is being registered in the health indicator and this can be accessed via the health endpoint which we have enabled over here all right so this is a reason why we enabled Health end point now the next property says sliding window size so sliding window

    
    05:03:31
    size defines the number of calls stored in the sliding window of the circuit breaker and this is used generally to calculate the percentage or failure rate all right so we have kept it to 10 then we have minimum number of calls so we are seeing minimum number of calls as five and this defines the number of calls that can be recorded before the circuit breaker can calculate the failure rate okay so to calculate a failure rate we need some calls right we cannot calculate failure rate on zero calls so that is what this number

    
    05:04:09
    defines so we can customize this as per our requirement so this is one then we have permitted number of calls in half open State and we have set that to three so the circuit breaker can go in open closed and half open State now half open state is a state where you can permit some number of calls before circuit breaker can decide to transition back to open or close State all right so half open is a state in between and essentially you are configuring the number of calls that can be permitted in that particular state so we have

    
    05:04:46
    mentioned three over here you can customize this as per your requirements but for learning purpose we have set it to three then we have weight duration in open state so this property determines or controls how long the circuit breakers should stay in open State okay so in open State the calls that are being sent to the microservice are rejected okay and we have specified this to 10 seconds then we have failure rate threshold so this defines the threshold when exceeded the circuit breaker will transition to open okay so here we have

    
    05:05:26
    seeing 50 which tells that if the failure rate is more than 50% the circuit breaker will transition to the open State all right then we have register Health indicator is equal to true so this property is similar to the first property that we have set okay so it will register the health indicator into the actuator or the health end point then we have automatic sliding transition from open to half open enabled so this property enables circuit breaker to automatically transition from open to half open State okay and then we

    
    05:06:04
    have the sliding window type okay so this determines the type of sliding window and we are saying that we want Count base which means that the last end calls are recorded and they used to calculate the failure rate where n is the size of the sliding window okay so this is just the window type that we have determined so these are some properties that we have like added and you can also add the this one more property here which we have added to the actuator configuration which says circuit breakers enabled true in health

    
    05:06:42
    now what this means is this will enable the health check for circuit breakers in the actuator all right so these are the configurations now if you head over to browser and if you go to the resilience 4G documentation if you click on circuit breaker here here on the right hand side you're going to to see create and configure the circuit breaker and if you click on this you will see this table here and this is all the table that has all the configuration that you can Define so you can see over here failure

    
    05:07:17
    rate threshold it has the default value as well and the description as to what this task so if you want to customize anything you can customize over here so you can see here sliding window type is Count based you can even set it as time based okay and you have different number of properties so you can go through this if you wish to so this is for additional exploration but now what we have done is we have configured the application. properties now let us create the circuit breaker so what I'm going to do is I'm

    
    05:07:55
    going to head over to the controller here not controller so we will need to implement this in the service implementation class so what we are going to do is we are going to go to get all jobs so this is the method which helps us get all the jobs from the database all right and this is the one that Maps it to DS so what I'm going to do is I'm going to add an annotation over here to this method and I'm going to say circuit breaker here okay and here I'm going to say name and the name will be company

    
    05:08:36
    breaker like so so this is the same name that we have added in the applications. properties okay so not this one but this one which is for jobs so this is the name that we are adding over here okay so yeah so what we are seeing is circuit breaker is to be enabled on this particular method here and this is a method that enables us to get the list of all the jobs okay and if you scroll up here you can see from where this annotation is coming in so this is coming in from resilience 4J circuit breaker.

    
    05:09:17
    annotation and this we are getting because we have added the dependency so this is about the configuration and uh creation of circuit breaker in our job application welcome back so let us see the changes we have done in action so we have added a circuit breaker into our application for getting all jobs method here and we have also done a lot of configuration in our application. properties so if you have not restarted your application I would request you to go to Services Tab and rerun your job application so that

    
    05:10:00
    you can get these changes to effect now let us go to our browser and let us see all these changes so here in browser I will access the actuator SL health and I will hit refresh over here now the moment you hit refresh you're going to see under components you're going to see this tag here which says circuit breakers you'll see status up and you'll see company breaker which we have just created in our app application along with this you are going to see some details of this so here you have different properties like

    
    05:10:40
    failure rate now what is failure rate failure rate is the percentage of recent calls that have failed and if you have this negative value like minus one or something like I'm seeing this indicates that there have not been enough calls yet to calculate a meaningful value and this is because we have just restarted the service then we have failure rate threshold so this is the percentage of failures at which circuit breaker will switch from close to open State and in this case if the value is more than 50% it will fail

    
    05:11:17
    or it will open then you have slow call rate which says the percentage of recent calls that were slower than the configured threshold now again negative means there has not been enough data to calculate yet slow slow call rate threshold so this is 100% And this is the percentage of slow calls at which circuit breaker will switch from close to open then we have buffered calls and this dictates the total number of calls that the circuit breaker has recorded in its ring buffer and this includes the

    
    05:11:53
    total number of calls like the successful as well as failed then you have slow calls which keeps a track of so slow calls that have happened failed calls so these are slow failed calls so these are calls that have been slow as well as they have failed so slow as in they have been slower than the configured threshold then we have failed calls and not permitted calls so failed calls are the total number of calls that have failed and then we have not permitted calls so if the circuit breaker is open

    
    05:12:27
    then the calls won't go through right because circuit breaker will reject so this is that number so total number of calls that have not been permitted and then finally you have the state of the circuit breaker so this can be closed open or half open depending on the time you are accessing it so this is our circuit breaker details that we have and we will be using the actuator Health endpoint to monitor this now we have all our services up and running here so if you head over to Postman and if I go to

    
    05:13:04
    job microservice so we have to go to 8082 Port and let us try getting all the jobs so if I send this request I get an empty call so let me create a few jobs and before that I'll create a company I'll create a review here against that company so that we have some data to work with and then I'll create a job as well now if I try to fetch jobs I'll see like the details of the job along with company and review now if I come back here and if I access health endpoint you will see there have been two calls that have happened okay

    
    05:13:49
    and you can see there are zero calls that have not been permitted and that is because the state of the circuit is closed all right now let us make our company service go down okay so the circuit breaker is between the job microservice and the company microservice so if the company microservice goes down and if our failure rate happens to be higher than that of threshold the state should change to open so let us try that so I'll head over here to intelligy and I'll turn down the company microservice okay so the micros service

    
    05:14:29
    is down and it's removed from urea registry okay now let me do a API call so I did one call so of course this is failing and if I refresh our endpoint you will see buffer calls three and Feld calls one okay now let us send this request again for some time okay so I have done like five six calls now and if I refresh you will see failure rate is 60 state is open and failure rate threshold is 50% which we had set okay so circuit state is open now if I refresh it goes to half open state after 10 seconds because that is

    
    05:15:21
    what we have configured in our application okay so this is now half open and let me do a call now so if I do a call it won't go through if I do one more it won't go through let us also check the logs here okay so if I refresh this it's still in half open and if I check logs here so job microservice so here for job microservice if you scroll up here you will see an exception here so here in the logs of job microservice you can search for call not permitted exception okay so if you you can sayr f

    
    05:16:04
    if you are on Windows and command F if you are on Mac and you can enter this call not so if you just enter call not you will find this call not permitted exception so what happens is whenever the call is not going through or the circuit is open then you get this exception over here because call is not permitted because the circuit is open and you can see the reason also over here okay now what we will do is we will turn back our company microservice up again so let's say company microservice was down for a

    
    05:16:39
    while there were some issues with the micros service and developers worked hard to fix this and bring the service up now you will see if I refresh this is still half open which means there will be certain number of calls that will go through the circuit so if I send this request again it gives me error if I send this again okay it will give me error because there is no company there now so I'll create a company and I'll try getting the response so I'll say get and this works now so if I come back here and if I

    
    05:17:17
    refresh you will see failed calls have become zero now like in like recent duration buffer calls one and state is still half open so this will go to close state after some time after after we have some X number of successful calls so I did one successful call I'll make couple of them and I'll come back and I'll hit refresh over here so you will see there have been now certain number of successful calls and that is the reason the state is now changed to close because the circuit breaker now assumes

    
    05:17:56
    that the service is back up since the calls have been successful and that is why it's allowing now all the calls so so this is how the entire process of circuit breaker works okay so you can see how different parameters were working when a particular service was down and how our configuration also gave us a better control to configure different options here so you have multiple options here you can like change anything like you can even change the weight duration if you want weight vition to be higher or lower okay you

    
    05:18:34
    can have minimum number of calls configured and so on so you can play around with these settings a bit and depending on the use case you can get this applied to your production applications so this is about circuit breaker in action all right I hope you all enjoyed this class and found it valuable I shall see you all soon thank you welcome back so let us start talking about the fallback mechanism so here whenever a microservice is down like when our company micros service was down and if we tried sending a request we got

    
    05:19:15
    an error over here okay and circuit was set to open but it's not a good thing to show an error to the user so let me simulate this scenario again for you so I'll stop the company microservice and I'll try sending in this this request so you can see we are getting an internal server error for jobs okay and here the circuit will be open all right so this over here is not a good thing so you showing errors to your users so you can easily prevent this or control this by using something called as a fallback mechanism now what

    
    05:19:57
    is a fallback mechanism so fallback mechanism is an alternate path that you have to show to the user Whenever there is a failure of an microservice and you can implement this with the help of circuit breaker so let us head over to intellig and let us implement the same for this scenario here so here in intellig I'm going to head over to circuit breaker over here now here we have passed one parameter which is name I can pass one more and I can call that parameter as for fallback method now here I can define a fallback method so I

    
    05:20:36
    can say company breaker fallback so I can have this definition created over here now what I can do is I will have to Define this particular method okay so I'll copy this method name I'll go over here and here I'm going to say public and let's say I just want to return a simple list of string values and the method name is this okay now I'll have let's see I'll I'll have some code defined over here so I'm just returning the list of a simple string as a fallback over here so I'll say list string and here I'll say l list is equal

    
    05:21:24
    to new array list and now I'm going to say l do add I'll add just some dummy information so I'll call it dummy and I'll return l or I'll return list so this is the implementation here all right now this will also have a parameter exception e okay which we have added so this is the fallback method that we have created now one thing to keep in mind is to keep this names similar okay so just make sure that this name that you have specified here in with The annotation as the parameter matches the name of the

    
    05:22:08
    actual method all right this is where a lot of people go wrong and then it does not work so I'll restart my job microservice and let us see what the output looks like so our job micros service is up and running state is closed now let me hit the URL over here so just for your information the company microservice is still down so I'll say send so we don't have any jobs so we need to create a job in order for a request to go to the company ID so I'll say send and now here since the company microservice is down we are seeing dummy

    
    05:22:51
    over here okay and this is the message that we have given in the list so this is the list that we are getting over here okay so here we are clearly not getting any error and if you send this like four five times and if you head over to this particular endpoint you will see failed calls four not permitted calls two and the state is open so not permitted calls is two because two calls were not permitted because the circuit State changed to open after repeated failures but the best part is this over

    
    05:23:30
    here you're not seeing any errors so if there is a failure and if you want to handle failure gracefully in front of the users you can have some dummy response created or you can have some alternative database or something from where you fetch in some information and give it to the user so that at least the request Loop is closed and user does not see any error messages all right so this is the benefit of adding fallback and if you go back to intellig you will also see we are not getting any any errors

    
    05:24:02
    here okay so so this is about the fallback method and how you can get this implemented into your microservices along with circuit breaking welcome back so let us implement the retry mechanism with the help of resilience 4J so we have already seen how circuit breaking works and resilience 4J also provides one more way or one more technique called retry with the help of its retry module so we will be implementing that and retries are simple yet effective way to add resiliency into our system so what is retry if any

    
    05:24:49
    network call fails we will be retrying that Network call to see if we can succeed and we can do all the configuration as to how many times we want to retry and what should be the duration and so on so to begin with what I'm going to do is I'm going to just comment this out here okay so I'll select this and I'll comment this out now I'm going to add a new annotation over here and I'm going to say retry here like so and if you scroll up here you will see this is also coming in from resilience 4J library that we have

    
    05:25:28
    configured now we need to add the details so here I can say name is equal to so I'll say company breaker so we'll add this similar details here okay I'll just paste it over here okay and this should work so let me remove this comment from here so yeah retry is configured for this particular method here now I want to demonstrate how retry works so what I'm going to do is I'm going to create a temporary variable over here I'll say integer attempt and I'll initialize this to zero now I'm keeping this variable over here

    
    05:26:11
    or I'm creating this variable to keep a track of all the retries that are happening all right so what I'm going to do is I'm going to say over here system.out.print Alin and I'm going to say attempt and I'm going to say attempt okay and I'm going to increase the value of attempt so for every method call here we do the attempt value will increase and it will print the same onto the system so we have implemented the retrive functionality now let us head over to our application. properties and let us

    
    05:26:51
    do some configuration over here all right so here I'm going to say so this is since this is the configuration for resilience 4J I'm going to here and I'm going to copy this entire thing okay and I'm going to say instances. company breaker. Max attempts all right and I'll delete all of this and I'll remove all of this the rest of the part and I'll say Max attempts can be five so here I'm configuring the maximum number of attempts that we will be doing if the network calls fails so I'm mentioning

    
    05:27:33
    this to five now I'll copy this and I'll paste it over here and I'll add one more thing over here which is the weight duration so I'll say weight duration like so and I can say weight duration as 2 seconds so weight duration specifies the duration for which we will wait before making the next Call and Max attempt is the number of attempts that we will do so now I'll restart this service here okay now let me restart the job micros service so after starting the job microservice just check whether the

    
    05:28:12
    service is up in urea also I have the company server down now what I'm going to do is I'm going to head over to postman I'll create a job and I'll do a request to fetch the job okay so something happened here the request is not loading so I'll just close everything and I'll just select this now I'll try getting the job so when we trigger the request now we got a dummy response all right now let us head over to intellig and see what the output looks like so here in intellig I'm checking the logs for job application and now

    
    05:28:51
    here if I say attempts so you can see attempt one attempt two so you can see attempts have happening for the request over here and the application is trying to fetch the data from the company microservice all right so retri module is indeed working now and we are seeing our changes based on this particular configuration all right so this is about the retry module and how you can get this implemented into your project hey there welcome back so let us start talking about rate limiting what is it and why is it needed in modern web

    
    05:29:40
    applications so what is rate limiting so rate limiting is a technique for limiting any networks traffic so it sets a limit on how many requests a client can make to a server in a specified amount of time so in other words it's a way of controlling the rate at which and an application or a system uses resources okay so this is what rate limiting is now if I have to give you an example an example would be an API might have a limit of th000 requests per hour and if you exceed this rate the server would return a response which is like

    
    05:30:20
    something like 429 and this response with status code of 429 stands for too many requests so a website might have a rate limit for account creation to prevent some spam accounts being created and you can only create one account every 10 minutes from a single IP address so if this rate is being exceeded it's likely that there are fake accounts or some spam accounts being created so these are some of the examples as to where rate limiting can be used now what is the importance of rate limiting so rate limiting can be

    
    05:30:57
    crucial for several reasons so the number one reason reason could be preventing abuse so without rate limiting a malicious user can overload a server with request causing it to slow down or crash so this is one of the reasons as to why rate limiting is important resource allocation so by limiting the number of requests you can ensure that resources are distributed fairly amongst all users cost management so if your server or API is is hosted in cloud and you pay for the amount of traffic it handles rate limiting can

    
    05:31:36
    help you keep costs under control these are few points as to why rate limiting would be important in today's applications now what are the use cases of rate limiting so the number one use case is of apis so in API world to prevent a single user from making too many requests apis often use rate limiting so this protects the server from unwanted load and ensures Fair usage web scraping so there is a possibility that web scraping people might be doing web scraping onto your website so sites might use read limiting

    
    05:32:17
    to prevent web scrapers from overloading their servers login attempts so to prevent Brute Force attack websites often limit the number of login attempts from a single IP address so so you must have seen this message that uh maximum number of login attempts exceeded and retry after like 5 minutes so so that is rate limiting in action so if there are maximum number of failed login attempts from a single IP then a website might block requests from that IP for a certain period of time and this is to

    
    05:32:52
    secure the website and your account so these are some of the use cases of read limiting now there have have been some real world incidents of Doos so what I mean by Doos is denial of service and DDOS stands for distributed denial of service attacks so distributed denial of service attacks are where multiple systems flood the bandwidth of a particular system and they try to take it down okay so you will have one server that you are targeting and you will Target that one server from multiple places so there's no single IP from

    
    05:33:31
    where the request is coming it is coming from multiple servers and one of the most notorious attacks that has been of this type has been with GitHub in 2018 so they have even written a blog post on this so here in browser if you search for like GitHub DDOS so you will land on this link here and you can see this happened on February 28th and they have acknowledged that this is something that happened okay due to dist distributed denal of service attack and they have also given as to how what happened

    
    05:34:05
    exactly and why this incident occurred so you can see the server load went suddenly up you can see over here and they have posted everything so yeah so this is about a real world example okay and GitHub was hit with a massive uh attack and this attack took GitHub down for some time all right so GitHub was not working so they have mentioned it over here GitHub was unavailable for this much of time okay so this is about the real world incidents of denial of service attacks so now the question is how can we build resilience into our

    
    05:34:43
    applications to prevent these kind of things so you can do this with rate limiting feature of resilience 4J so resilience 4J is a lightweight library and you can use the rate limiter module as to control to how many times a method or client can call your service in a given period of time and this is really useful in microservices architecture where you need to control the number of calls to prevent your service from being overwhelmed so this is about rate limiting and I hope you have a fair understanding of this concept

    
    05:35:22
    now welcome back so let us start implementing the rate limiter module so since we have resilience 4J configured into a project resilience 4G has a module called rate limiter as you can see over here on the left hand side so you can click on this and you can read more about rate limiter and how rate limiter works now if you scroll down here you will see this table here under create and configure rate limitter so this table gives you the configuration that you can add in your application. Properties or within your application

    
    05:36:00
    to get rate limiter configured so you can see time out duration and the default value is 5 Seconds and this is a default wait time a thread waits for a permission you have limit refresh and then limit for period so this is the 50 so limit for period means the number of permissions or number of calls that are allowed during one limit refresh period so there are 50 calls that are allowed for now okay so let us head over to our application and let us start configuring this so here in intellig I'm going to

    
    05:36:35
    paste some values here okay for rate limiter which I have already written so these are the values so I'm saying resilience 4J do rate limiter and I'm saying instances company breaker time out duration I'm specifying as zero okay so this is the default wait time a thread will wait to acquire permission to run when the limit is reached so I'm setting it to zero then I have limit refresh period so limit refresh period is the period after which the limit is refreshed and you have the limit for period set to two so what this means is

    
    05:37:15
    the rate limitter will allow two calls every 4 seconds for us now if more calls are made within that period they will be immediately re rejected without waiting now why without waiting because the time or duration we have specified is set to zero so if we specify the time out 0 to 5 seconds or 2 seconds it means that the more calls if they are made within this period they won't be immediately rejected but they will be made to wait for that particular duration all right so this is our configuration and what I

    
    05:37:50
    will do over here is I'll now head over to services and I'll now restart my job application so our application is started now now we'll head over to our browser and now we need to simulate this scenario so we need to have a way to simulate these many requests to our server and for that we are going to make use of a tool called jmeter I'm just going to search for jmeter Okay so jmeter is nothing but a load testing tool for analyzing and measure measuring the performance of variety of services so so with the help

    
    05:38:30
    of jmeter you can simulate a lot of requests on your application or on any endpoints so you can go to Apache gometer and you can say download and you can download the zip file from here so I have downloaded the Apache J emitter Here and Now what I can do is I can head over to the unzipped version so after downloading the zip you can unzip it and here in bin folder you'll see this file Apache jmeter dojar which you need to launch so it'll take some time to launch for the first time but then it'll open a

    
    05:39:13
    window like this okay so here now we can right click on this test plan on the left hand side and we can say add a thread group okay now we can specify a number of five over here in the number of threads and we will save this so I'll just minimize this so thread group is created now I'll say right click on thread group and I'll say sampler HTTP request okay now here is where we will be simulating this request so what I'm going to do is I'm going to head over here and I'm going to copy 8082 so here I'm going to enter the

    
    05:40:01
    details so I'm going to say HTTP server name is Local Host port number is 8082 and then we will have to enter the path so I'm going to go to postman and I'm going to copy slash jobs here and I'll say jobs here and I I'll make sure that the request type is get here okay so this is done now I'll say say add now once you have created this you will see this start button over here at the top so just click on this green button and it will say you should save this particular thing so just save this by clicking on yes so you can save it

    
    05:40:47
    with any name now after you have saved you can click on this request you can say add and you can go to listener now here you can see view results tree so now here we can run this and we'll see all the results so you can see all the requests are being sent right now okay and nothing seems to be failing so all the requests worked properly and none of the requests were blocked so here you're seeing green requests meaning all worked properly so we are missing something so we'll head over to our source code and

    
    05:41:26
    here we have configured properties but if you go go to the service implementation we also need to add an annotation over here so what I will do is I'll disable this annotation and I'll say at the rate rate limiter so this is something that we missed okay and I'm going to copy this same information here okay so we have rate limiter named company breaker and that is what the name that we have specified over here company breaker and I have like added a fallback method as well now let us redeploy our application so what I'm

    
    05:42:08
    going to do is I'm going to rerun the job application so the application is running successfully now if we can head over to the Apache jmeter and I can right click on this view results tree and say clear so this will clear everything and then I can run this again so now if I run I I'm still not getting the desired result so if I say if I change the number of threads to 10 and if I run this okay so if you select the request here okay you will see sampler result over here and if you select the request

    
    05:42:48
    tab you will see the request that is being sent and here you will see the response that is being sent that is being received I'm sorry so you can select two of the request and you will see this response but if you select the third you'll see dummy over here okay which means that after second request the request is not being entertained and the fallback method is being shown all right now if I remove the fallback so if I go over here and if I go to implementation here and if I remove the fallback let's say for example okay and

    
    05:43:26
    if I save this and I'll restart the service so let us see what happens if you remove the fallback so in this particular case the request was working it just was it was not showing it over here so everything was green but it was shown in the response data all right so I believe the service is up and running so we'll create a company and we'll create a job and let us see if it's working so it's working fine now we'll go to rate limiter and I'll clear the results and I'll run the rate limiter again okay so

    
    05:44:07
    now this time let us see what happens so again you're getting dummy despite removing the fall back so here what you can do is you can select any request here you'll see the sampler results you can go to request and then response data so here you will see the response that you're getting from the request so you can select one two and if you select third one you'll get dummy asy response which means this is not working and it is being returned all right so this is rate limiter in action hey there welcome to this class

    
    05:44:50
    so let us start talking about this concept of message cues so what are message cues and why are they needed so let us talk talk about the need and let us understand a scenario wherein message cues would be important so let us say we have this two service one is the job service and then we have a review service now these two services are communicating by exchanging a message right so they have a request that is being sent from a job service to review service and the request has some message that is being consumed by the review

    
    05:45:27
    service now let's say say if a review service is down then in that case job service won't be able to communicate with review service and it will start getting the error now here for job service to talk to review service review service has to be up so the communication between the two is synchronous okay so because of this synchronous communication there is a dependency that is being added into the architecture now how do you decouple these services and how do you decouple this communication so the answer is by

    
    05:46:06
    implementing something that allows you to do asynchronous communication and how is that possible so that is possible by adding a message CU like this so message cues play crucial role in microservices architecture to facilitate communication and data exchange between different microservices so you can see in the diagram over here we have job job service that wishes to communicate to the review service and we have a message cue here in between so a message from the job service will be left in into the

    
    05:46:40
    message queue and then review service will consume this particular message so that is how this entire process works now if review service is down that is completely fine because if the message is sent by job service that message will be stored in the message queue for a while and then when VI service is ready it can consume the message once it is ready to consume until then the message will be there in the message Q so that is what message Q is now why is there a need of message cues so the number one

    
    05:47:14
    reason is decoupling so message cues enable decoupling between microservices meaning that each service can Now operate independently without needing to know the specific details of other services and services can communicate through messages sent via the message CU making them more independent and losely coupled the next need would be to facilitate asynchronous communication so like I said message cues support asynchronous communication patterns where Services can send messages and continue processing without waiting for

    
    05:47:53
    an immediate response so in our case if job service does not need an immediate response and and if it just wants to send some data to review service it can just send the data in the message queue and just forget it so it does not have to wait for an immediate response or an acknowledgement and this is especially important in scenarios where certain operations might take some time and are not that critical for immediate response scalability as microservices can be deployed and scaled independently

    
    05:48:29
    message cues will help manage the communication between the services without overwhelming them with direct request so you can think of them as a buffer allowing services to process messages at their own pace and scale independently fall tolerance so message cues provide an additional layer of fall tolerance so if a micros service is temporarily down or unreachable the messages are stored in the queue ensuring that they will be processed once the service is back up then the next need could be event driven

    
    05:49:08
    architecture so with the help of message cues you can enable event driven architecture into your microservices now this is a way where Services can publish events to the queue and other services can subscribe to these events and react accordingly and this makes it easier to implement even driven patterns and respond to changes in the system time decoupling so message cues allow services to process data at their own pace and this is particularly useful when dealing with Peak loads or when Services have varying processing speed

    
    05:49:47
    so in such scenarios there is time decoupling and microservices don't have to wait since the other microservice is taking some time now let us Define message cues so what what is a message CU so a message CU is a form of asynchronous servico service communication that is used in serverless and microservices architecture now messages are stored on the Queue until they are processed and deleted and each message is processed only once by a single consumer now when it comes to message cues there are couple of terms

    
    05:50:25
    that you should be aware of so here in this diagram I have jobs service which is sending a message to this particular message queue to which both the services are subscribed so job servic is subscribed to this service sorry this message queue and then review service is subscribed also to this message CU and job service publishes a message and review service consumes the message so in this case job service is known as a producer and review service is known as a consumer so what is a producer then so

    
    05:50:58
    producer is a service that creates messages and adds them to the queue so they are just responsible for producing or publishing the data so anyone who produces anything into the message queue is known as a producer so this is one of the terms that you are supposed to be aware of and likewise what is consumer so services that process these messages or consume them are known as consumers and they read or consume the data and usually delete the message from the queue once the processing is done because that message need not stay there

    
    05:51:35
    in the queue now when it comes to message cues there are quite a few message cues that are available in the market which you can use for your next project so I'll discuss a few of them so the number one and the most popular out there is rabbit mq so here I'm on the official website of rabbit mq and rabbit mq is widely used open-source message broker software now what is a message broker so message broker is nothing but a piece of software that enables asynchronous Communications so rabbit mq supports

    
    05:52:13
    wide array or broad array of developer platforms and languages making it quite versatile and it's a good choice for complex applications that require High reliability and flexibility in message routing so you can go through the features that message rabbit mq has okay you can see there are quite a few features and you can just browse through the website if you wish to know more about rabbit mq then you have Apache Kafka so Apache Kafka is another one okay which is quite popularly used and you can just browse through the website

    
    05:52:51
    to learn more about Kafka and you can see this is the website then you have Amazon sqs so this is a queuing service that is managed by Amazon okay so you don't have to install it but this is in the cloud and you can use it so this provides serverless options for applications okay and uh you can go through its feature so you can check out this website and if you just Google Amazon sqs you will land on this page then you also have active mq which is also like a popular Java based message broker so there are quite

    
    05:53:31
    a few in the market now the question is how do you choose which one to use so there are various factors that influence this decision of choosing the message broker of your choice the number one is scalability so if you need to handle large amount of messages per second you can consider using some service that is in cloud like sqs or Google has a queuing service as well so you can consider using that the next point would be reliability and if your use case requires highly reliable delivery then you can consider

    
    05:54:05
    using rabit mq or Apache active mq now both of them have strong message durability and delivery guarantees okay then the next factor that you can use for considering and evaluating is simplicity so if you need something that is really straightforward easy to use solution then you can go for cloud-based services like Amazon sqs and so on so they have simple interfaces and managed infrastructure you don't have to take care of or manage them essentially so Amazon will manage it for you then the next Factor would be cost so rabbit mq

    
    05:54:42
    like I said is open source okay and you can run on your own server for free while cloud-based services like Amazon sqs are usage based costs so if cost is a constraint you can choose something that is open source for your project so every message CU software has its strengths and tradeoff and the best choice depends on your specific needs and what kind of uh application you are building and whether you are willing to spend and if you're not willing to spend then are you willing to manage everything so so that's the choice that

    
    05:55:19
    you need to make so that is about message cues I hope you found this valuable and I shall see you all soon thank you hey there welcome back so let us talk about a scenario wherein we can understand more about message cues so we have already created Job review and Company microservice so what are we doing is now we are creating a job using the job endpoint but while fetching we are fetching the job company as well as the review so what if we want to create the company and review as well from the

    
    05:56:03
    jobs post request so that is completely possible what you need to do is you need to add some extra parameter and some extra Json over here that will represent the company and review and the job controller or job service will do the job of routing the objects to the respective microservices and then once the communication is done the company and the review are both created okay so this is completely possible and you can implement this but if you are implementing this without message cues so the issue is if company or review are

    
    05:56:43
    down or they are slow then job will have to wait for a response right so if we create a job over here we are getting 21 created so if company and review are part of this request then this request is not complete unless and until company and review have been created as well so in that case jobs API or job micros service will wait for an update whether the request has been successful or not from the company and reviews microservices but if they both are slow then this will also go slow and this will probably end up

    
    05:57:21
    waiting for a long time and possibly time out so in that particular scenario so what you can do is you can have a message queue that can save the message here until the company service is back in action and then it can consume the message from here so that is completely possible and you can implement this with the help of message cues now the question here is why aren't we using fallback methods so we have a way using which you can Implement fallback methods and if there is any issue with the microservice then fallback methods can

    
    05:57:58
    come into action so why do we need message cues then fallback methods can act as a replacement of message cues right no so fallback method is a different concept and it can work together with message CU but it's not a replacement there so fallback methods provide a alternative path for execution if something has happened to the service okay but with message Q message cues facilitate a synchronous process in so if there is some issue with the service the message stays there and it can be consumed by the service once it's up so

    
    05:58:37
    it can solve the problems like Services down or Services slow so client does not need to wait until unless it gets the response it can just publish the message to the queue and forget it there is one benefit of message queue then we have things like decoupling and reliable message delivery so fallback methods are different when we compare them with message cues they are not the same so this is one of the frequent questions that students ask me that we can use fallback methods instead but to clarify

    
    05:59:10
    they are not the same so that's about the importance of message cues and fallback methods hey there welcome back so let us start talking about what are we going to build with the help of message cues so we have a review service and we have a company Service Company stores the company related information and then we have review related information being stored in the review service now reviews are managed by review service and these reviews belong to companies but what happens if a new review is added so a new review is being

    
    05:59:54
    stored in the reviews database itself but there is no review information that is associated with company yet so what I mean by this is within company we are not storing the aggregate review information like aggregate rating information is what I mean so for example I would want to know whether a company is rated four star five star seven star or whatever so the average rating of the company should be stored in the company service is what I want and the detailed information like what what review was posted when it was

    
    06:00:33
    posted by whom it was posted all of that can remain in the review service now this is something that I'm willing to build so for this what I need to do is I need to have a field in the company service wherein I'll store the overall rating of the company okay and this needs to be updated whenever a new review is posted okay so now how do I do this communication so this communication can go from review service to that of company service okay but and rating information can be passed in that all right and based on that company service

    
    06:01:11
    will update the review of the respective company but the thing is this is synchronous communication now synchronous communication like we said it's not the best okay there is a possibility like company service is busy or it's down or it's too slow slow to respond then in that case there is a possibility that the rating information might get lost so what are we going to do is we are going to have a message queue in between and these two services will communicate with each other with the help of message cues so review

    
    06:01:49
    service will be the producer and it will produce the rating information and it will publish it to the message CU so whenever a new review is posted by any user the review information goes into the message queue so company service will fetch the review from the message q and it will verify the company ID and it will update the average rating of the company against whom the review was posted and this way company service will maintain the average rating of different companies whereas the details of the

    
    06:02:26
    review will be there in the review service so company service will be our consumers in this particular scenario so this is what we are going to implement so I hope the problem statement is clear as to what we are building and why we are building so without a further Ado let's get started hey there welcome back so let us start with the setup for rabbit mq so here I am on the official website of Rabbid mq which is Rabbid mq. comom and you can click on get started over here and here you can click on download plus

    
    06:03:10
    installations so here on the left hand side you can see different ways of installing and setting up rabbit mq you can also see this Docker command okay from where you can set up the rabbit mq so we will be using stalker of course for getting Rabbid mq up and running onto our system so we won't be installing anything onto our machine but since we have Docker up and running let's use Docker so here I have some Docker commands ready so with Docker there are two ways one is you run this command and

    
    06:03:52
    get Rabbit mq up and running onto your system or you can add this to your Docker compose file okay so let me explain both the ways so here you are seeing Docker run hyphen D which is you are running this in the detached mode you're giving this container a name which is rabbit mq and this is the image that you're specifying so rabbit mq colon 3 hyphen management so this is the image that will get downloaded now here you have specified or your are map mapping ports twice so this is the first Port that you are

    
    06:04:31
    mapping and you are mapping the container port to that of the host so 5672 and 15672 these are the two ports now what is 5672 so 5672 is the default port for rabbit mq whereas 15672 is the default port for rabbit mq management so rabbit mq management is an interface that you can access through the browser to interact and work with rabbit mq so that is what this command does you can happily use this command as well alternatively you can copy paste this into your Docker compose file so I'll choose the docker compose way so I'll

    
    06:05:15
    copy this and I'll go to Docker compost. yaml and here I'll say enter and here I'll press paste okay so what we are doing here is we are getting this image this is the container name these are the ports so I'm mapping 5672 of the container to that of host and 15672 of container is being mapped to that of host and I'm making sure that I'm creating or adding rabbit mq to this network here so this is the docker compos version of this command here that we were supposed to run on command line so we are done adding this into

    
    06:06:01
    Docker compose now what we can do is we can switch over to our console or terminal so you can switch to any inbuilt terminal of your operating system okay make sure you have Docker up and running and you need to navigate to the folder where the docker compost file is created and there you need to say Docker compose up high D and I'll press enter so you will see the processing happening for rabbit mq so rabbit mq does not exist yet on my system and it is being downloaded for the first time and you can see the download progress

    
    06:06:43
    that is happening okay so you can see it's happening and this container is started and these two containers or these three containers like Zipkin PG admin and postris container were already up and running okay so this is running now now what we need to do is we can access the rabbit mq management interface from our browser so let's switch over to our browser so here in the browser I'm going to say Local Host colon 1 5672 okay so this is the link that I'm going to go to now when you access this URL you are going to be presented with

    
    06:07:26
    this login page and you'll be asked to login so the default login credentials are guest and guest so you can enter that so we have now logged into Management console and this console gives you a bird eye view of rabbit mq environment you have overview tab which gives you the general information about rabbit mq server including the messages connections channels exchanges consumers and so on so you can take a look at a lot of different stuffs here then you have the connections tab that will display all the active connections to

    
    06:08:06
    your rabbit mq instance okay so if you click on all connections here you will see all the connections coming up over here the channels tab will show you all the active channels now what is a channel so when publishing or consuming message from a queue that process is entirely done over a channel okay so that is what you are going to see over here then you have something called as exchanges and this particular tab displays the list of all the exchanges onto the Rabid mq server okay and you can see the different types of exchanges

    
    06:08:47
    like direct fan out headers match and so on now exchanges are message routing agents okay and exchange is responsible for routing the messages to different cues okay so it will accept the message from the producer and it will route them to the appropriate queue all right and you are seeing like different exchange types over here then you have cues over here so cues in rabbit mq are buffers that will store the messages so a message will be stored in a message CU and each message is processed by consumer who will then consume the

    
    06:09:27
    message message so that information you are going to see over here so this is about rabbit mq and how you can log into rabbit mq console and you can view different information over here now also you will see this message here erlang and some version so this you are seeing because rabbit mq is written in Aang programming language okay so this is just for your information so yeah that's about rabbit mq and how you can access accd console welcome back now let us understand how we can integrate rabbit

    
    06:10:09
    mq into our spring boot project so what we are going to do is we are going to head over to spring initializer because we are going to need some dependency to add so I'm going to say add dependency and I'm going to say rabbit mq now here you will see spring for rabbit mq so I'm going to select this I'll make sure I select Maven here and I'll hit explore so there are three dependencies that I need to take so I'll take all these three okay so that we don't miss anything and I'll head over to my project here so now in our project I'm

    
    06:10:50
    going to head over to company micros Service First okay and here in the end I'm just going to paste the dependency okay so I think I can just get rid of okay so I got the dependencies tag as well copied let me check yep I copied the dependency tag as well so I need to get rid of this and I believe we don't need rabit test and spring boot starter test so I'll remove this so if I scroll up we have already added spring boot stter test test earlier so I just I'm just adding spring boot starter amqp okay and I'll copy this and I'll

    
    06:11:36
    even paste this into review micros service because these are the two micros servic that will interact with message cues so I'll paste it over here and I'll go to Maven Tab and I'll reload all the maven changes now everything is resolved and all the error go away now what we are going to do is we are going to do a little bit of configuration and we are going to make our spring boot projects aware as to how they can interact with rabbit mq so first we'll start with company so I'll go to SRC Main and I'll

    
    06:12:14
    select the application. properties now over here I'm going to add rabbit mq like so now here I'm going to add some property properties like I'm going to specify the host Port username and password for rabbit mq so I can say spring. rabbit mq. port or we'll start with host host is Local Host right now so I'll say Local Host and then we'll need to specify the port so I'll say spring. rabbit mq I'll say Port is equal to 5672 so that is the default Port where our rabbit mq instance is running then I'll add

    
    06:13:02
    username so I'll add username here guest and password the password is also guest over here so we have this settings or these configurations that we need for our spring boot project to be aware of rabbit mq and This Way Spring boot will know how it can access and interact with rabbit mq then I'll copy this and I'll head over to review microservice and I'll add the same in application. properties in the end right so these are the changes that you need to do in order to integrate rabbit mq into your spring boot

    
    06:13:49
    projects hey there welcome back so let us get started with the building so what are we going to build first we are going to build a way to publish messages to Rabbit mq and who will be the publisher in our case so in our case publisher will be the review microservice so I'm going to head over to review microservice I'm going to close all the tab now here this particular microservice will be responsible for publishing the message into the rabbit m q okay so there will be a queue wherein the message will be published and this

    
    06:14:28
    message will be then consumed by the company micros service now when are we triggering this message so we are triggering this message whenever a new review is being posted so when a user posts a new review a message is being triggered to the queue company microservice then knows that hey a new review is now available and then it fetches the average rating for that particular company against whom the review was posted so against that company it fetches the new average rating from the review micro service so

    
    06:15:06
    let us make that happen so I'll head over to the review package over here and let us create a new package here so I'm going to create a new package and I'll call this as messaging okay so we are going to have all the files related to Rabbit mq written over here now I'm going to create cre a new class over here and I'm going to call this rabbit mq configuration so I'm going to call it rabbit mq configuration like so all right now what does this class do so this is the configuration class for setting up rabbit mq in the spring

    
    06:15:46
    application now this particular class will be allowing us to define the beans and it will also be used to configure and control the behavior of rabbit mq messaging so we are going to have three method definitions here we one method is going to create a queue another method is going to do the message conversion so it will convert the message into the Json format so we'll be serializing and deserializing the message and then we will have a method which will give us an instance of rabbit template now what is

    
    06:16:22
    rabbit template rabbit template is a helper class so let us start doing that so here in rabbit mq configuration I'm going to do is I'm going to say public Q now I'll need a q so I'll say Q now when you are selecting Q over here just make sure you select Q from com. rabit mq. client. eqm okay so there are quite a few Q objects that you will see over here okay just make sure you select the right one that is important otherwise you will end up Landing errors so it's spring framework. amqp do core okay so I select that and

    
    06:17:06
    what I'm going to do is I'm going to name this method so I'm going to say company rating Q okay and here I'm going to return a new Q object all right and as a parameter I'll pass in the Q name so I'll pass in this name here like so okay and then I'm going to have public message converter so I'll say message converter so we'll add the message converter from amqp do support package all right and I'll call this method Json message converter like so and here I'll return so I'll say return new Jackson

    
    06:17:58
    so you can see this particular suggestion Jackson to Json message converter so that is what we are going to use over here and we are returning the instance of the same all right and then again I'll have public rabbit template okay so I'll say rabbit template here and I'll say rabbit template like so and this particular class will accept final connection Factory like so and and it will say connection Factory here and then I'll create an instance of rabbit template so I'll say rabbit template and then here we need to pass

    
    06:18:38
    the connection Factory as well okay and then I'll say rabbit template dot set message converter so we will have to set the message converter and here I'll have to pass the instance of Json message converter like so okay and then I'll return the rabbit template like so okay so we are getting an error over here okay so the error we are getting is because we are providing an incorrect argument okay so I'll have to change the import type over here so we have imported a wrong connection Factory here okay so let me remove this

    
    06:19:25
    and let me scroll down here okay final connection Factory so just make sure you have right inputs okay so these are the input statements so you need to have right input statements because otherwise you will land in error so you notice over here everything is from the amqp package over here all right so we have set up the configuration class and this class is responsible and it will help us like do the configuration for our Q now we need to Define this as configuration over here so I'll say configuration and I'll Define everything

    
    06:20:07
    as Bean over here so I'll say bean and I'll copy this and I'll paste it everywhere okay like so so yeah so what we are doing here is we are creating a queue over here all right then we are creating a new Jackson 2 message converter bean and this converter will be used to serialize and deserialize messages okay now in this case the converter uses Jackson and Jackson is a popular library for handling Json in Java to convert messages to and from Json format and then you have rabbit template over here

    
    06:20:47
    so this is a helper class like I mentioned and it handles the creation and release of resources when sending messages to or receiving messages from rabbit mq okay so we are creating an instance of rabbit template Bean over here so now we are done with this now what we need to do is we need to set the message format that we can have over the network all right so for that what we are going to do is we are going to create a dto so I'm going to head over to my project I'm going to create a new dto here so I'm going to say

    
    06:21:24
    dto so I'm going to have it in dto package and I'm going to say review message so this is the format in which the message will be broadcasted and I'm going to have a few parameters over here so I'm going to say long ID I'm going to say private string title so we will be passing all of this to the message CU and this will be ultimately used by like the company microservice okay so I'll say description we can have rating as well go and then I'll have the company ID so I'll say long Company ID like so and then we can have gets and

    
    06:22:12
    sets for everything okay so I'll select all we generate gets and Setters all right so we're done with the tto object creation as well now what what we need to do is we need to create a producer to send the message all right and for that I'm going to create a producer in the messaging package so I'm going to call this as review message producer like so okay and this particular class is going to have all the logic so I'm going to say private so I'll need an object of rabbit template so I'll say rabbit template

    
    06:22:56
    rabbit template and I'll add a Constructor so that spring can essentially inject this so I'll say okay we are done here now I'll create a method so I'll say public void send message like so and here I'm going to have review so I'll say review and review so I'll receive I'll have the review object come in over here and then I'll create a review message object so I'll say review message is equal to new review message like so now I'm going to set everything over here so review message. set ID and I'm going to say

    
    06:23:43
    review. get ID then review message dot set title so I'm going to set all the parameters this way all right so I'm done adding the send message function over here okay so this is the review message producer which which will do the job of sending the message to Rabbit mq okay so this will publish the message and it will convert it into like the appropriate format and send it to this particular queue here so that is what this class does so we are done setting up review like to publish the message into our rabbit mq instance okay or

    
    06:24:25
    rabbit mq Q so now here when the review is added we are not triggering this so we'll be triggering this soon but for now this is done and review micros service is configured to interact with the rabbit mq instance so now it's time to work with the company microservice and give it the ability to receive the message so so with company microservice I'm going to head over to the microservice I'll expand so here we'll again need two classes which will be the configuration class and the dto class and we can have

    
    06:25:10
    the same class over there as well what I will do is I'll just copy these two packages okay and I'll paste it over here like so okay so within company I have dto now which is the review message over here okay which is cool and then I have the messaging so here I have rabbit mq configuration okay which is what we need in company as well okay and then I have the producer over here so I don't need a producer so I'm just going to delete the producer but instead of a producer I need a consumer over here so I'm going

    
    06:25:51
    to right click I'm going to say create a consumer and I'm I'm going to say review message consumer like so and here I'm going to start defining the consumer so here first I'll create an object so I'll say private and I'll say final so we are going to need company service over here now why do we need company service here because we are receiving the rating information okay now once we receive the rating information we need to update it against a particular company now in order to do that I'm going to create an

    
    06:26:35
    instance of company service I'm going to have a Constructor created over here okay and since okay so there is some problem here identifier expected okay so I didn't Define the object name here and now I need to define a Constructor like so okay so this is done now what I need to do is I need to define the consume message method so I'll say public void consume message and here I'm going to say review message like so and I'll have an instance of review message being passed on to the method and I'll say company

    
    06:27:23
    service dot update company and I'll say message over here like review message okay so this is done now what I need to do is here I need to Define rabbit listener so I'll say rabbit listener since we are listening to the particular queue and I'll pass in cues over here and I'll specify the Q name so company rating Q like so so now we don't have a method thir in company service that accepts this particular review message as the parameter so we need to Define that so I'm going to head over to company

    
    06:28:06
    service so in fact I'll go to company service over here now here I'll create a method okay so I'll create the method as public void and let us call it update company rating and not update company because we already have a method called up update company so I'll say review message here and it will take review message as an instance and here I'll update this to update company rating here like so now we need to head over to the implementation class here and I'll have to overwrite that particular method here

    
    06:28:50
    so I'll say Implement and I have overridden okay so this is done now we won't have any logic over here defined yet okay this is something that we will do soon but for now we have the company microservice also ready to start listening to the messages okay so we have rabbit mq configuration which does the configuration then we have review message which is the dto in which we accept the response so this is a format and then we have review message consume which is the consumer and it listens to the queue over here so yeah we are done

    
    06:29:28
    with company microservice so now we have configured our microservices like review and Company to interact with rabbit mq now it's time that we can test our changes so what I have done is I have started all the microservices except the company microservice so so what I'll be doing is I'll be using review to create a review and publish the changes to the host or to The Exchange all right so let us head over to the controller here okay so in review service what we are going to do is whenever a new review is being added

    
    06:30:16
    so whenever this is being done we will be creating a message and sending it to the rabbit mq and how will we do it with the help of rabbit mq message producer so I have created a message producer here all right so here we have review message producer so what I will do is since it's a bean I'll say private review message producer okay and I'll get this automatically injected over here here like so and I'll say this dot review message producer dot like so now I'll go to this class and we'll check if we have defined it as

    
    06:31:02
    a configuration so we have not defined it here so we have not added any annotation so this is not yet being managed by Spring framework so what we need to do is we need to Define this as service and not configuration because this is not a configuration this is service okay so once we add this definition okay we'll see this import statement and this is now being being managed by spring now back over here okay here we are getting an error so we are getting an error in review controller and we getting error

    
    06:31:37
    somewhere over here so I've not added a semicolon which is fine I'll close this now I'll use this message producer to produce a message so I'll go over here and once the review is added okay so if the review is added successfully I'll say like before just returning I'll say review message producer dot send message and I'll pass in the review object all right so we can do that and okay else without an F so since we are now having multiple statements I need to add the curly braces like so okay so we're done with

    
    06:32:22
    this now what we can do is we can restart the review micros service so the service is up and running so now here in Postman I'm going to head over to review microservice and I'll select this particular thing here and I'll add a review against the company ID one so the review is added successfully now let us head over to Rabbit mq and see what we see over there so here in rabbit mq I'll head over to exchanges sorry Q I'll switch over to q and you can see the queue being created over here so you can see company rating q and

    
    06:33:03
    this is a queue that we have created ourselves you can see some stats here ready one total one which means one message is ready to be consumed now if I click on this particular option here like the que and if I go inside you'll see some stats over here okay and here if you go down there is a get message option here so you can click on get message and you will be able to see the payload of the message so this is the message that we are sending okay and this is what is there in the queue right now all right and this is of type the

    
    06:33:42
    review message which is something that we have defined all right now one thing if You observe over here ID is coming in as null and we need to check why is that happening so I'll head over here and I'll switch over to review message producer now here if you see we are setting the ID but we are setting it with review message so I need to say review dot get ID so this should be fine now and this should fix that issue all right and one thing to remember over here the message is now residing in the

    
    06:34:20
    queue and Company microservice is down all right so now what we can do is we can head over to company service implementation so here is where you need to head over so I'll just collapse this in company I'll switch over to company service implementation okay now one thing that I would like to change over here so just keep this file open we'll come back to this but here you are seeing that we have defined the package outside okay so I'll just move this inside company okay we'll read Factor this so in company service

    
    06:34:57
    implementation this is the method that is being called once the message is consumed so if you see message consumed okay here consume message and you are updating the company rating okay so here what I will do is I'll add a simple statement we'll say review message. get description so I'll just do this to see if we are able to read the message properly so once we get the message details over here it means the message is being read successfully okay also since we just copied the configuration and the message like the

    
    06:35:36
    dto package from company we need to add The annotation here as well okay so in review message consume I'll add the service annotation okay this is something we missed earlier and now I'll start the service so I'll head over to company microservice and and I'll say start now the moment it starts what it will do is it will check the messages in the queue and it will read whatever is pending all right that is the first thing it'll do so you can see over here description two and this is the description of the message that existed

    
    06:36:15
    over here now if I say get message you'll get this message that Q is empty here okay and if you hit refresh over here so you can see ready zero unacknowledged zero and total zero okay so there are no messages right now in the queue and the message we had in the queue is being read by company service now if I send this once again so if I say description as one and everything one and if I send you can see description is one now so we are indeed reading the message over here now the next thing we need to

    
    06:36:53
    do over here is we need to update the company rating now how do we update the company rating so to update the company rating once the message is received by the implementation over here okay so once we have the message over here we are going to make a call to the review service and from the review service we will pass in the company ID in the API and we will fetch the updated company rating for that particular company so that is something that we need to do because here we don't have all the reviews stored all the reviews are there

    
    06:37:29
    with the review microservice so there is no way we can calculate the average rating so we need to trigger this query and get the results from there so this is something that we'll do so that's about how rabbit mq is up and running and we'll we shall continue this in the upcoming lectures hey there welcome back so far we have integrated a message Q which is a rabbit mq message q and we have integrated this to work with our microservices so how the flow is working is we have review microservice that

    
    06:38:07
    publishes the message to message CU and then we have company service that consumes the message and review microservice publishes a message only when a new review is added now what we need to do as next step is we need to update the ratings against the particular company so we need to update the average rating against a particular company within the company microservice so the first step would be to add the average rating field in the company service then if there is a new message what does that mean so it means that a

    
    06:38:44
    new review is published in company review service or sorry not company review service review service so it means new message is published in review service so what company service will do is whenever there is a new review it will fetch or it will call a new endpoint of review service which will return the average rating of that particular company against which the review was published now how does company service know against which company the review was published simple so it will get that information from the

    
    06:39:20
    message over here okay and then once it gets the average reading from the review service it will update that within its database against that particular company so that's the flow so let's head over to intellig and let's begin some action so here in intellig I'm going to head over to review microservice now here I'll switch over to the review controller so we will have a new endpoint defined over here okay so I'm going to say get mapping and I'm going to say slash average rating here okay and I'm going to say

    
    06:40:02
    public and this is going to return a double I'll say get average rating or get average review so you can call it whatever you want this does not matter but here what I need to do is I would be accepting the company ID so I need to know for which company I need to return the average rating right so I'll accept this and I'll accept it in the form of request parameter so I'll say at theate request parameter here like so now here I'm going to say review service okay dot get all reviews and I'll get the reviews for

    
    06:40:50
    Company ID like so now I have all the reviews now I'm going to store it in a list so I'm going to say list review and I'll say review list is equal to like so all right so we have this information now now what I'm going to do is I'll just collapse this and here I'm going to make use of streams to get the average review so I'll say reviews review list tot I'll say stream I'll convert this into stream do map to tble and I'll I'll say review here colon get rating or get average review okay so we are not getting get

    
    06:41:41
    rating over here so yeah this is the method so after two colons we'll get get rating and I'm saying dot average so I'm calculating the average and I'm saying dot or else okay so if I don't get an average I'll say or else 0.0 okay so this is what I'm doing here so what I'm doing is I'm saying convert this review list into stream and then map everything to double okay and then for every review I'm getting the rating over here and then I'm calculating that into or converting that into an average okay now if the average does not exist

    
    06:42:25
    we are returning 0.0 so this is what the function does or this particular mapping will do okay so now we have added this over here now what we need to do is we need to call this from the company microservice so I'll head over to company microservice over here now to call this particular API what we need to do is we need to add open fan over here okay because we are making an API call so I'll go to job microservice because we have already added open fan integration over there okay so I should see that dependency somewhere over here

    
    06:43:06
    so you can see this dependency Cloud starter open fan so what I'm going to do is I'm going to copy this I'm going to close this and I'll head over to company microservice and I'll get this added all right so this is added I'll hit refresh over here now the first thing we can do over here is so we will head over to the company entity here and we need to start storing the rating that we are getting for every company so this will represent the average rating of that particular company okay so I can say private double

    
    06:43:46
    and I'll say rating like so and I can generate Getters and Setters for the same okay so say right click and I'll say generate getter and Setter okay so they're done now after this step we need to define the client okay so we need to start making use of open fan over here to make the API calls and to do that the first thing we need to do is we'll head over to the application class and I'll see enable Fe clients like so okay then I'll close this then we need to head over to or we don't need to head

    
    06:44:31
    over anywhere we need to just create a new class over here okay which will be the Fain client so I'll say clients do review client so we will create a review client in the client's package okay and now here we will start defining the API call so this will be the client that will be used for making the API calls and I'm going to say Fain client here and I'll say review service like so so essentially what I'll do over here is we'll need a method here so I'll say get mapping like so and here I'll see the

    
    06:45:22
    get mapping is SL SL reviews slash so I'll just check the mapping so average rating is the mapping names I'll say average rating here all right and here I'll Define the method so I'll say double and I'll say get average rating for company like so and here I'll say request param and I'll pass in the company ID like so okay and I'll say Company ID over here so let me hit enter so that we get a better visibility so I'll say Company ID and we need to define the type of company ID so it's long okay so yeah we have defined

    
    06:46:14
    the method so I'm getting some red marks okay so Missing Method body so a small mistake we did here is we defined this as a class so so it's not a class it's an interface and the error goes away so we have a review client which is ready to interact with the review service and it has this mapping defined now what we need to do is we need to head over to the implementation class of company service and here is where we receive the review message once the rating is updated so now what we need to do is we

    
    06:46:52
    need to make use of the client to fetch the newly updated ratings like the average rating and we need to save it against the company all right so what I will do is I will scroll up here and I'll say private and I'll say review client so review client review client and I'll get the review client added over here in the Constructor so that it's provided at the runtime okay and here I'll say this do review client is equal to review client like so so we have an instance of review client now now what I will do is here I'm going to

    
    06:47:36
    say company so there is a series of steps that we need to do over here so first we need to get the company from the database okay and we also need to get the average rating against that company from the review service and then we need to update this company review and we need to save it all right so I'll say company company is equal to company repository dot find by ID okay and here I'm going to say message dot get Company ID all right and here I'll say dot else throw so I'll throw and exception

    
    06:48:20
    probably we can or we can just quit this okay you can throw an exception if you wish to okay so we're getting an error because it's optional okay so we need to add else throw okay so I'll say dot else throw and you can have an exception inside okay so I can say like this I'll have a so I'll have an exception created like this and I'll say company not found and I'll pass in the ID here so I'll say review message dot get Company ID okay so this is something that we are doing so let me explain this here what

    
    06:49:09
    happened so here we are throwing an exception okay so if we are finding the company by this ID it's good or else we need to throw this exception that is what this line simply means all right now here I'm going to say so we need the average rating as well okay so we have the company now I'll say double and I'll say average rating so this average rating we are getting from the review microservice with the help of review client so I'll do this and I'll say message. get Company ID like so all right and now what I need to do is I

    
    06:49:51
    need to update the app average rating against the company so I can say set rating and I'll say average rating and here I'll say company repository dot save company so we have successfully updated essentially the rating that was posted against a particular company all right now let us test our changes okay so what I will do is I will restart the company Microsoft service and we also need to restart the review micros service okay and we'll wait until they both are up and running so they both are up now we will

    
    06:50:36
    head over to postman here and what we can do is we'll first create a company with the ID one so I've added a review first we'll create a company to with the ID one over here so we'll call it one as well okay so companies created now if I get the list of all the companies you'll get the rating as well and rating for this is five okay so you can see the rating here now what we can do is we can go over here and I'll get the rating for company one so you can see the there is one rating that has been defined for this

    
    06:51:21
    particular company which is rating is 5.0 okay so now what I'll do is I'll post one more rating here okay and the rating can be let's say three or I'll post a three star against the company one okay and I'll say description to description or review to description two and I'll send this okay now if you check the console for company you should see this message being received now what we will do is we will try getting the companies so now if you get the company you will see the rating has reduced to

    
    06:52:02
    four which indicates that the rating was updated if I post one more rating over here let's say rating three rating three and I'll keep this as one star and if I try to get the rating now you'll see rating has reduced now to three and you can see this from the logs as well okay you can see all the queries update company so compan is being updated as well so these are all the queries that we getting from hibernate all right so this is indeed working perfectly fine and as expected okay you can see here also with review

    
    06:52:42
    microservice we are seeing the rating query coming in action so it's working fine all right and it is working as expected so this is how you can make use of rabbit mq for a synchronous communication between microservices and this way it can be really helpful because synchronous communication might not always be possible and it might not be the best option so rabbit mq for the rescue hello everyone welcome back so let us start talking about microservices packaging so so we all know microservices is a style of architecture

    
    06:53:28
    wherein we have a collection of small loely coupled services and each of these microservices is deployed on a separate server it is developed separately deployed and skilled independently as well but how do we get these services from our development environment to a state where they can be easily deployed executed in a variety of environments like testing staging and production and this is where packaging comes into picture so let us first talk about how does a typical spring boot application executes or runs without any packaging

    
    06:54:09
    so what are the steps involved so the number one step is the code compilation so the first step is to ensure that your source code is compiled into bite code and this bite code is do class file which which is being used by the jvm and the source files are compiled by Java compiler then the next step would be running the main class and in Spring boot application there is a main class which is annotated with at theate Spring boot application annotation and this serves as the entry point to the application then we talk about class

    
    06:54:47
    paths and dependencies so when you run the application without a jar the class path must be set up correctly to include the compiled classes and any required dependencies so the class path specifies the location where the Java runtime can find the necessary classes and resources embedded server so if your spring boot application is a web application the application typically includes an embedded web server and when you run the main class the embedded server starts and the application becomes accessible while HTTP

    
    06:55:24
    endpoints source code changes so since you are running the application from the source code any changes you make to the code will take effect immediately upon rerunning the main class so there is no need to rebuild the jar and restart the application then development mode so running without jar packaging is convenient during development as it allows for Rapid integration and testing of code changes but for ction environment it's recommended to create a jar file so these are different steps that typically an application goes

    
    06:56:00
    through when you are running it without packaging now what is packaging so packaging is a process of preparing your microservice for deployment it involves compiling your source code into bite code bundling it with any dependent libraries and creating a single executable artifact that can can be easily distributed and run now this artifact is what is called a package okay so you can think of it something like this so within the package you have bite code dependent libraries and the configuration and

    
    06:56:39
    packaging ensures that all the necessary components to run the service is gathered in one place in a format that's easy to distribute and execute now what is jar so when working with Java based microservices one of the most common forms of packaging is a jar file so jar stands for Java archive and it's a file format that is used to bundle the components of the Java application together and jar file allows us to package our compiled code related libraries resources metadata and the single file can be picked up by Java

    
    06:57:21
    runtime environment and it can be executed now packaging our microservices into a jar file can provide us with number of benefits so the number one benefit is simplified deployment so instead of dealing with numerous dependent files and classes we have a single file that we can move around easily second it ensures that all the dependencies are satisfied by including everything we need in our package so this way we avoid the risk risk of missing libraries or other dependencies and lastly J files can be

    
    06:57:58
    executed directly by Java runtime which simplifies the execution process so to summarize packaging and specifically packaging into jar files is a critical steps in preparing our microservices for deployment so it simplifies the process of transferring our applications between environments and ensures that we have everything we need to to run our service now there are also other packaging options that exist which is war so this is like converting your application into a war file and then we have e format as well and then

    
    06:58:36
    we have Docker image so these are different packaging options also available so that's all you need to know about packaging hey there welcome back so I wanted to talk talk a little bit about packaging Basics so in the world of java there are two primary build automation tools that dominate the entire landscape and one is Maven and the other one is Gradle and both these tools provide a comprehensive framework for managing the entire life cycle of a Java project and this includes packaging so Maven is one

    
    06:59:19
    of the earliest tool it's one of the older tools that that exists and it uses this XML format that you can see and it's a configuration file called pom.xml and this is used to manage project builds now pal stands for project object model now this outlines the unit of work in Maven and it outlines the details about the project what all the project needs the configurations and so on also you can have defined packaging over here so you can specify whether you want this application to be packaged as jar war or

    
    06:59:58
    ER file and it takes care of the details without you having to worry about it on the other hand we have Gradle as well so if you head over to the browser and if I open up spring initializer with Gradle and if you say explore you have this build. gdle file now this is equivalent to the pom.xml file that we have have in Maven and this file takes care of having all the dependencies the project definition and so on if you are making use of gridle as the build tool now when it comes to packaging the build file so build.

    
    07:00:40
    gridle is the build file in case of gridle and pom.xml is the build file when it comes to Maven so when it comes to packaging the build file specifies the format of the package and it becomes the entry point for the application and with packaging it also has any additional resources or definition that might be included in the package so I wanted to just stress on the importance of having build tools when it comes to packaging so here you have everything about the project now so you have all the dependencies and what

    
    07:01:15
    all your project needs on the runtime along with versions is specified over here so that's the importance of build Tools in packaging hey there welcome back so we need to start packaging our microservices so what I'm going to do is I'm going to head over to Google and I'm going to search for Maven now here you can head over to the official Maven website and you can click on download here so the there are two ways of using Maven so in order to package our microservices into a jar file we will need to run few Maven

    
    07:02:00
    commands so you can either download Maven from here and get it installed on your system but this is not what I'm going to do so I'm going to use something called as a maven wrapper now what is a maven wrapper so Maven wrapper is something that we get with spring boot application okay and we can use Maven commands without in installing Maven then so Maven rapper is a shell script and a small binary that automatically downloads the correct version of Maven for your project and uses it to execute Maven commands so

    
    07:02:36
    with that step we don't need to install Maven manually onto our system of course if you want to you're welcome to do so but what I'm talking about is this wrapper over here so you will see this do mvn file or mvn folder which has the maven wrapper in it so we are going to make use of this now before we start packaging we need to understand a few Maven commands so the number one command is mvn clean so the clean command in Maven is used to remove all the files that are generated by the previous build

    
    07:03:12
    so if you are generating multiple builds and you might want to clean the files that are generated from the last build you can use Maven clean and this is because course with every build you will have some set of files that are being generated by Maven so this is just for cleaning purpose so running Maven clean will clean the target directory of your project and which is where the maven places all its build files so if you see the project structure you will have a Target directory wherein all the files

    
    07:03:45
    are being generated so by files I mean class files and Char files the next command we should be Ware of is Maven package so package command compiles your source code and packages it in its distributable format and the distributable format can be jar war or anything so running Maven package will compile your code run any tests if you have defined them and then package your code into a jar file and the resulting jar will be placed in the Target directory of your project then we have Maven clean package so this this command

    
    07:04:22
    combines the above two command so it will first remove all the files that are being generated by the previous build and then it will compile your code and package it into distributable format so these are some of the commands that you are supposed to be aware of now here we are using mvn but if you are using Maven wrapper you don't need to use mvn so there is a different way of executing commands using Maven wrapper which we'll take a look at it shortly but if you have installed Maven you can use mvn and

    
    07:04:55
    the rest of the command remains same so let us head over to intellig now let us start talking about how can you start creating a package or a jar file so what we are going to do is we are going to create a jar file for let's say company microservice okay so what I will do is I will open up the terminal from here this is the inbuilt terminal that I have Within intellig now here I don't need to do any changes in pom.xml because I'm creating HR file now if you wish to create a file in some other format or some other packaging you

    
    07:05:35
    can have a packaging tag defined over here and you can specify whatever you want to so you can specify ER war or you can even specify jar but if you don't specify this jar is the default so I'll just remove this and we have everything set up we have the target folder created as well okay now Target folder does not have the Char file so let us open the command prompt and let us make sure that we switch over to the company microservice directory so I'll check where I am so I'll go to the company microservice directory so I'll say

    
    07:06:15
    company micros service and here I'll start executing the command so I'll say dot forward slash because we are using mavin wrapper I'll say mvnw so this is mavin wrapper and we'll say package now this will start the process over here and you can see like there is a lot of activity that is happening over here and there will be lot of console logs that will be generated okay so when you are running this particular command just make sure that all the dependencies that your application needs are there so

    
    07:06:53
    for example things like Zipkin server rabbit mq or whatever it needs like postgress SQL database everything is up and running okay so here you can see the logs so if I scroll up you will see everything was scanned and then pom.xml was taken into consideration okay and here if you go it started generating the files you can see it started compiling and then your application tests were run now your application was also started okay so if you scroll down here your application was running okay and that is

    
    07:07:32
    why we need all the dependencies so your application might start and then you saw quite a few logs okay and your application was started and then if you scroll down a bit here you will see like everything was successful and if you scroll down you will see that that the jar was generated over here in the Target folder and build was successful so now if you go to the Target folder here you're going to see this jar file appear over here okay so yeah we have created our jar file now you can even validate the jar file after

    
    07:08:11
    it's created okay so I can run a simple command I can say jar hyphen TF I can say Target and I can say company Ms snapshot. charar and I can say enter okay so I'm not able to run this command jar so I'm getting this error because I'm not able to run or jar command is not recognized and this is because I believe Java environmental variable path is not set for my system so if you get the similar error so what you can do is you can go to my computer right click on my computer icon and go to advance

    
    07:08:53
    setting and uh over there you will find environmental variable option so if I go over here if I search for environmental variable here so you can also go here from the search so since I'm on Windows 11 I can search directly over here and I can search for environment variables and I get this popup here okay so I can simply open this or if you are not on Windows 11 you can go to my computers right click and uh you can choose properties so on my computer icon if you right click you'll see properties and

    
    07:09:30
    you can click on Advanced system settings and there you will see environmental variables over there okay so on Windows you can select environmental variables and here you need to go to the path variable you need to say edit and here you need to add the path to jdk okay so so of adding you might need to restart okay so I'm not doing that and if you ask me what is the path that I need to set you need to set the path of java installation or the jdk path so you need to go to program files so here if I go to program files I have

    
    07:10:08
    it installed so Java is installed in Java folder within program files and there you have jdk 20 now within jdk 20 you will have this folder bin now here you will have this file jar. exe so this is what we are using here okay so you need to copy this path and set add to this path variable over here okay this path variable so I'm not doing that but as an alternative what I'll do is I will run it using another way so I have the command created so this is the path of the jar file okay what I'm doing is in power

    
    07:10:52
    shell I'm passing in the entire path of jar. exe along with the and variable because so this is because I'm using Powershell and you can pass the rest of the command as it is okay but if jar command works for you you can just specify jar and if you are not using Powershell you can also use something like this so you can simply say something like this so in Powershell you will need and operator at but if you're not using Powershell this should work for you okay so I'm going to copy this first command and I'll go over here and

    
    07:11:32
    I'll paste it okay and now once you paste this you can see like everything within your jar okay so if you scroll up and you will see all the contents of your Char file okay and if you see over here you'll see everything that your jar file has okay so this is to confirm that everything is working as expected okay and you're just checking if everything exist in your jar file now what you can also do is you can run your jar file okay right from the command line okay you can run this project now how would you run your

    
    07:12:14
    project from here so the answer is with the help of Jar file so it is an executable jar right so we'll say Java okay something went wrong so I'll just clear my screen here I'll say Java and I'll say over here hyphen jar so since we are running a jar file we need to specify hyphen jar and now we'll specify the path of the jar over here and we'll say run so you can see the application is running now okay and I believe it won't run so it will shut down and and the reason is because our Port is already

    
    07:12:55
    engaged and who is engaging this port so I have the company microservice already running from intellig but if you stop this and if you start from here okay the port 8081 will be freed up and it will be in use by this particular service so this way you can get your jar to execute and this is the process that we went through so I hope you found this entire ire process easy to set up and easy to follow so that's about jar files with microservices so let us test the functionality of our application that

    
    07:13:37
    has been packaged into the Char file so what I'm going to do is I'm going to go to services and I'm going to turn down the company microservice application okay so this application is down now I'll try running the application right from the terminal so I'll type in the command I'll say Java hyphen Char and I'll say Target slash company snapshot. charar and I'll press enter so now you see the application is running we'll wait for a while and we hope we don't get any errors so the application is running

    
    07:14:22
    also make sure before you run the application you have all the dependencies up and running like the post SQL Zipkin server rabbit mq so whatever this application needs now let us head over to browser and here I'll go to urea okay and we'll see that company service is now registered with the urea server and you can even send some requests so I can like get companies I can post a company okay and it will give me the list of companies so it is working perfectly fine without any issues you can see here we created a new company

    
    07:15:06
    and we are also able to get that particular company here okay so rating is coming in as null so I need to update the rating here like so so I'll say 5.0 okay and I'll add a comma here so I'll create this company and now if I try to get you'll see company with rating so this is indeed working perfectly fine as if you are executing the project directly welcome back so now let's talk about containerizing our spring boot microservices so what are we going to build so we are going to containerize each and every microservice that we have

    
    07:15:54
    and we are going to take everything to talker so this is what our architecture is going to look like so we have three microservices chob company and review all three will be running on Docker they have their own individual databases which is again running on Docker then you have the Gateway which is doing the job of routing requests and it is serving as an interface for the external clients so that will also be on Docker and we have rabbit mq config server urea server and Zipkin which will also be

    
    07:16:35
    running on Docker so this entire thing will be running on Docker and we will be managing everything from a single file which is Docker compose so we don't have to go to our IDE and turn on every single Le service but Docker is going to manage everything for us so this is what we are going to build so without a further Ado let's get started welcome back so let us start talking about spring boot profiles but before we talk about profiles I want to present a problem to you so let us say I'm here in job microservice and I have

    
    07:17:21
    my configurations or all the application properties defined over here all right now if you see these configurations these are the configurations that are for my current system now what happens if I dockerize this application or what happens if all my applications and microservices start running in Docker so in that particular case you can no longer use Local Host over here that is because you have the microservices running now in different individual containers and not on your local machine so instead you will have to replace this

    
    07:18:04
    with the container name and that is where the concept of spring boot profiles come into picture so here we are able to make use of post SQL with the help of Local Host but config server if it's running on container we would want to include container name over here and there will be few properties that we might want to change based on the environment in which the application is running and this is where the concept of profiles come into picture so what are spring boot profiles so spring boot profiles provide a way to segregate the

    
    07:18:42
    parts of your application configuration and make it available only in certain environments now what I mean over here is if your microservice is running in multiple environments like testing staging production there is a possibility that you might need different configurations for different environments so you might have a different database or a different URL of database for testing you might have a different URL or different instance of database for staging and depending on where your application is running you

    
    07:19:19
    might want your application to use use that particular instance of database depending on where it's running so this is where spring boot profiles come into picture so you can have different profiles of your properties and based on where your application is running the corresponding property file is being picked up and it is being utilized the other property files are not being used so this is what profiles are in simple terms so profiles enable spring boot application to work in different environments and to run

    
    07:19:56
    seamlessly with the help of different configurations for each environment and spring boot does the job of managing this during runtime you just have to configure them so that's spring boot profiles for you so let us now begin preparing our projects for doer so what we will need to do is we need to modify all the configurations and create different profiles for application to work in Docker as well as to work on our local system and also you need to make sure that you have this particular plug-in

    
    07:20:40
    spring boot Maven plugin added in all your microservices because of this plug-in you will be able to dockerize your application without cre creating a Docker file so this is something you need to check for now let us head over to application. properties and what we need to do is we need to create a duplicate of this file so I'll copy this file over here and I'll paste it at the same location but this time I'll say hyphen Docker over here so we are creating a separate application. properties file for Docker environment

    
    07:21:19
    okay and we are creating a separate profile as you can see so we are making use of this concept of spring boot profiles all right now let us modify the application Docker so here in data source I'll need to specify the database URL over here so I need to specify the container name here so I'll say post Crest and rest of the thing I'll keep same now in case of urea server I will specify the container name over here as well so I'll say service registry RG so you need to make sure you create containers with this

    
    07:22:00
    name only so I can add config server over here so I can say config iin server like so okay and if you scroll down so we need to add for Zipkin as well so I have not defined the URL for Zipkin okay so we need to define the tracing end point Point okay so I need to say management dot Zipkin dot tracing dot endpoint so this is something you need to Define explicitly because by default The Local Host URL is taken so I'll say so I'll copy this URL structure over here okay and I'll paste it over here

    
    07:22:45
    and I'll say HTTP Zipkin and so that will be my container name and here I'll say 9941 and here I'll have to add API hyphen V2 hyphen spans like so okay so we are done changing the URLs now what you can do is you need to head over in your job app and you can see this client folder which you have created so here you are making use of a server names over here okay but this might change when you are working with the containers so for that purpose we will make use of variables defined in properties so what I will do is I'll

    
    07:23:36
    create three properties over here okay I'll say job hyphen service. URL is equal to http colon job colon 80 82 okay so this is for my job app job microservice and I'll replicate this and I'll say this is for my company service and I can again paste it and I can say this is for my review service and I'll change the URLs and Port so I'll say company and I'll say review and I can say 8081 is company and 8083 is review all right now what we can do is we need to head over to application so not application. properties but company

    
    07:24:29
    client and over here we need to make use of another field so I'll say URL okay and I'll say dollar and I'll specify the company service URL okay so I'll say company so wait a minute let me take this on a new line okay and and I'll say company hyphen service. URL over here so with this what we are doing is we are actually specifying the URL and the URL is supposed to be picked up from the configuration because of this syntax and where have we defined configuration so we have defined it over here okay so

    
    07:25:14
    we have specified this for client like company client only one of the clients we need to also specify this for review okay so I need to head over to review here and I'll copy the same thing and I'll paste it over here like so and here I'll say review service. URL okay so now the URL is being picked up from application. properties file now what I need to do is I need to copy this and I also need to add it to the default one okay so the default application. properties there also we need add this so there I'll say Local Host okay and

    
    07:25:55
    Local Host Local Host so if there is no profile that is being used and if we are making use of default application. properties then it will point to Local Host otherwise it is pointing to Containers or we are done doing configurations for the job service now what I will do is I will close the other tabs okay and I'll just keep keep company client open okay because we might want to replicate the syntax in review or company now I'll head over to company microservice here and I'll open up the application. properties now here

    
    07:26:35
    I'll just duplicate this so I'll say application hyphen talker do properties okay and here let me see if I'm defining any clients so I'm defining a review client Okay so what I can do is I can copy these URLs and I can have them added over here okay like so okay so there is some problem with the paste so I'll just press enter and then add it okay so now it works perfectly fine and I'll also get this added in the local file like the file which we have without any profile okay and here as you usual I'll specify Local Host

    
    07:27:22
    okay and I'll get this copied across okay so we have this defined and I'll close this over here so now in the company microservices I'll make all the necessary changes okay and I can keep this as a reference so I'll say postgress and I'll paste postgress over here I'll scroll down for urea server I need to say service registry here so I'll past it that over here and I need to add the Zipkin URL okay so you see I have one spelling mistake over here so typo so management. Zipkin do tracing do endpoint that is what it

    
    07:28:07
    is so I'll copy this endpoint as well and what I will do is I'll paste it over here for Zipkin like so and I believe rest of the things are fine okay so rest of the things are okay and there are no issues as such now what I can do is I can go to the clients that I have created over here so I have only one client which is review client and I can copy the syntax that I have defined here and here I'll say so instead of company service I'll say review service okay and it seems I'm getting an error okay so I need to

    
    07:28:49
    specify name over here if I'm specifying URL which makes sense so here we have company service URL and let me check so I'll go to SRC main Java and here in clients I'll go to review client so yeah I've made the change over here so we have review service. URL here and we have made the changes similar changes over here as well okay so this is now making use of hardcoded URLs all right and we have replicated the same in the default application. properties so I'll collapse this and if you go to application.

    
    07:29:29
    properties we have replicated the same so far so good so this is also done this is company microservice now let us do this for review as well okay so I'll go to application. properties here I'll say posis SQL so first let me copy this so I I'll just copy these and I'll paste it over here at the top okay so this is done now I can replicate the application. properties into talker profile I have a new profile now I can collapse this so now I'll scroll up and I'll use the company microservice Docker file as a

    
    07:30:13
    reference so I'll copy these three tags and I'll get them pasted in review Docker file okay and if I scroll down now so here I need to add the database container name which I add and I need to add the service registry so I'll add that over here and then I need to add the Zipkin URL which I'll add over here right so rest everything looks fine and there are no issues as such okay so I have everything set up now and one last thing I believe we need to check for clients so we don't have any clients

    
    07:30:58
    defined in review but despite that I have created the URLs here just in case in future if we want to use we can make use of these okay so this is about configuring all three microservices and getting them ready with spring boot profiles along with container names that we are going to use for other parts of the the application or architecture so now we are ready to run these applications or spring boot applications with Docker hey there welcome back so we have prepared our project to be dockerized and we have everything ready

    
    07:31:44
    now let us begin building the docker images so to do so so we have to make sure that we have Docker up and running all right so I have started my Docker desktop here as you can see and I have my terminal open now what we are going to do is we are going to start building the docker image and let us start building the docker image for our service registry project all right so let us head over to the terminal so you can either use the inbuilt terminal or command prompt on your operating system or alternatively you can use the one

    
    07:32:25
    that you get with intellig so you can click on the terminal tab over here and you can make use of this and you can even add new tabs over here if you wish to okay so I would be using Powershell since I'm on Windows okay you can choose the equivalent one for your operating system and what we are going to do is we are going to navigate to the service registry directory okay so I'll check where I am right now so I am in company microservice so I'll go one step above and I'll say service registry okay and

    
    07:33:01
    now I'm in this particular project so I'm going to clear everything now we need to write in the command and we will be making use of Maven rapper over here okay so here is the command that you can see over here so this is the format so what we are going to do is we are going going to make use of Maven wrapper over here as you can see I'm going to say spring boot colon build image hyphen D spring boot. build image image name is equal to so this is what I'm going to then specify so my Docker Hub username

    
    07:33:39
    and my image name so the image name that I want it to be so if you're not aware or if you don't have a account on dockerhub I would request you all to head over to hub. do.com so I am on dockerhub and I have already created an account over here okay so I would request you all to create an account okay and uh you will need the username that you set over here okay and what we are going to do is after creating the docker image we are going to push this image to the docker registry which is hub. do.com all right so so I have this

    
    07:34:21
    command created over here so my username is decode 07 and service regge is the name of the image so I'm going to just copy this command I'm going to head over to my terminal and here I'm going to paste this and I'll say enter now the moment you say enter you're going to see some processing happening over here okay so you'll see like the image building process is happening there are quite a few tests that are running okay and you can see this prompt over here like it's building the image and it's also pulling in Peto

    
    07:35:02
    build packs okay so we'll wait for a while so it will download everything it will pull everything and then it will create your own image okay so here it is pulling in petto build packs because it's using the concept of cloud native build packs to create Docker image now build packs are modular and language focus and know how to build application based on different languages and Frameworks for example there are build packs for Java application nodejs application python application and so on okay so Peto build packs is a specific

    
    07:35:39
    implementation of cloud native build packs that spring boot uses it is using this since we have a spring boot project and each percentage update is indicating the progress of pulling the base Builder image from the docker registry and in this particular case it's Docker Hub over here okay now once this image is pulled so this image is pulled over here it will be used to create the docker image so you can see over here after the build packs were pulled in Creator was started and it started creating the

    
    07:36:18
    image over here and this is the entire stack trace and if you scroll down a bit you will see like there are quite a few layers that have been added okay and the image is now saved okay and you're seeing build success and it took this much of time so the time it will take will vary for your project okay it completely depends on the processing speed that your computer has and also your internet connection okay and now if we say docker images we are going to see this particular image that exist now we

    
    07:36:54
    are also seeing Peto build packs Builder pcket to build packs run and so on okay but we are concerned about our service registry over here okay so we are seeing the docker image now the time is to push this image to Docker Hub okay so what I'm going to do is I'm going to say Docker push and I'm going to write in the the name of the image okay so I'll copy this and I'll paste this and I'll say enter now there is a possibility that you might be asked for logging in into Docker right from the terminal so you

    
    07:37:34
    can enter your username and password and uh get logged in but uh it didn't prompt for me because I had already authenticated so now it's pushing the entire image to remote dockerhub all right and uh we'll wait for a while so the process is complete now let us head over to dockerhub and I'll open the docker up website and if I refresh over here so after refresh you will see service registry Docker image appear over here okay so what we have done is we have successfully created the docker image for service

    
    07:38:12
    registry and we have pushed it to Docker Hub all right so this is the entire process that we we need to follow for creation of talker image and getting it live onto talker Hub hey there welcome back so it's now time that we should dockerize all our other microservices and get them pushed to doer Hub all right so we have done this with service registry we need to doize all the other five microservices so I would request you all to take this up as a challenge you are aware of the process as to what you need to do so you

    
    07:38:57
    need to trigger this command in the root directory of the project and once this command generates the docker image file you can push the docker image file by running Docker image and after space you can specify the doer image name so this is something that we need to do for the rest of our microservices and I would want you all to take this up as a challenge so you can pause this video right now attempt this as a challenge and see if you are able to get Docker images for all your projects all right

    
    07:39:33
    so I hope this went well with you so let us do this for our other projects so I'm going to start with company micros service okay so I'll head over to our terminal and I'll switch over to company microservice and here I'll paste that command and I'll say enter now with this the process will begin and you will notice that it does not fetch the petu build packs this time because we had already downloaded it when we were creating Docker image for service registry all right so it won't do that this time so it will just create the

    
    07:40:15
    image and this time it will be much more faster master so Docker image creation is complete and you can see over here that this is the docker image that's created so the creation is done now we can push this particular image so I can say push and so Docker push and let me paste the image name over here okay invalid reference format so this should be removed or one second so I'll I'll just remove this command okay so you don't need to have a forward slash so it should be review Ms like so okay and I'll press enter and

    
    07:41:01
    you can see that it's now begin the push process so the push process is complete and if we head over to our browser and if I refresh you should see review micros service appear over there all right and now we can try the same process for job micros service so I'll head over to the terminal and I'll switch over okay sorry so I need to add full stop and I'll switch over to job microservice directory and I'll paste the command and this will begin the process to create the image for job microservice so we'll wait for a while

    
    07:41:38
    so the image creation is successful now we need to say Docker push and we need to get the image name so I'll paste it over here and this will be pushed to like dockerhub so hub. docker.io all right so we'll wait for a while until the push process is done so the processing is complete and if you head over to the browser and if you hit refresh so we are seeing the job micros service available now over here okay so let us do this for the rest of the two micros service so I'll copy this for Gateway micros service and here I'll

    
    07:42:18
    switch to Gateway microservice project so I'll say CD Gateway and I'll paste this over here okay and it will begin the process to generate a Docker image so the image creation is done completely this time it took 38 seconds so now I'll say Docker push and I'll copy the image name until over here and I'll paste it over here now this is going to get this pushed onto talker Hub okay so we'll wait for a while again so the process is complete now if you head over to the browser and if we hit refresh you should see the Gateway

    
    07:43:03
    microservice project over here as well okay now let us do this for the last remaining micros service which is the config server okay so what we can do is we can come over here we can switch over to the config server project okay so I can say config server and I can paste the command here now this should begin the process without any issues okay so we'll wait for a while until this finishes so this process is done and now we need to push it to the docker Hub so I'll say Docker push and I'll copy the

    
    07:43:42
    image name from here and it should get this pushed to Docker report repository okay so you can see over here it's preparing and it will get it up on the system so the image is pushed and now if you head over to the browser and if I hit refresh you should see the config server appear over here so all our microservices have been pushed to doer Hub okay and the process is fairly simple you just need to generate the image locally and you need to get that image pushed onto the server you might be asked for authentication for

    
    07:44:21
    dockerhub which you can do from the terminal and once you authenticated the process should be fairly simple all right so that's about this class and in the next lecture we will move forward with this all right so we have dockerized all our microservices and we have even got them pushed to dockerhub now what we need to do is we need to start managing all our microservices with the help of Docker compose file so I'm going to open the docker compost file over here okay now this Docker compost file has

    
    07:45:04
    configuration for rabbit mq Zipkin PG admin and pogress what I will be doing is I will be adding more components to talker compose so you can see I have this notepad file where I have the updated version of talker compose and you can see I have Pais if you scroll down I have config server along with the docker image name and I have service registry company microservice job microservice and I have one more instance of job microservice over here which I don't think we will need so I'll just remove this okay we have review

    
    07:45:48
    micros service and I have rabbit mq okay and Zipkin and Gateway micros service there is a lot in this particular file okay and what I'm going to do is I'm going to copy this file and I'm going to move this into our project here okay so let us go through this file so you will see I have the configuration for posis which is okay it it does not change same for PG admin now there is this new edition of config server here okay I have specified the image name over here the container name so this will be the

    
    07:46:28
    container name which will be created using this particular image then I have port and then I have specified the dependency okay so this dependency is something that we need to specify so what is this depends on tag so config server is dependent on service registry and service registry is this particular container over here okay so what I mean by specifying this is this container or this service should be started after service registry okay so that is what we have specified over here and we have

    
    07:47:08
    added this to a couple of networks like a microservice network and pogress network okay and you can see over here I have also specified which profiles I wish to use for this particular image so the active profile is of Docker so by default if you see this is config server okay so slash Docker file will be picked up okay so we have defined SL talker file for all our microservices so that is what will be picked up okay now you can see over here service registry depends on rabbit mq Zipkin posis and PG

    
    07:47:46
    admin so first these services will be started and then service registry will be started okay and I have added this to couple of networks again we have company microservice again which is dependent on service registry and also the config server then we have job microservices and here we have specified a couple of things like the docker profile is supposed to be kept active and we have specified the urea client service URL default Zone okay and this is the container name that we have specified okay so we have specified

    
    07:48:25
    similar things for the rest of the microservices and if you go down we have couple of networks that we have created over here now what we need to do is we need to start our project with the help of Docker compose file and for that I'm going to head over to our terminal so here in terminal I'm going to go to the root directory and I'm going to go to the company microservice directory now here you will see Docker compost. yaml which we have just modified so here I'm going to say Docker compose up and I'm going to run this in

    
    07:49:04
    detached mode okay so you will see like these four containers were recreated okay and then you have the rest of the containers created and starting all right so our application is now starting in the form of Docker images okay and you can see all the containers have started and you can say Docker PS so this is going to give you the list of all the containers okay which you can check yourself so you can see these are all the containers that have been started okay now if you want to remove all the images okay so you need to say

    
    07:49:45
    Docker compose down okay so I will say you can just go over here okay and you can say Docker compose down like so and it will stop all the containers you can see it is stopping all the containers over here and if you want to restart or if you want to remove all the images now okay so let's say I want to check what all images I have on my system so let me just zoom in a bit and I can say Docker images so this will give you the the list of all the images that exist on your system along with the size now if

    
    07:50:23
    you want to remove all the images that we have created so you can say Docker system prune hyphen a so the moment you run this all the images will be deleted and system will be clean but I won't be doing this because I need these images so now I'll say Docker compose up and D so you can see everything has started now and everything is created so this is how you can move all your microservices to Docker compose and you can see now how it's easy to manage all our containers and all our projects so with

    
    07:51:01
    the help of one command you are able to run the entire architecture okay so earlier where you had to go to each and every project and start them individually in intellig now with the help of Docker compost that hazle is removed okay so this is how Docker compose helps you a lot and you just specify your configuration at one place and get going so that's about how you can move your microservices and manage them through Docker compos so now that we have all our containers up you can see the started

    
    07:51:42
    status so what we can do is we can head over to our browser and check in jurea if everything is up and running so here in browser I'll enter the address for urea okay and if you scroll down and hit refresh you will see you are seeing only two Services right now company service and the review service so we are not seeing rest of the services so clearly there is a problem and we need to identify the problem so here if you see I I'll say Docker so let let me type in talker PS and if you scroll up you are not able

    
    07:52:22
    to see the job micros service so it has failed okay now what I'll do is I'll say I need to see the logs so I'll say Docker compose down like so so I'll stop everything okay so one thing if You observe you only saw two microservices you didn't see like these two microservices like the company microservice so you saw company but you didn't see config server and the Gateway okay and there is a reason for this so the reason is we have not created the docker file for this okay so application hyphen Docker properties so let us

    
    07:53:05
    create that as well so I'll say hyphen Docker like so okay and here what I will do is I will make some changes over here so I'll say instead of Local Host post I'll say service registry over here okay and rest everything I believe will remain the same okay so this is for the Gateway micros service where you are able to make these changes now if you scroll down we also need to add one more thing over here so we need to add the settings for Zipkin and also we need to update these names over here okay so what I'm going to do

    
    07:53:48
    is I am going to like open up some other micros service here okay so I'll head over to this particular micros service and here you can see this is the setting for zkin so I'll just add that over here okay so this is done okay so this is added somewhere okay so it's added over here so I'll just replace it over here and I'll just get rid of it from here okay so this is in Gateway now I'll scroll up and here you will see we have everything set up to Local Host so I'll change all of this so I'll say service

    
    07:54:26
    registry here urea server static this is also service registry like so okay we have zipin configured here we have the review service so this I can change to a URL so I'll just copy this and I'll say review 8083 like so and I'll copy this as well and I'll add this for job as well so I'll say job over here okay and this can be 8082 okay and then I'll have this so this won't be review actually it will be review Ms so let us check the micros service name over here so if you scroll down you will have okay no so it's

    
    07:55:15
    review so this is what the the name will be so container name is what we are going to use over here and this will be job 8082 okay and this needs to be company service so here instead of company service I'll say company okay and Company will be 80 81 I believe yep so this is done and I don't think we are missing anything over here okay so this looks good so so this is Gateway now we need to make changes into config server okay so I'll head over to the application. properties over here and I'll just duplicate this

    
    07:55:59
    and I'll say doer here like so and I'll have to add the so I I'll have to say instead of Local Host over here I'll say service registry like so okay so this is done I don't think we need to make any other changes over here okay so I'll head save and I believe we are good to go okay so config server is changed Gateway is also changed all right now we need to check for job microservice as to what issue happened over there okay so I'll say talker compose up but this time I won't start it in detach mode I'll

    
    07:56:41
    just start it without detach mode so let us see what happens and this way we will see all the logs and the progress of whatever is happening over here okay so everything is starting and you're seeing logs for different microservices as you can see over here okay and uh you should see the logs for jobs microservice shortly so company starting okay so here is where job microservice is and we can see the stack trees you can see the error over here okay so we found the error and the error says application

    
    07:57:18
    fielded okay why did it fail so it says property spring profiles active imported from application hyphen Docker properties is invalid in a profile specific resource interesting so let us switch over to our coding editor so it is saying that there is a file and it is also giving you the line number okay so it's giving you the line number over here is 34 okay so application Docker properties within job microservice so here you can go go to application properties and line number 34 is this so it's saying that this is invalid like

    
    07:57:59
    you can't have the profiles set from application. properties because you're running it from Docker compose and by the time the application is booted profile is already set okay so what I will do is I'll get rid of this so if we want to set the property we can set it in the docker compost file so we have Docker compost. yaml and if you scroll up here you can set the profiles from here okay so I'll just get rid of that okay and uh I'll just close this so here I have got rid of that and now there is one more problem over here

    
    07:58:40
    which I see so here we are saying config server colon 8080 okay but if you go over here it's config server Ms so the service name is incorrect over here clearly so I need to update the service name as well and I'll hit save so we have made changes to the job microservice over here but in fact we have made changes to three service one is Gateway job microservice and the config server so we need to create image for all three and we need to push it to the docker hub okay so let us do that so over here so here we have started this

    
    07:59:22
    in non- detached mode so I'll say control C okay since I'm on Windows I'm saying control C if you're on Mac you can press control or command C okay so that would stop all the containers okay now once all the containers have stopped we will create images one by one and we will get them pushed to the docker Hub okay so I'll press the up arrow button and here you can see this command here which I had executed previously to create the image of job microservice so this will create the image for job microservice and uh it's running right

    
    08:00:00
    now okay okay so we got few errors now what are the errors the error says okay so because we need config server okay you can see there are quite a few issues there is no database up and running so since we start stopped everything like even PA SQL and there are no containers running this is the problem so what we need to do is we need to say Docker compose up hyphen D here so this will be created and all the containers will be running and we need to start a new Powershell window over here okay so here we have all the

    
    08:00:42
    containers R running or instead of starting a new Powershell window you can just do over here because I just started it in detach mode okay so we have database and everything running now I can create an image of job microservice so the image creation process involves starting the microservice running all the tests and so on so it needs things like database and all to be up and running okay so now we won't get that issue because the database and everything is up and running okay so this will take some time

    
    08:01:14
    wherein it will uh get the image ready okay but meanwhile what I can do is I can switch over to let's say I can go to desktop courses spring Boot and uh here I can switch over to config server okay and we need to create an image for config server as well all right so what I will do is I'll scroll up and I'll look for the command that I did use to create the config server image okay so I'll scroll up so in a new tab what I have done is I have switched over to config server directory and I'm running this command

    
    08:01:59
    over here okay and uh I'll say enter so this will create the image for config server and uh I'll create a new tab again okay and here I'll switch over to Gateway so Gateway is the service where we made the Chang okay so here I'll create the image for Gateway service okay and uh we need so Gateway service name is so Gateway image name is Gateway hyphen Ms so I can say Gateway hyphen Ms and I'll press enter here okay so this image is also being created and meanwhile the config server image is done so I can say talker post

    
    08:02:48
    and I can just pull in the config server image okay so this is being pushed and uh let us switch to the first tab so so this Docker image is pushed this is of config server and now let us switch over to the last tab of Gateway micros service and this is also built so we can push this so I can say talker push and I can take this particular image name okay so it picked in this name so I can say Gateway hyphen Ms and it'll push Gateway as well okay and here if you see in the first stab we have created the image of job micros

    
    08:03:35
    service so I'll copy this and I'll say talker sorry so I'll say Docker push image name so one thing you need to keep in mind is you need to make sure that you navigate to the directory of the project or micros service and then you create the image okay I'll tell you one problem that I just faced in so I was in the company microservice directory okay so if I scroll up a bit here let me scroll up okay so here I created the image okay and here I was in company microservice so this command I executed

    
    08:04:16
    but but I was in the company microservice directory okay and I was creating the image for job over here okay but that is not correct right so if you are in the company microservice directory and if you're creating an image for the job so what is happening is the image for company microservices being created with the name of job Ms so this is this is the problem over here so I was in the same directory and I created the image for job over here so actually I was in company microservice directory then what I did is I recreated

    
    08:04:51
    the image for company over here okay so if you scroll down over here you will see that I recreate the image okay so there are quite a few logs so here I recreated the image for company microservice okay and then I went I switched over to the directory of uh jobs and then I created the image over there so here you can see I had to switch over okay so so just make sure that you are in the right directory so you can see over here this is the command that I'm talking about so I realized that this was a mistake so I

    
    08:05:31
    recreated the company micros service image and then I switched over to the job microservice directory and then I triggered the request for job micros service okay and you can see the request is successful and the image is created so now what we need to do is we need to now start pushing the image for job microservice to dockerhub so here I'll say Docker so one second so Docker push job microservice and it will push all the changes okay so now we have recreated the images for all three microservices

    
    08:06:15
    all right and everything is pushed now we need to head over to company microservice directory because that is where our Docker file is and we need to say Docker compose up so I won't be running this in detached mode but I'll run it in directly normal mode okay let us see how this goes so we are seeing the logs and we'll wait till all the logs have completed okay and I'll keep a watch on the logs as to see if I'm not encountering any errors so you can see all the services are up now let us head over to urea

    
    08:06:54
    server dashboard now here I'm going to hit refresh and you will see all the services are up and running okay so this way we have got everything running in a Docker container along with config server and everything all right so everything is up and running you can see company service job service review service and so on welcome back so let us start talking about kubernetes and let us understand what is kubernetes so first I would want you all to raise your hand if you have ever been scared by the sheer number of containers

    
    08:07:36
    that you had to manage in Docker so this is a problem and one of the major problems that developers always have so if you're working on a real world project there are n number of containers that you will have to manage with the help of Docker and Docker compose now to solve this problem this is where kubernetes comes into picture so let us take a step back into history and understand how kubernetes came into picture or how kubernetes came into existence so the story of kuet is begins with Google yes that's right Google so

    
    08:08:15
    imagine the am amount of load Google has to manage with billions of searches happening every day and not to mention YouTube Gmail and all its other services are so popular that they have a lot of load now to manage this Google built a system named bog okay so the system was internally known as bog and it was so useful that they decided to create an open-source version of it and this project initiated around 2014 and this is what now is known as kubernetes or it is also sometimes referred as k8s but what exactly does kubernetes do

    
    08:09:00
    so simply put it is an open source platform that automates Linux container operations so it eliminates many manual processes involved in deploying scaling containerized applications okay and in other words you you can cluster a group of host running Linux containers and kubernetes can help you manage those clusters easily and effectively so kubernetes is essentially a platform designed to completely manage the life cycle of containerized applications using methods that provide predictability scalability and high

    
    08:09:38
    availability so consider a scenario where you are running multiple containers and you need these services to talk to each other you also need to restart them automatically if they fail and you need to have X number of instances always up and running for a particular service so this can be addressed by kubernetes so kubernetes provides you with a framework that enables you to run distributed systems resiliently and it takes care of scaling failover of your applications it provides you with deployment patterns and

    
    08:10:14
    more so you you define how your application should run and the ways they should be able to interact with each other or the outside world and once you define this kubernetes will take care of this okay now kubernetes did not become popular overnight its success is attributed to the fact that it addresses a critical issue as to how to manage and orchestrate containers at scale and not just that kubernetes also supports multiple contain container runtime environments including talker and so on so you can run containers on any

    
    08:10:53
    operating system on any cloud and in any region okay so this is why kubernetes is very popular so kubernetes like I said is essentially designed to manage the life cycle of containerized applications so that's kubernetes for you hey there welcome back so let us start talking about the benefits of kubernetes so the number one benefit that we have is service Discovery and load balancing so kubernetes can automatically expose your containerized services to the internet or any other services in the same cluster using a DNS

    
    08:11:38
    name or an IP address now if there is high traffic kubernetes can distribute Network traffic to provide load balancing and ensure that your deployment is stable for example if you are building a busy e-commerce website during a big sale and as the traffic increases kubernetes has the ability to evenly distribute the load amongst different instances of the site and this ensures that the site remains responsive and does not crash under heavy load so this is a number one benefit of kubernetes then you have automated roll backs and

    
    08:12:19
    roll outs so when you describe the desired state of your deployed container kubernetes can change the actual state to the desired State at a controlled rate so if there is a mistake kubernetes will roll back the change for you without any downtime for example if you're deploying a new version of your application and you discover critical buug in the update so kubernetes can quickly roll back to the previous version minimizing downtime and the impact that it will have on the users the next benefit we have is

    
    08:12:58
    horizontal scaling so kubernetes can scale up your application and it can even scale down with a simple command and you can even do this with the help of a UI or automatically based on CPU usage and other application specific metrics so in case of an unexpected search of users in your application kubernetes can automatically spawn more instances of your application to handle the increased load so this is about horizontal scaling then we have selfhealing so kubernetes constantly monitors the health of your nodes and

    
    08:13:40
    containers it does not replaces the container that fail so it will restart the container that don't respond to health check and doesn't advertise them to clients until they are ready to serve so for example if a container in your application crashes due to an unexpected error kubernetes will automatically restart without needing manual intervention and this will minimize the potential downtime or degradation in the service then the next benefit you will have is secret and configuration management now kubernetes lets you store

    
    08:14:18
    and manage sensitive information like passwords oord token and SSH keys so you can deploy and update secrets and application configuration without rebuilding your container images and without exposing any sensitive data in your stack configuration for example instead of hardcoding sensitive information like database credential into your application you can provide them securely using kubernetes secrets and this will improve the overall security of your application so these are the benefits as to why kubernetes should be used and how

    
    08:14:58
    it makes the life of developers easy so that's about the benefits of kubernetes so let us begin talking about the kubernetes architecture so kubernetes architecture consists of control pain and worker nodes so what are worker nodes so worker nodes are machines that run your application now each worker node contains a cubet as you can see over here and Cube proxy now what is a cubelet so cubelet is an agent for managing the node and the communication with the kubernetes control pane over here so all the

    
    08:15:44
    communication between control pain and the worker node is done by cuet now worker node also has something called as pods now what are pods so pod is nothing but the smallest and simplest unit in kubernetes object model that you can create and deploy so pod represents a running process on your cluster okay now what do you mean by cluster so cluster is nothing but a set of nodes that can be used to run containerized applications okay and they have pods now pods contains of multiple containers as you

    
    08:16:23
    can see in the diagram and there's a container runtime that is provided to them for execution purpose so this is about worker node and what all it has now kubernetes architecture includes worker node now worker node runs containerized applications and another component is the controlled pain which manages the state of the cluster now control pain has several components like API server it has controller manager Schuler and etcd okay so API server is nothing but the interface between the control Pane and the rest of the cluster

    
    08:17:03
    so these are all clusters that you have and API server is the communication medium between the control Pan and the rest of the cluster so API server you can say acts as a front end for kubernetes and its main management point of the entire kubernetes system okay now this is about API server what is etcd so etcd is a distributed key value store that holds the cluster's persistent state so there will be scenarios wherein you might want to hold some data that persists so that is where etcd come into

    
    08:17:43
    picture and it stores the configuration information which can be used by each of the nodes in the cluster okay and this is critical part of kubernetes it allows kubernetes to store the state of the cluster then you have Schuler so schul places the pods into worker notes so here you have pods in the worker notes and this is done by schul and this is done based on resource availability so schedul is responsible for Distributing work or containers across multiple nodes so it tracks the utilization and the

    
    08:18:21
    workload of the cluster nodes and makes sure that it allocates them appropriately and then you have controller manager that runs controllers to manage the state of the cluster okay so this is about the kubernetes architecture so you can uh think of this like you will have multiple worker nodes that will have multiple ports right running different containers okay then you also have container runtime and this is the runtime software that is responsible for running containers and then you have cuet and cuet like I

    
    08:18:57
    mentioned it's an agent that runs on each node in the cluster and it ensures that containers are running in the Pod and it acts as an interface with the control pane over here so this is about the architecture of kubernetes hey there welcome back so let us start setting up our environment to work with kubernetes so the number one thing that we will need to get started is mini Cube now what is mini Cube so mini cube is nothing but a tool that makes it easy for us to run kubernetes locally and like we know kubernetes is a powerful

    
    08:19:43
    container orchestrator system that manages deployment scaling and operation of containers in our system so we will need to have a way to run kubernetes onto our system and mini cube is that way for us so I'm going to head over to Google and I'm going to search for mini Cube kubernetes so here you will see the first link which is of the kubernetes website so we won't go there but instead we will go to mini Cube official website here okay and you will be taken to this web page over here so you can see mini

    
    08:20:21
    cube is local kubernetes which means it enables you to set up kubernetes onto your local system now here are some reasons why you might need mini Cube so mini cube is used for local development and testing okay so if you are running kubernetes and if you want to test your application locally with kubernetes then you can make use of mini Cube and mini Cube will mimic the real kubernetes cluster and enable you to work with it it is also important to use mini Cube for Learning and experimentation okay

    
    08:20:59
    since you are not working on production on development environment you can use it for Learning and production so this is why you can use mini Cube now should you use mini cube in production absolutely not so mini cube is intended for local development and test testing purpose and if you are deploying your application to production you will have a full scale kubernetes cluster provided by the cloud platform or on promises infrastructure so what I mean by this is if you are deploying your application to

    
    08:21:32
    Amazon you have the Amazon kubernetes okay so if you search over here Amazon kubernetes so it's called manage kubernetes service which is eks and then same for Google you have their managed kubernetes service so you can use that you don't need mini Cube for that so let's get ahead with the installation process so if you scroll down over here just make a note of all these requirements okay so you need two CPUs or more 2 gigs of free memory 20 gigs of uh free space internet connection and a virtual machine manager such as doer or

    
    08:22:16
    any of these okay so we have doer installed and you can choose which operating system you are on so I'm on Windows stable and you can choose the installer type so you can choose exe Windows package manager or chocolate if you're on Mac you can choose your architecture then you can go for binary download or you can install using home Pro okay so you just need to execute this command if if you have home bre installed or if you don't have you can go for this command which is binary installation and similar process we have

    
    08:22:53
    for Linux so I have Windows and I'll select this and I'll download the latest release over here so once you have downloaded the exe you can double click on this you can say yes and you can go through the process of installation it is a simple process that you can go through I'll say next and it will install this for me so the installation is complete okay now what you need to do is we need to start using mini Cube so for that I'll head over to partial okay and let us write a command over here so I'll say clear and I'll say

    
    08:23:35
    mini Cube let us see if this works okay so mini cube is all right so this command works for me and what I did is I just restarted my terminal so terminal was open U even before installing the mini Cube so after installing mini Cube I have to restart the terminal so I restarted and I typed in mini Cube and I can see that it's being recognized now I can say mini Cube do start or mini Cube start and this is going to start the local instance of mini Cube so you can see it is downloading kubernetes over here it is

    
    08:24:18
    starting control pan node okay and it is using talker desktop driver with root privileges which is fine now when I said uh mini Cube start I saw some processing and I got this error so it says that fail to start because virtualization is disabled okay so it says this computer does not have VT hyen X enabled okay and you need to enable the virtualization support on your computer and for this you need to restart your computer enter the BIOS and enable virtualization but I let's say I don't want to do that so let me try

    
    08:25:03
    running mini cube with a different driver so I'll say mini Cube start and here you have a suggestion driver equal to talker so I'll just copy this and I'll paste it over here okay so hyphen ien driver equal to Docker and I'll press enter okay so I'm getting an error over here so it says existing mini Cube cluster was created using virtual box driver so you need to delete that first okay so you need to say mini Cube delete okay so it'll delete this and now you can start using Docker so let us see if this also gives

    
    08:25:49
    us the same issue of virtualization so since I have Docker already installed and configured I can leverage that to start mini Cube now you can see I this took some time like there was some processing is what I saw and this is complete now and we did not get any error this time with Docker as a driver okay so we just have to make sure that Docker is up and running so this is done and you can see the message Cube CTL is now configured to use mini Cube cluster so what is Cube CTL so Cube CTL is a way using which you

    
    08:26:30
    can interact with mini Cube so in order to see the status you can say Cube CTL and I can say cluster hyphen info so this will give me the information and it says kubernetes control plane is running over here and cod DNS is running over here so this tells us that Cube CTL or mini cube is completely set up on our system and it's up and running okay so this way you can get this setup done okay now there are different options when it comes to starting mini Cube so you can say mini Cube start hyphen

    
    08:27:10
    hyphen driver talker you can even use hyperkit as driver okay so you if you wish to use that you can use that as well okay so this is about mini Cube and setting up your environment on your Windows or Mac machine hey there welcome back so let us start talking about mini Cube dashboard so mini Cube offers a dashboard which is a web based user interface that you can use to observe the state of your kubernetes cluster and even manage it resources so while you can do everything via a command line with the help of cube

    
    08:27:55
    CTL command you can even make use of dashboard which gives you a more visual representation and an intuitive way to interact with your cluster so how can you access the dashboard so to access the dashboard you need to say mini Cube dashboard the moment you press enter this will open up the dashboard in the browser so you can see it is taking a little bit of time it is saying enabling dashboard and it says like there is some addon that is needed and you will see this open up so this is nothing but the

    
    08:28:36
    dashboard here as you can see that we have don't have anything deployed yet and neither there is any name space okay and you can see different options over here so this is a visual representation of what you can do with kubernetes okay and this is inbuilt like we have not created this and this enables you to do things like monitoring managing resources accessing logs access control and it can also be a learning tool essentially okay so yeah this is about kubernetes or mini Cube dashboard I should

    
    08:29:13
    say hey there welcome to this class so let us start talking about pods so what is a pod in kubernetes so a pod is nothing but a basic building block in kubernetes and it represents the smallest Deployable unit you can think of it as a group of one or more containers and their shared resources such as volumes IP address and network ports containers within a pod run on the same worker node and share the same life cycle now pods are ephemeral and can be created scheduled and destroyed dynamically so

    
    08:30:00
    these are some of the characteristics of the Pod now let us talk about what a pod is not so pod is not a durable entity so if a pod fails or is terminated it cannot be restarted or resumed it instead a new pod will be created and it will be replaced pods are not designed for horizontal scaling on their own so scaling is typically achieved by creating multiple identical pods and distributing the workload amongst them using a high level construct like deployment or a replica set so you cannot horizontally scaled pod by itself

    
    08:30:41
    you need to do it with the help of deployment or a replica set now there are some key considerations when you're working with pod pods should be designed to be stateless like any state or data that needs to be preserved should be stored in external volumes or managed by highlevel abstractions like stateful sets Parts communicate with each other within the same cluster using Local Host so containers within the Pod can communicate with each other via interprocess communication mechanisms like shared

    
    08:31:20
    memory pods are assigned a unique IP address within the cluster which means that they can communicate with other ports or external services using that same IP let us talk about life cycle and availability so life cycle and availability of ports are managed by kubernetes so it monitors the health of the ports and takes action like restarting or rescheduling pods whenever necessary now pods can have Associated labels and annotations which can be used for grouping filtering and selecting ports when we Define deployments

    
    08:31:58
    services or other kubernetes resources so how can a pod be created so this is a sample code which is used to create a pod over here okay now let's break it down so you can see at the top you have API version now this specifies the version of kubernetes API that you are using to create this object and P is nothing but an object in kubernetes then you specify the kind so this specifies the type of cuberes resource that you are creating and in this case it's a pod then you specify the data type that uniquely

    
    08:32:38
    identifies the Pod okay then you have metadata which is nothing but the data that is specified to uniquely identify the Pod then you have things such as spec okay now spec describes the desired state of the Pod and what applications or Services it should run it includes the details about the containers volumes and other data so if you take a look at this container tag over here you will see it includes details like name image image ports and container Port as well so name is NX over here and this is the

    
    08:33:21
    name of the container that will be running in the Pod and image this is the image that we are using and this is a Docker image that we are specifying over here then we have ports where we are specifying the network ports that the container should Expose and container Port 80 here in this case specifies that container should expose net traffic on Port 80 what you can even do is you can add more containers to the port so here this is the different version of the same file okay you can see here I have

    
    08:33:56
    one more container specified and this container is now of redus okay so here I'm specifying the name and the image that this particular thing would use all right so let's get handson with this and let us create our first pod so now now to go Hands-On I'm here on my desktop and I have created a new folder called k8s okay and I will be using a different IDE than intellig for this purpose and I am making use of Visual Studio code and I have even opened the folder k8s over here now if you are not familiar with

    
    08:34:37
    Visual Studio code or if you don't have it installed I would recommend heading over to Google and searching for visual ual Studio code over here and you can click on this particular link first so it is an IDE which you can use and it is free and open source so you can download it for Windows Mac or Linux so whichever operating system you are on you can download it and you can open it okay so after installation what you need to do is you need to go to file you need to say open folder and you need to select

    
    08:35:14
    the k8s folder that you have created on your system and then it will open up something like this now here what we need to do is we need to create a new file and we will call this file as first hyphen pod and we'll specify this as yaml okay so I have defined or I have created this particular file so after creating this file we need to add the code so I have the code written over here in this particular notepad so what I'm going to do is I'm going to Simply copy paste this code here so I have a code for a

    
    08:35:58
    single container as well as for multicontainer so let us copy this and let us save this over here okay so this is the code that I have added now we need to create this pod now how do you create the Pod so for that we will head over to our terminal okay before heading over to terminal just make sure that you have saved the file okay so if you were seeing a DOT over here like this okay you can see this round dot it means that you have not saved the file so you need to hit contr s and it will change to

    
    08:36:35
    cross this way now in order to work with or in order to create the Pod we will head over to window Windows partial or any terminal that you have on your system and you need to navigate to the directory k8s okay so here I'm in this directory k8s okay I'll clear this and I'll run the command I'll say Cube CTL apply hyphen f first hyphen pod. yaml okay and I'll hit enter now you will see the pod has been created now this command is used to create the Pod and hyphen f is followed by the file name or the path to the file

    
    08:37:24
    that contains the resource configuration okay and we have the resource configuration defined over here now when you run Cube CTL apply f file name kubernetes reads the file interprets the resource definitions and applies them to the cluster if resource already exists it will update them to match the definitions in the file and if they don't exist it will create them now let us modify the spot that we have created so here I'm going to open this notepad and I'm going to copy this second definition that I have over here so I

    
    08:38:00
    can paste this remember to save and then if you go over here and if you say apply you will see my pod is invalid okay and P updates may not add or remove containers now this suggests that you cannot modify the given pod now why is that so so in kubernetes the specification of pod is immutable meaning that pod once created you cannot directly add or remove containers from it and the reason for this is consistency so kubernetes ensures that pods are consistent and predictable as well okay and atomicity another reason

    
    08:38:44
    wherein pods are treated as atomic units okay and uh by allowing modification to Ports container could introduce complexity in managing ports life cycle and also ports identity so every pod has a unique IP address or host name assigned and modifying the containers within the Pod could affect the pods Network so now we have this pod created and if we wish to have have a new pod or a pod that has a different configuration you need to add that as a new pod okay so you have Cube CTL get pods so if you

    
    08:39:26
    run this command you will get the list of all the pods that exist in your system so right now we have one pod now what we will do is we will modify this pod and we will say this is my new pod and I'll hit save so what we doing is we are now instead of updating the existing pod we are now creating a new pod so I'll say over here Cube CTL apply hyphen f first pod. yaml and you will see this message here and if you get the pods you will see that the status is container creating so you can say get pods hyphen W so hyphen W will

    
    08:40:11
    run this command in the watch mode and you will get get Live status updates so as of now the status update is not there because it's already changed to running okay so to exit you can say control C or command C on Mac so this will update and this is known as a watch mode okay so this way you can get your pods created and you can view them so this is all about pods just remember one thing that kubernetes does not allow you to make changes to Containers within a pod and it is recommended to create new pods

    
    08:40:48
    with the desired configuration and terminate the existing pod okay so just make sure to keep this in mind all right so this is about pods and how they work hey there welcome back so let us start talking about service in kubernetes so what is a service so so service in kubernetes is an abstraction that defines a logical set of PODS and a policy by which to access them and this is sometimes called as micros service now what I mean by this in simple terms is a service is nothing but a way using which you can access the ports all right

    
    08:41:36
    so why do we need such a thing so this is needed because ports in kubernetes are ephimeral which means that they can be created anytime and they can be destroyed right so you cannot rely on pods or pod IP to access them because IP is dynamic and it will change if a new pod is created and added to the cluster so how would you access and make sure that you have a single access point to your pods or containers so this is where service comes into picture so with the help of service you can have persistent

    
    08:42:12
    connection to the ports it needs to access and regardless of changes in those ports so this is irrespective of changes in the ports so Services enable you to help communicate with the p so now given the ephemeral nature of PODS this greatly simplifies the network configuration and provides a simple way for us to access other ports right now the question is how do you define a service so here on my screen you can see a simple yaml file and this file specifies the application classification the ports protocol and

    
    08:42:56
    the set of PODS that uh can be targeted with the service okay so here you can see we have specified the API version first then the kind of the object this is so it's a service kind and this specifies the type of kubernetes object or resource that you are creating and then you have the name that you have given to this particular service and this is comes under metadata and metadata is the data that helps you uniquely identify the service like for example its name then you have the spec and this section specifies the desired

    
    08:43:35
    state of the service and this will include various properties like selector ports so select ctor this field is a map of Key value Pairs and a service will route the traffic across the set of ports that match the select a label okay then you have ports and ports is the array that defines protocols and ports okay so here you have TCP protocol ports 880 and Target Port is the port on the port where your traffic is routed okay it can be a port number or a name if not specified it defaults to the same as the

    
    08:44:14
    port field so this is the definition so now let us head over to visual studio code and let us start defining our service so here I have this notepad wherein I have written the definition of a sample service now what I'm going to do is I'm going to copy this information and I'm going to create a file over here okay and I'm going to call this as first service. yaml okay and I'm going to paste the service definition over here let me hit save over here so be sure to save the file now if you switch over to

    
    08:44:55
    your terminal you need to run a command so here we will say Cube CTL apply hyphen f and here instead of first pod we will say first service like so and I'll hit enter now you will see first service is created and you can get the service using cctl get service and you will see that there is this service that exists which is of type cluster IP and you have this IP here and this is the port and the ages it was created 8 seconds ago so this way you can check for services hey there welcome back so let us start

    
    08:45:47
    talking about how you can expose your application so let us talk about three types of services that we have when it comes to kubernetes and the type of service determines its accessibility whether it is from within the cluster from the node hosting the board or from outside the cluster entirely okay so this brings us to the most most common types of services which is cluster IP not port and load balancer so cluster IP is the default type of service so whenever you don't specify the type you will get the service of type cluster IP

    
    08:46:31
    now what does it do is it gives a service its own IP address to communicate with other services within the cluster and these services are only reachable for from within the cluster and they are not exposed outside okay then you have not port and nodeport expands on cluster IP and exposes the service on the same port across each node okay and this makes the service accessible from outside the cluster using node IP okay and nodeport so this way you can access the service using nodeport now what is load balancer so

    
    08:47:14
    load balancer exposes the service externally using the cloud providers load balancer so you can think of it that it builds on not port and assigns a fixed external IP to the service and this is typically used in cloud-based environments where load balancer can be provisioned automatically okay so if you have to see how you can specify the type of the service you can see this example over here so here in our example we did not specify the type and when we created the service you can see that we got the

    
    08:47:50
    service type of cluster IP but if we specify the type you will get the type as that of load balancer over here if you run this okay and this is used to expose your application to the outside world because it will give you a fixed IP to your service which can be accessed externally so this is about types of services and how you can expose your application to the outside world hey there welcome back so let us start talking about replica sets so what are replica sets so replica set is a kubernetes object that is used for

    
    08:48:37
    managing and scaling a set of identical ports now why would you need a set of identical pods so the there is a reason for this and one reason is high availability so running multiple identical replicas of your application SP ensures High availability so if one part fails or becomes unresponsive the other replicas can continue serving the application's workload without any Interruption and this redundancy can help maintain the overall availability and reliability of the application then you have load balancing so identical

    
    08:49:18
    pods enable load balancing across multiple instances of your application so by Distributing incoming requests or traffic even among the replicas you can handle increased load and Achieve better performance and scalability load balancing also ensures that there is no single pod that becomes overwhelm with traffic and it allows for efficient utilization of resources then you have scaling so having identical pods makes it easier to scale your application horizontally because when the demand for your

    
    08:49:56
    application increases you can simply scale up the number of replicas to handle the additional workload and kubernetes can automatically distribute the load among the replicas and this enables your application to handle more traffic without compromising the performance then you have something called as rolling updates so identical Ports play a crucial role again during rolling updates or deployments so when you need to update your application to a new version kubernetes follows a rolling update strategy which involves gradually

    
    08:50:34
    replacing the old pods with new ones and having identical ports ensures that the application remains available throughout the update process as new pods are gradually introduced and the old ones are gracefully terminated then you have service Discovery and load balancing so identical pods with a common label can easily be discovered and load balanced with or by another kubernetes resources such as Services now Services can automatically discover and distribute the traffic to all the pods that match a specific label

    
    08:51:14
    selector and this provides a seamless and a consistent experience for client accessing your application okay so why do we need replica sets Okay so pods are ephemeral in nature and again they can be created and destroyed right and ephemeral nature makes it challenging to rely on a single P to provide a particular service so replica sets mitigate this problem by ensuring a certain number of identical pods are always up and they are always running and this is really crucial for load balancing and for ensuring the

    
    08:51:53
    availability of the application so this is about why we need replica sets then what is replica set not okay so a replica set is not designed to handle rolling updates or deployments now replica set only focuses on Main maintaining the desired number of replicas at any given point of time so if there is a rolling update or deployment happening even at that point replica set will be responsible for making sure that there are some X number of replicas available and another point is it does not provide declarative

    
    08:52:31
    updates to the Pod it manages okay so to update the Pod you need to create a new replica set with updated configuration and delete the old one so this is about replica sets now what should you keep in mind about replica sets so replica sets use a selector to identify the Pod it manages all right so this is one point and selector defines the criteria for matching pods so selector is nothing but a label that is used or a criteria that is used that enables replica set to identify which pod it has to mat manage and this

    
    08:53:13
    is something that we'll see shortly in practicals so also when creating a replica set you specify the desired number of replicas that you wish to have at any given point of time all right so this is something that you have control on as a developer also if a pod is managed by replica set gets failed or deleted the replica set will replace it automatically to maintain the desired replica account so this is another point then you have replica sets are often used with deployments and deployments are the ones

    
    08:53:53
    which provide updates and rolling deployments are defined there and these are done by managing the replica sets then you need to keep in mind that when updating the configuration of PODS such as image versions or resource requirements it is 100% recommended to use deployment ments instead of directly modifying the replica set because deployments will make sure that the updates are done properly and are applied to the respective ports so let us take a look at an example of a replica set so here I have a notepad

    
    08:54:31
    file which defines the replica set over here and you can see over here the API version I have defined the kind of object that it has and I have specified replica set over here then I have meta data defined over here so this provides the data that helps you identify the replica set uniquely like the name of the replica set okay then you have the spec defined over here now spec has multiple labels over here as you can see okay so here we are talking about replicas so like I said that you as a developer has the

    
    08:55:12
    ability to Define how many number of replicas you want at any given point of time for a particular pod so here I have specified three as the count so at any given point of time three replicas will be made avalilable for this p over here now here I have select a field and this section is used by replica set to identify the pods that it should manage okay so for example here as specified match labels and app coolon in so replica set will manage this particular pod okay and it will make sure that there are three replicas always

    
    08:55:53
    available for this particular label then we have template so this section defines the templates for the pods that replica set will create okay so metadata under the template defines the metadata for the ports and it includes the labels that will be assigned for that particular Port so this is the label that is being assigned and here you can see this is the label that is being managed and then you have spec over here and spec under the template tag defines or describes the state of the desired ports so in

    
    08:56:31
    this case we are specifying that each pod should run a single container using this Enix image and this is a version of the image and we are also specifying the container Port over here okay so this is the definition of the replica set file so I'll just copy this and I'll head over to visual studio code and here I'm seeing a popup which says Docker is installed on my system do you want an extension for this okay from Microsoft for visual studio code so you can just say install if you wish to so this will

    
    08:57:10
    just enable you to manage talker okay so back to this particular thing here and here I'm going to again create a new file okay so I'll say replica set so I'll say replica set. yaml something like this and I'll paste the definition over here okay so I believe the extension is installed now okay so you can see it makes working with talker easy with all the syntax highlighting and everything build image and all so it's good to have this so yeah so yeah I have created a replica set over here and now let us create this okay so let us

    
    08:58:00
    create this using terminal so I'll head over to my terminal here and here what I will say is I'll say Cube CTL apply hyphen f and here here I'll say replica set. yaml okay I'll just remove this Dot and backward slash so you have this command here now if I say enter you will see the replica set is created so you can now check the pods in the watch mode and you will see the pods are running and you can see there are like three replicas of this P here okay because you had specified three in the count when defining the replica set so

    
    08:58:47
    here there are three replica sets that are like three pods from the replica set that are running over here okay I can just exit the watch mode and I can even say get pods normally and you will see the same output I can even get the replica set using this particular command so I can say replica set here okay you can see desired count is three current is three and ready three and age is 46 seconds so this was created just 46 seconds back okay now let us say I delete a pod or one pod gets deleted so

    
    08:59:28
    how do you delete a pod so you will say Cube CTL delete pod and you will specify the Pod name so let us say we delete this particular pod okay so I'll copy and I'll baste okay and delete spelling is incorrect so I'll just make it correct okay so Cube CTL delete my replica set okay now if I run this the pods gets deleted and now if you run this in the watch mode you will see that there is one more pod that was created automatically okay and this was created without you doing anything and this is

    
    09:00:09
    replica set in action right now so you can see how it's managing the replica so one pod was deleted and another one was immediately created all right so you can see over here it was within a fraction of second so if I keep this open over here okay like so okay so let me keep this open here and what I will do is I will open another instance of Powershell over here so let me say so I'll create one more instance and I'll open this like this in a new window or how do I move so let us now begin talking about

    
    09:00:55
    the concept of deployments in kubernetes so what is a deployment a deployment in kubernetes is a highlevel concept that manages the replica set and a deployment provides updates for pods and and replica sets so if you take a look at pods and replica sets they cannot be changed right now you need a way to seamlessly roll out updates and everything during the deployment and development process now how would you do that so this is where the deployments in kubernetes come into picture so what you have to do is you have to only describe

    
    09:01:38
    the state in the deployment object and the deployment controller changes the actual state to the desired state to at a controlled rate for you now this means that you can seamlessly roll out new features or roll back to previous versions without any Interruption because deployments is working for you so let me show this to you so we are going to create a new file and I'm going to call this as first deployment. yaml like so okay now here I'm going to have a notepad being added here so you can see I have this notepad over here where

    
    09:02:22
    I have written the definition of my deployment file okay so here you can see I have the API version defined then the kind of the object that I'm creating which is deployment I'm specifying the name over here so metadata helps you uniquely identify a particular object and here I'm saying my deployment is the name of this object then I have spec created over here okay now spec defines the desired state of the object so this includes the number of replicas the selector and the template over here okay

    
    09:03:03
    now replicas specify the number of replicas that you want to run for a particular pod and in selectors you specify which ports you want deployment to manage okay so in this case the selector is looking for the pods label app my my app okay you can see this is the label over here okay then you have template then this template is used for creating new pods okay and this template includes the Pod specification or spec which includes things like POD containers the names of those containers and the images the containers should run

    
    09:03:46
    so this is all the definition that we have okay so what we're going to do is we're going to move this to our Visual Studio code over here okay in the first deployment. yaml file now as you can see you have created the deployment object over here now why do you need deployment objects so number one use case or the reason you have is automated roll outs and rol backs so deployments are designed to facilitate updates to your application in a controlled manner now when you update your application version or

    
    09:04:21
    configuration kubernetes will replace or it will gradually replace the old instances with the new ones ensuring there is no downtime during the transition and if something goes wrong kubernetes can also roll back the changes so this is the benefit so this is about automated roll backs and rollouts then you have scaling so deployments also allow you to scale up or scale down to match the demand okay and then you have health monitoring so kubernetes continuously monitors your health of the pods in deployments and

    
    09:04:56
    restarts any pods that fails it ensures selfhealing of your application okay so we have created a deployment file okay now let us head over to the terminal okay and and I'm going to just minimize this one okay and here I'm going to just create that particular deployment so I'll say first deployment do yaml okay sorry so okay so I got an error it says no objects and the reason is I have not saved the file okay so you need to make sure you save the file and then here you need to run this command so you will see

    
    09:05:41
    see the deployment is created over here now you can say Cube CTL get deployments to get the deployments that have been created and you can see the status over here okay so this command will give you the deployments and you can even get the pods over here so I can say get pods like so and you can see image pull back off so you can see there are quite a few pods that are up so let me run this in the watch mode okay so you can see there are quite a few pods that are running in okay and there is I believe some error

    
    09:06:21
    that is coming in this image okay but this way you can see the deployments going on and you can even take a look at the parts that have been created by the deployment now you also have describe command which enables you to see the event related to your deployments including any errors or or anything okay so you can say Cube CTL describe deployment and you can add the deployment name over here so the deployment is my deployment over here okay so I can say something like this now you can see all the events over here

    
    09:07:02
    okay so you can see three desired three updated and three total zero are available and three are unavailable okay now if you see over here so you are so you can see all the logs over here as to what happened okay so you can just go through this if you wish to and if you wish to describe your deployment so you can even check the logs for your pods so I can say get pods and you can say Cube CTL logs and you can add the log like the Pod name over here like so and you will get the logs for for that

    
    09:07:41
    particular pod so this pod does not have any logs is that so so so yeah I believe there is nothing for this particular pod but let me check for these parts so you can see over here container my app in is waiting to start and failing to pull image so there is there is this error that we are seeing okay and uh wait a minute so my app so the there is no container called my app over here is what I can see okay so it's failing to pull the image and that is why it's failing over here so here like image so

    
    09:08:23
    this image does not exist okay so we need to add a valid image over here and if we do that so let me add this image here and let me apply this okay so if I save this and if I go over here and if I say apply the deployment and if you go in watch mode you will see okay so this p is being terminated the deployment is being terminated so let me check the status so I'll just run pods over here and you can see it's started now okay because we have specified a valid image name here okay so it terminated everything and it

    
    09:09:13
    started the required p over here okay so yeah so this is deployments in action okay you can even use describe to describe your deployments now how would you manage changes in pods with the deployments so to update the Pod and add more containers the recommended approach in kubernetes is to use a high level resource called deployment okay now this is because deployment manages the life cycle of the pods okay so a typical workflow to update the Pod and add more containers using a deployment would be

    
    09:09:50
    to have a deployment file okay and in the deployment specification you can specify the number of replicas so let's say if you want to make any updates you can update the changes over here okay and if you want to add any containers you can add more containers over here and then you go back and apply the deployment and the changes would be applied and this is similar to the change that we just did over here so we just updated the image name over here and you could see those changes applied okay so make any changes over here and

    
    09:10:24
    apply and those changes will be reflected in your application so this is about deployments and how you can work with them hey there welcome back so let us begin begin deploying sekin rabbit mq pogress to kubernetes and for that we will first Define the folder structure or the project structure over here so here I have some files but I will be creating a new folder over here okay so I'll say one folder can be bootstrap and I'll have one more folder okay so this folder won't be under this one but it

    
    09:11:08
    would be in the main directory so I'll say Services okay so these are the two folders that will have everything that we need for deployment okay now within the services folder I'm going to have a folder for defining the configuration and the deployment for Zipkin then I'm going to have one for rabbit mq and then okay so they all are being listed under zkin so I'll just track this to under services okay so we have under Services we have two folders now and I can add one more folder over here okay so one is for Zipkin one is

    
    09:11:52
    for rabbit mq and then we have one more service post okay so I'll add one for post here so this is where we have Services now on the bootstrap we can have all our microservices okay so you can have company okay and then under bootstrap you can add one more folder you can call this review and then under bootstrap you can add one more folder and you can call this as job like so okay so you have multiple folders like company Job review and then you have Services okay so it's good to organize things this way

    
    09:12:37
    okay because organizing things helps you find important things and also helps you with easier deployment for example if you want to deploy all your services like not your micr services but all these services like pogress rabbit mkin Zipkin so you can just run a simple command Cube CTL apply hyphen f and you can say k8s SLS services so this particular command will take everything like all the files under all the sub folders as well under services and it will deploy them okay and to deploy the microservices company job and review you

    
    09:13:17
    can run the same command but instead of SL Services you can say slash bootstrap so this can help you with different aspects like organization maintainability and also add modularity to your structure so this is a structure that we are going to follow okay and what you can do is if you don't want you can just move these files so I'll just create one more folder I'll say first and under first I'll move all the files that I have over here okay so that will just make things look a bit cleaner over here

    
    09:13:58
    okay so this is the structure that we are going to follow and we are going to build on okay so yeah I would recommend you all to create these folders and then we can get started with with the next step hey there welcome back so let us start defining the configuration that we need for Zipkin to be deployed into kubernetes so we are going to need couple of files over here okay so here under Zipkin folder I'm going to create a new file I'm going to call this as Zipkin service. yaml and I'll add one more file over here

    
    09:14:43
    okay I'll say Zipkin deployment so this is the deployment file that I need okay so why do we need deployment and service file so deployment will be responsible for maintaining a specific number of replica pods running in the cluster and service will be responsible for providing the network access to one or more parts Okay so so I have the configuration ready with me and the configuration is here in this notepad Okay so you can see here I have like this is the deployment and let me move this to the respective files

    
    09:15:26
    okay so I'll copy the deployment first I'll paste it over here here and I'll hit save and then I'll move the service part as well okay and I'll copy this and I'll paste it over here so let us understand what is happening now okay so let's talk about deployment first so here we are specifying the API version the object kind and then we are specifying the metadata so this is the name of the deployment here Zipkin and then we are telling Zipkin or then we are specifying that we need only one replica and that is what this deployment

    
    09:16:05
    tells and then we have the selector defined okay so we say app Zipkin and this selects the Pod with the label app coolon Zipkin to manage okay and then you have the template over here and this template also has labels of app colon Zipkin over here okay so this defines the labels to apply to Ports created by this deployment all right and then spec defines the container definition okay so you have container with the name Zipkin and here is the image that you are using and then here is the container Port that

    
    09:16:46
    you are exposing so what you're seeing is you are saying I want to expose 941 within this particular container and this is a standard P for Zipkin HTTP collector interface so that is what we are defining and creating in this deployment file now in the service what we are doing is we are exposing or providing network access to one or more parts okay so here we have this General tags that we have mentioned or general properties and then over here we are specifying the port under the spec now Port uses TCP

    
    09:17:27
    protocol is what we have mentioned over here and Target Port is 941 so this defines the port configuration for this particular service and it Maps the port 941 on the service to Port 941 on the Target Port okay or on the target pods not Port sorry so this is what it does and then you have the type of the service defined here and the type you are creating is load balancer now a load balancer service will provision an external load balancer that can Route traffic to the pods selected by the service all right

    
    09:18:06
    so I hope this makes sense so I'll hit save and we will save this configuration for zkin so together this configuration will deploy a single replica of Zipkin running in container so this container name is also Zipkin and this container will expose the port 941 and we also have a service named Zipkin that routes the external traffic to the Zipkin container through a load balancer so I hope this is making sense as to how service and deployment both will work together to bring Zipkin to life from within the kubernetes cluster

    
    09:18:51
    so this is about Zipkin and the configuration that we need for Zipkin welcome back so let us start talking about the configuration that we need to Define for rabbit mq so here I'm going to create a couple of files so I'm going to say rabbit mq hyen service. yaml okay and I will duplicate this particular file and I'll paste it over here in the same folder and I'll refactor it and I'll rename it to deployment okay like so so I have defined two files or I have created two files for deployment and service or of rabbit mq

    
    09:19:41
    so I have the definition ready for the deployment as well as the service so I'm just going to copy this entire file and I'm going to head over to deployment and paste it so this bottom part is of service so I'll cut this over here and I'll move this to service. yaml over here okay and I'll save both the files so just don't forget to save okay so we are creating two files here a deployment that will manage the desired state of our application and it has all the definitions that are needed for the

    
    09:20:17
    deployment to be created and we have specified the replica over here as one okay so this will make sure that there is only one replica for rabbit mq up and running at any given point of time so this deployment file is necessary for this very reason where it helps you to manage the number of of replicas the updates and even selfhealing so let's say if I have defined one replica over here and if this one replica fails then the deployment will make sure that there is one more rep instance that is created

    
    09:20:55
    for rabbit mq and the service is not town okay and we have specified the container over here like the container definition wherein we have said the container name is rabbit mq and image is this image and we are exposing a couple of ports over here okay and we have specified the app label over here as well so this is about deployment and then we have service file and service file like we know it enables us to get a stable IP since pod can be deleted and created any time so IP keeps on changing for the Pod so service file helps us

    
    09:21:34
    with a stable IP and it's also helping us with the load balancing okay and it also enables us to access this particular service from outside so that is why we are creating this service file and this particular file is enabling us to define the service for rabbit mq so this is about the Rabid mq service and deployment welcome back so let us get started by defining the configurations for pogress SQL so handling of pogress SQL will be slightly different as compared to the other services rabbit mq and Zipkin that we have over here and

    
    09:22:26
    there is a reason for this because we want the data in pogress to persist and also there are some connection details and little bit of configuration that we have with posis SQL so how do manage this so when deploying a postgress SQL database on kubernetes it makes sense to use a config Mac State full set volume and a service so these are the four things that we are going to need okay now what is a config map so config map is used to store configuration data in key value pairs so let me show you the

    
    09:23:05
    configuration so I have this notepad here wherein I have the definition for all the four file types so you can see this is config map and here I have the definition of configuration or the configuration settings in the form of key value Pairs and this can include things like connection strings memory strings and other things as well that can be used for pois SQL tuning now we are creating a separate file to maintain the configuration and the reason for this is it helps in separating the configuration from the image and the

    
    09:23:45
    deployment and allows for a bit of natural adjustment if you want to in future okay so that is why we are creating a separate file over here and also this can be reusable so this is another reason why you should have a separate configuration file so you can reuse this with different environments and instances okay so this is about config map so we are just storing configuration in config map now the next thing we have is service over here so service like we know it is used to provide a stable endpoint for the applications to connect

    
    09:24:24
    to pogress SQL okay so that is what we are doing over here and then we have a stateful set over here now what is a stateful set so stateful set is used to manage stateful applications because databases require persistent storage and specific Network identity right because ports can be started and killed so you need to have a mechanism for data to persist and that is where stateful set come into picture but the next file we have is the volume file and this volume file represents a storage location and

    
    09:25:04
    for a database like postgress SQL where persistence is crucial we need a volume file okay now this is needed because we need data persistence now when a p dies the data in its storage can be lost and using a volume like persistent volume or persistent volume claim like we have defined over here it can ensure that the data remains intact so this is one reason why we have used and also performance so you can choose different types of storage backends based on your performance requirements here okay but

    
    09:25:38
    persisting data is the main reason why we are adding a volume so let us move all of this to visual studio code so I'll just copy all of this and I'll create a file over here okay so let me create a file called config map so I'll say config map. yaml and I'll paste everything now let us move everything to their respective files so I'll create one more file called service service. AML and I'll create one more file called stateful set okay so State full set. yaml here and I'll have one more file created here okay and I'll

    
    09:26:27
    call this file as volume volume. AML now let us move the code in their respective files okay so here after config map I'll copy everything okay and the next part that we have after config map is service so I'll head over to service I'll save this and I'll head over to service here and I'll move this to service so this is the service definition here okay so if you scroll up this is the definition of service okay so I'll just select all of this till the end okay and then we will head over to State

    
    09:27:13
    full set okay here and uh here at the top I have the definition for stateful set so I'll press backspace and I'll copy the volume definition to the volume file okay so I'll move this to volume file here like so so we have all the definitions set okay now let us understand what each thing means so we'll start with config map now here in config map we are actually specifying the API version the kind of the object the name of the metadata and here we are specifying few configurations as you can see so these

    
    09:27:55
    are key value pairs that represent the configuration data so we are seeing the database name is membar X over here and then we are saying the database user is membar X again and then we have the password as embar X okay so these are three configurations that we have added okay then we have the service file so service defines how to access the pods okay and here we are specifying like the metadata the kind and API version the selector the ports and the type which is cluster IP so service type says it's of

    
    09:28:37
    type cluster IP and cluster IP makes it reachable only within the cluster all right then we have stateful set so stateful set will manage the deployment of a set of a pod and guarantee the ordering and uniqueness so here in the beginning we have standard things like uh API version kind metadata and so on and then we have defined the spec over here okay so we have specified the service name as part pogress the replica as one and we have the selector which matches the label of PA over here okay so what it will do is it

    
    09:29:20
    will select the pods with label app colon PA all right and now under template we have defined the template for creating the pods so we have the metadata wherein we are specifying the labels over here and then we have the specification of the containers okay so this defines the configuration for the container named posess over here image we are using is of the pogress SQL so this is the official image that we are getting and we are specifying the image pull policy over here then we have EnV from so this is going to import the

    
    09:30:01
    configuration and environmental variables from the config map named posis config okay so if you you go over here you have this config map called pogress config so this is going to be imported over here okay and then we are defining the resources over here okay so we are saying request under request we have CPU 100m and memory of 256 and limits we have specified some limits over here okay so these are like different configurations of the memory and CPU capacity that you wish to have okay and then you have volume mounts

    
    09:30:41
    over here so this defines where the volume will be mounted in the container okay so we have specified the name and the path of the volume Mount now if you scroll down we have volume claim templates so this is a template for creating persistent volume claims now what does persistent volume claim means so persistent volume claim requests a specific amount of storage that can be used by a particular pod so we are seeing access modes as read write once okay this is the access mode that we are specifying and we are specifying the

    
    09:31:19
    storage wherein we need five gigs of storage okay so this is the definition of the stateful set and then we have volume. yaml okay wherein we have created a volume of persistent volume claim all right and we have named it as pogress PC volume claim and the label of the app is postris over here and then within spec we have defined the storage class name as manual and this specifies the storage class name to use and then we have the access mode and the resources again or specified over here so this is the

    
    09:32:00
    configuration that we need to do for pogress SQL and these configurations together set up a single replica PA SQL database within the kubernetes cluster and they include the configurations for environmental variables how to access the pods and how to manage the deployment and how to handle storage ensuring that the data persists even if the pods are restarted so that is really important so this is about the configuration for pis SQL hey there welcome back so now we have the configuration set for all our

    
    09:32:46
    services and now it's time to run them so what I'm going to do is I'm going to delete first whatever I'm already running so if you see over here and if I run get pods you will see there are quite a few pods that I'm running already and there are quite a few deployments as well like so so instead of getting deployment pods and services individually I can say Cube CTL get all and you will see that it gives me a list of everything like replica set deployment service and then pods as well okay so what we need to do is we need to

    
    09:33:28
    start deleting all of them and then we need to start deploying our services so this is something we created for learning purpose so we will delete all of this so I'll start by deleting deployments now I'll say Cube CTL delete deployments hyphen two times all again and then I'll say name spaces like so okay so this will delete all the deployments now I need to delete all these services so I'll just run the same command but I'll replace this with Services okay and then I'll run the pods over here like

    
    09:34:12
    so so you can see now everything is delet it okay and you can like run Cube CTL get all you can see few replica sets still exist okay so you can even delete them so I can say replica sets okay and if you say get all you will see like nothing exists now now okay so we have uh we have cleaned everything it's important that you go in order essentially so you delete the deployments first Services first and then you have ports so if you're deleting deployments first deleting deployments will cause the associated

    
    09:34:57
    replica sets and ports to be deleted as well because you're deleting the higher level entity and then if you delete the services after deployments this ensures that you don't have Services attempting to Route traffic to non-existent Ports and then you finally delete the pods which are not managed by any deployments out there okay and you need to be careful about uh the delete commands Okay because we are running them across all name spaces so everything is deleted here so now since we have deleted

    
    09:35:32
    everything that was running now it's time to run our services so we are going to start with pogis SQL so right now I'm in key at s directory and I'm going to say Cube CTL and I'm going to say apply hyphen f and let me say services and I'm going to go to pogress and I'm going to run deployments okay so for PA we did do not have deployments yaml so you just have to go to the directory here and you just have to press enter so it will pick up all the files and it will get everything created okay so now if you say Cube CTL

    
    09:36:17
    do getet all so you will see like everything for pogress is up and running so you have a pod you have a service and you have a stateful set as well all right so this is how we can get pogress SQL up and running Zipkin and rabbit mq is something we will touch upon later but for now let's get started with pogress SQL hey there welcome back so we now have postgress SQL running in kubernetes now what we need to do is we need to log to postgress and we need to create the databases so remember our microservices

    
    09:37:04
    need three databases job company and review so we need to set that up so what I'm going to do is I have everything up and running you can see over here I have the Pod the service and the state full set up now what I can do is I will say clear I'll say Cube CTL and I'll run this command I'll say hyphen it for hyphen zero and I'll say hyphen two times psql underscore u membar x so let me explain what this command means so here this command is used to log to the terminal of pogress SQL so we are saying

    
    09:37:52
    Cube CTL execute exec and this is a command that is used to execute a command in a already running container within kubernetes cluster all right then we are seeing it so these two flags I and T stands for interactive and T stands for TTY which is which stands for terminal so together they allow you to interact with command you are running inside the container as you were connected to the terminal session in that container all right then we are saying pogress hyphen Zer and this is the name of the specific pod

    
    09:38:34
    that the command will be executed in then we have hyphen two times and this symbol signifies the end of the command line options for cube CTL excc so this was the command line option for cube CTL excc and we specify that it's end of the command line options and the beginning of the command you want to run inside the container so now inside the container we are running this command so we are saying psql hyphen u membar x so so this command gets run inside the container psql is the command line client for

    
    09:39:14
    interacting with the POs SQL database and hyphen u membar x part specifies that you want to connect to user membar X so let us press enter and let us see what's happening okay so it says posg hyphen Zer does not have a host assigned so I'm getting this issue now what I'm going to do is I don't know why this issue is coming in so I will be restarting mini Cube this could be one of issue with mini Cube so I'll say mini Cube stop and uh this will power off mini Cube and I'll say mini Cube start so I'll say

    
    09:39:57
    mini Cube start over here okay so it will restart mini Cube for us and then I'm going to like redeploy or rerun pause SQL and then I'm going to try this command again so the restart is complete you can see the logs over here now what I'm going to do is I will I will apply so let me say apply Services pause Chris and you will see everything is created now okay and now I will let's say I'll execute the same command here and now you will see that we are logged in to the terminal of our container all right

    
    09:40:37
    now we need to start running some commands here and we need to get our databases up and running so what we can do is we need to first check the list of databases so I'll say hyphen and I'll say l now here you will see these are nothing but the databases over here so you can say backwards slash l or backwards sln list so if you say so here you have more list okay and you end over here okay okay so the command is done and you can see we got four records here so either you run hyphen L sorry not hyphen or backwards SL l or you can say

    
    09:41:19
    list over here okay and you will see the same thing so you have this database or you can see like you have this database created here Embark X which exists already okay so I'm just going to press enter and we will exit this okay so I said contrl c on Windows and then I pressed enter for the output to exit okay or you can press command C if you are on Mac all right now what I'm going to do is I'm going to create the database so I'm going to say create database chop and I'll end it end this with semicolon then I'll create a database

    
    09:42:01
    called review it will create the database and then I'll create a database called company and it will create the database now if I run list you will see we have all the databases up and running okay you can see there are seven rows now so we have company job pois and review so company job and review is what we will be using so now to exit this I'll say control C and I'll press enter okay so we have now successfully created the databases within the container and now we need to exit this shell okay we don't need to stay in this

    
    09:42:45
    shell now because we have database that we have created so I can say control D on Windows to quit the shell and if you're on Mac you can see command D all right so this will quit the shell and you are back to the normal Power shell so if I say PWD you will see that I am in my normal directory now so that's about posis SQL and how you can set it up within the containers hey there welcome back so let us start talking about API Gateway and urea server when it comes to kubernetes So In traditional microservices architecture tools like

    
    09:43:32
    API Gateway and urea server are often used to manage and discover services Now by urea server it's a service registry from Netflix suit of tools now when transitioning to kubernetes many of these functionalities are either built into the platform or can be managed through other tools that that are designed to work natively with kubernetes so let us talk about each one of them so a simple answer to this question like do we need API Gateway and jurea server in kubernetes the answer would be no and I'll explain you why so

    
    09:44:10
    let us talk about API Gateway so for API Gateway there are multiple ways like uh kubernetes Ingress controllers so kubernetes provides Ingress controllers to manage externals access to services within the cluster and these controllers can handle load balancing SSL termination and path-based routing so this reduces the need for API Gateway in instead of this service mesh can also be used for even more advanced traffic routing options and even for tolerance and security okay so this negates the need for traditional

    
    09:44:49
    API Gateway in the kubernetes environment and then talking about urea Discovery server so service Discovery is also managed internally in kubernetes so when a service is created it is automatically discoverable by other services within the cluster using its service name so this is taken care by kubernetes itself so this negates the use of an external API Gateway or service Discovery for our architecture but we will be having this on our local environments so like we have different properties file so what we can do is we

    
    09:45:31
    can have API Gateway and service registry for our local environments and docker but for kubernetes we can negate this and we can do without these Services okay so to summarize the core functionalities provided by API Gateway or service Discovery tool like urea either built into kubernetes or can be supplemented with kubernetes Native tools and therefore it's possible to use these tools within kubernetes environment but they might add unnecessary complexity since kubernetes itself provides mechanisms like routing

    
    09:46:10
    load load balancing service Discovery and so on and these are sufficient for most of the use cases and this negates the need for tools like API Gateway and urea server so basically we can get rid of these services in kubernetes environment hey there welcome back so let us start with the job microservices and we will begin setting up the application properties for the kubernetes environment for our project so here as you can see I have a sample application. properties file and this is something that I have written for

    
    09:46:56
    kubernetes so we'll move this file to our project and we will discuss the changes so I'll copy this entirely and I'll head over to my project here now here under SRC I'll go to main resources and here I'll duplicate this particular file so let me see whether we have a duplicate option okay so we don't have a duplicate option so I would rather go ahead and create a new one okay so I'll say new file and I'll say application hyphen k8s and I'll say properties like so and I'll paste the contents that I have copied okay so this

    
    09:47:47
    file is now created in the jobs microservice now let us go through like everything that we have done in this particular file so this particular file is the configuration for the micros service that is to be deployed in the kubernetes cluster and this file has various settings related to service Discovery data sources and so on okay so here to begin with we have the list of service URLs and these are the services that our job service will interact with and in kubernetes you will notice that we have

    
    09:48:24
    directly used the service name okay so you can simply use the service name over here as the host name here we have specified the port we have H2 database which is disabled here we also have urea this that is disabled so here I have made a few changes as you can see so I have disabled the urea service URL and I have specified the application name as job service and also here I have said register with urea false fetch registry false so if you go to the docker file your application. properties for Docker

    
    09:49:05
    you will see here I I have the service URL for urea and I'm registering with urea and fetching the registry as well but here I have disabled both of them then I have the logging level which is set to debug which is fine and then I have the config server that has been disabled so we don't even need to use an centralized config server so in kubernetes setup you can make use of config map or secret objects instead so I've dis this then you have the resilience 4G configuration and these are for setting up circuit breaker

    
    09:49:44
    patterns and other resilience patterns for our service all right and circuit breakers like we know prevent failures from cascading in distributed systems okay and these configurations will control how circuit breakers behave like how many failure it takes before opening the circuit and so on so these are all the configurations for that then I have the Zipkin configuration and the actuator configuration so for actuator I am exposing all the endpoints and for Zipkin I am sending the trace data to

    
    09:50:22
    this particular endpoint over here okay and then I have the pogress SQL configuration over here so I'm pointing to this database and uh I have all the details like username password and so on so this is the configuration file for kubernetes for job services all right so we have we will save this file and we will go ahead with the next step hey there welcome back so now is the time to set up the deployment and service for our job micros service so what we are going to do is we are are going to copy this entire file so this

    
    09:51:10
    is a notepad that I have written so I'll copy this entire thing okay so this notepad has the definition so it has the definition for the deployment file as to what it's supposed to contain and it also has the definition for the service file as to what it's supposed to contain so now what I will be doing is I'm going to copy this entire thing like the entire file okay so these two definitions will be copied and I'll head over to visual studio code now here you will see three folders bootstrap and services are the

    
    09:51:48
    main folders that will be running our application so here under bootstrap I'll go to job and I'll say create a new file okay and here I'm going to define the deployment file and the service file for the job micros service so I'm going to SA say job hyen deployment. yaml like so and I'll paste the entire file that I had created okay so this has service file as well so I'll just clean this up but before that I'll say job hyphen service. yaml something like this so we have deployment and service created now

    
    09:52:34
    what I will do is I'll cut these service part over here and I'll move this to the service. AML and here in deployment I'll just get rid of this until over here and I'll scroll up and I'll even get rid of this title here okay so we have everything set up now let us save these two files so don't forget to save and let us talk about what we are doing in this particular file so deployment file has the config configuration for deployment so we are defining the API version the kind of kubernetes object

    
    09:53:14
    and the name and the labels okay so this contains the information of the deployment itself like the name and the label then we have the specs and specs has the number of replicas so we are keeping the number of replicas to that of one we have the template defined over here now template defines the blueprint for the CS that will be created by this deployment okay and here under template you have a spec field or a spec label which defines the specifications for the containers that will run inside this p

    
    09:53:53
    over here okay so the specification says we have one container and its name is job and we have this particular image that we are pulling in image pull policy is always and it means that it will always pull the image from the registry even if it already exists locally so you can change this if you wish to and you have the ports set to 8082 and then you have the environment so this defines the environmental variables inside the container and here since we are saying spring profiles active and we are setting it to

    
    09:54:35
    k8s which means we'll be enabling a particular configuration like this particular configuration when the application runs and then you have restart policy as always so if the container crashes kubernetes will restart it and then in the end we have selector and this defines how deployment finds with which port to manage and here it's matching the Pod with label app colon chop so this is a definition for the deployment file now let us talk about the service file or the service configuration so here like always we

    
    09:55:16
    have API version kind and metadata set okay so metadata contains the metadata regarding the service here because this is a service object and it has the name here then we have the specifications defined so here we are specifying the selector and ports now selector is how the service finds which ports to send traffic to and here it matches the ports with label app colon job okay and then here you have ports defined so this defines the port that service exposes so the port on which the service will be

    
    09:55:56
    exposed in this case is 80 and the Target Port on the ports to which the service will be sent here it corresponds to that of 8882 so this is the service definition that we have so deployment and the service are the two configurations that we need to set up under job folder within k8s folder that we have and these two will Define the kubernetes configuration for job microservice welcome back so let us now start talking about the properties file for the company micros service so I've already created the properties file and

    
    09:56:41
    I've defined it here so what I'm going to do is I'm going to copy this entire file and I'm going to move to intellig and here I'm going to head over to company micros service SRC Main and under resources I'm going to create a new file over here so this is going to be the application k8s properties file so I'm going to say application hyphen k8s do properties and I'm going to paste the entire file all right so this is the configuration that we are setting for the company microservice to run in kubernetes now let us understand what

    
    09:57:25
    everything means and what are the changes that we have done in this particular file here so we begin with the definition for service URLs okay and these are the URLs that are application will interact with so we have defined URL for all three services and in kubernetes you can make use of container names as host names so that is what we are using we have specified the port number over here for the company microservice we have disabled the H2 database and here you can see I have disabled urea so here I had the URL specified for

    
    09:58:06
    connecting to urea client but this is something that I have removed and I have mentioned explicitly over here that I want to disable the urea client and even register with urea and fetch registry is set to false over here the service name is set to company now if you scroll down you will have rabbit andq configuration over here here you have the actuator configuration so here I'm exposing all the end points of actuator and then you have the Zipkin configuration so we are specifying the end point where we will be sending the

    
    09:58:46
    tracing data to and we are mentioning the probability like the sampling probability or the sampling rate to 1.0 and then over here I have the settings for postris SQL so I've defined all of this and this is a separate configuration which will be used for kubernetes deployment okay and it has all the configurations that is relevant for kubernetes so we don't have urea server we have disabled urea server company micros service didn't have config server configured otherwise we would have got rid of that as well but

    
    09:59:25
    these are the changes that we have done so far in company microservice hey there welcome back so now let us set up the deployment and service configurations for company service so here you can see I have a notepad where I have defined the deployment as well as the service configurations for company so what I'm going to do is I'm going to copy this entire thing I'll head over to visual studio code and under bootstrap folder I will expand the company folder so right now I don't have anything within company

    
    10:00:08
    folder so I'm going to add a new file over here and I'm going to call this particular file as company and I'll say deployment and I'll add the yaml file here then I'll add the company and service so I'll say company I service. yaml now I'll paste everything into deployment file and then I'll copy or cut the service part to company service over here okay and then within deployment file I'll just get rid of this end part here I'll just delete this and if I scroll up here I'll get rid of this as well and I'll save both the files so

    
    10:00:58
    don't forget to save here so I have deployment configuration and the service configuration set for company now let us go through and understand what each thing means over here so here in deployment file we begin with the specification like API version the kind of object we are creating and the metadata about the object now here in metadata we are specifying the name of the deployment and labels to identify this deployment then we have specs that we have defined here and under specs we have things like replicas template and

    
    10:01:39
    spec again okay and then we have selector two so under replicas we are mentioning how many replicas of a particular pod we want to be running so we keep this to one template template defines the pods specification so here we are saying the name is company and this is the name of the p and the label we have is appolon company and this is to identify the Pod now if you scroll down here we have the specifications and we are specifying the containers over here so this is the list of containers that will run within the

    
    10:02:20
    Pod and we are specified the container name as company which has this particular image and it runs on this particular Port over here so these are the ports that are exposed from the container so we are exposing 808 one and then we are specifying the environment property over here or environment variable of the container and the value we are passing in is key 8s because the properties file that we have created is hyphen k8s and then we have the restart policy over here so restart policy says always

    
    10:02:59
    which means if the container stops it will always be restarted and and then we have selector defined over here and this selects the Pod with label app colon company ensuring the correct ports are targeted by this deployment so this is the definition for deployment file and then we have service file wherein we have the specification like API version kind of the object and metadata defined at the top and then we have the selector defined over here and this select the Pod with the label app colon company and then we have the port

    
    10:03:41
    specified over here so ports mentions the list of the ports that we wish to expose so we're exposing Port 80 to the external clients and Target Port 881 means the port on the container to which the traffic will be routed okay so this is where our application will actually be running so you can see over here it's running on 881 so service is listening on 880 and it will route the traffic to the 881 Port of the container so we have specified the type as load balancers and this will allow external access to the

    
    10:04:22
    pods okay so this is how we have mentioned the service and the deployment configurations for company object or for the company microservice hey there welcome back so now it's time to set up the application properties for our review service and I have already defined the configuration file over here in the notepad and I'm going to copy this and move this file into our review microservice so I'll head over to SRC main resources and I'll create a new application. properties file over here so I'll say

    
    10:05:08
    application hyphen k8s so this is the application. properties file for kubernetes so we'll specify that over here and then I'll paste in whatever I have copied now let us go through this file so we begin by defining these service URLs okay and these are the URLs wherein we are trying to access the containers with the help of the service names and with kubernetes it is okay to use container names as host names then we have the server P defined for the review microservice over here I have the application name here we

    
    10:05:49
    are setting debug level to debug over here and we have disabled the urea server over here so I'm saying register with urea false and fetch registry also false and I'm disabling this URL over here the service URL for urea then here I have the rabbit mq settings wherein I'm adding some resiliency and I'm configuring the rabbit mq server then here I'm defining the actuator configuration wherein I'm exposing all the actuator end points and then I have the Zipkin configuration defined here now Zipkin

    
    10:06:34
    configuration defines two things we have the end point for Zipkin and the sampling probability which is set to 1.0 and then in the end I have the settings for postgress SQL database and here I'm specifying everything like the container okay how to access the container or pogress instance and then I have username password along with the database specification over here so I specified everything over here okay and you can see this is the database name in the end so this is a file that will be used to work in kubernetes environment

    
    10:07:16
    all right and this is what we have configured with our project hey there welcome back so let us set up the configuration for review service and we are going to define the kubernetes configuration for this particular service so here I have a notepad file created and I have two things in this file one is the deployment configuration and here I have the service configuration okay so what I'm going to do is I'm going to move both these things to visual studio code and I'm going to head over to bootstrap review

    
    10:07:58
    and I'm going to create a new file I'm going to say review hyphen deployment and and I'm going to create this as yaml file and I'm going to create one more file I'm going to say review hyphen service like so now under deployment I'll paste whatever I have copied and I'll cut the last part of the file and I'll move it to service here okay and I'll save this file now I'll do some Cleanup in the deployment file so I'll just remove this from here and then I'll scroll up and I'll remove the deployment heading at

    
    10:08:40
    the top and I'll hit save so we have two files added one is for deployment and another one is for service so you can see over here it begins with the general information like the API version the kind of the object that we are creating so deployment in our case and then we have metadata specified and this is the metadata about the object like the name and the label then we have spec defined and spec contains the specification for deployment so we have the replicas configured here so we want only one

    
    10:09:19
    replica for this particular deployment template we have the template definition for this particular pod and then we have the container definition for this particular pod and here you can see we are pulling in our image this is the container name we have the image pull policy and we are also specifying the environment as to how we are supposed to run this micros service and here in the end we are adding a match label then in the review service I'm creating a service object wherein I've have specified some information as to

    
    10:09:59
    the API version the kind of the object and the metadata which defines the name of it it service then I have the specification of the service so I say selector is app colon review and this specifies which pod the service should direct traffic to based on the labels and in this case those with label app coolon review is where the service directs the traffic so here you can see we have defined the label here and then we have the port information so here we have mentioned the protocol and 80 is the port that

    
    10:10:39
    service listens on and the Target Port is 8083 where the traffic is forwarded to and this should match the servers port in our case Okay so this is the thing that we have specified for review so here one small change I'll do so here we are forwarding to 8083 so here I'll add container Port as 8083 because that is where the traffic is being forwarded to and I'll hit save so this is the configuration that we have defined for our review service to be deployed and running on kubernetes cluster hey there welcome back so let us

    
    10:11:26
    now talk about the deployment of our micro services so we have done quite a few changes to our microservices so we have microservices like job company and review that have undergone changes and now it's time that we should deploy these changes onto talker okay so we don't need to get the other things like Gateway config server service reg and so on but we need company microservice job microservice and the review microservice and we need to create new Docker images for these and we need to push them to Docker Hub so let us let's

    
    10:12:05
    head over to our terminal and let us get this rolling so here I have some Docker commands already written we will be making use of Maven wrapper as you can see over here and I will be heading over to the terminal to execute this commands so I'm here in this directory spring boot where my project exists now if I say LS you will see this project over here or not project this folder over here k8s okay and what I will be doing is I will be switching over to company microservice so I'll say CD I'll say

    
    10:12:44
    company micros service over here like so okay now we need to run the command which will create the image for this particular service so I'll copy this and I'll paste it over here so just be sure that you are in company microservice project and you are running this command okay and I'll press enter now this will take some time depending on your system and the internet and this will create the docker image for me also one thing to be sure over here is just make sure you have Pais SQL and everything up and

    
    10:13:21
    running on your system so I don't have that running right now and that is why it failed and I got this error so what you can do is you can go to company microservice only so here in company microservice we have talker compose yaml so I'll say talker compose up and I'll enable this in the detached mode okay so this is going to create a few services like job company review and so on and uh along with this what we need is posis and PG admin Zipkin and so on so this error that we got will go away okay so you can see

    
    10:14:00
    over here it is unable to open the database connection and that is because the database is down okay so let us now try running this command again so I'll run I'll first okay I'll run this command since I'm in the same directory right now and let us see whether it works this time so after doing Docker compose up you can see that the image creation is in process and we don't see any errors okay so clearly it was because the docker compose was down so when running the command we made sure that Docker composes up now why did we

    
    10:14:37
    do that so we did that because here we are running or we are creating the docker image but we are not specifying the profile over here so this is still using the default profile which points to the docker container and the local instance of posg SQL okay so we need to make sure that we have the posg SQL and all the other services up and running so that the image at least is created okay now once this is done I will simply say Docker push space and I'll simply copy this and I'll paste this okay so when we

    
    10:15:14
    create an image with this particular command it is still pointing to the local instance and not the actual kubernetes instance which we have deployed okay so the procress SQL in kubernetes is still running but this is not pointing to that so you can see over here push was successfully done and we have the image being pushed to the remote server and now I'll switch the directories so I'll switch to job microservice okay I'll go over here and I'll copy the command for job microservice and I'll paste

    
    10:15:52
    it and this will take a little bit of time again depending on your system so the image creation for job micros service is also done now I'll get it quickly pushed to dockerhub so I'll say talker push and I'll paste this over here so this will again begin the process and our image will be pushed okay now after this process I need to switch my directory to review microservice so I'll head over to review microservice here and then I'll copy the command that we have for review microservice and this will create a

    
    10:16:29
    Docker image for review again so the image creation has succeeded now now I'll say Docker push and I'll copy the image name over here and I'll paste it so it will create the image or it will push the image that is created okay so you can see it is proceeding and the pushing is done now let us head over to dockerhub and here as you can see on the dashboard I'm logged in already and here if you hit refresh you're going to see all the images that you had pushed appear over here so you have review microservice job

    
    10:17:11
    microservice and company microservice as well so these are the latest images which has the code that point to kubernetes instance okay and we need these changes to be up on Docker Hub all right so now we are done pushing the changes and now it's time to go to the next step so now it's time that we understand how we can enable and access the services with the help of mini Cube so here in the terminal I'm going to say mini Cube service and I'll say Zipkin so let us try accessing Zipkin now the thing is

    
    10:17:57
    Zipkin is a service that is running in kubernetes okay and mini Cube allows us to access that particular service so you cannot directly access the services running in a kubernetes cluster you need to run this command and get the service URL so the moment I see this and if I press enter you will see mini Cube responds with this particular URL and it says because I'm using a Docker driver on Windows the terminal needs to be open to run it which is fine so what it's telling is I need the terminal engaged

    
    10:18:36
    open over here if I close this terminal or if I press contrl C then the service will stop running on this or I won't be able to access the URL over here service won't stop but I won't be able to access the URL so this accessibility will be cancelled so I'll copy this URL okay and I'll head over to my browser here and I'll paste this particular URL over here and the moment you paste you will be able to access Zipkin that is running right within the kubes cluster and this is possible because of mini Cube so mini cube with

    
    10:19:16
    the help of that command which we just executed it is allowing the access to this particular service within kubernetes cluster and it is accessible with the help of this URL okay now if I go over here and if I close this so if I say control C so it has stopped and I can run one more command over here and now if I try to access it won't work you see it's gone and now let us run this command again so I'll run this again and now you can see the URL is slightly different so the port is earlier it was 53 769 now it's 537 87 so

    
    10:20:00
    it changes and now if I paste so this won't work okay this is the old URL now if I paste this over here it will work and it's the same Zipkin dashboard which we had accessed earlier from the different URL so this is how you can get mini Cube to enable and access services so mini cube is indeed a really handy tool hey there welcome to this class so now it's time that we test the application onto the kubernetes cluster so the first step what we are going to do is we are going to deploy everything

    
    10:20:44
    to kubernetes okay so I have to make sure that I'm in the right directory so I am right now in review microservice so I'll just change this to the root directory and you will see that I have this folder here k8s okay so this is a folder where I have every micros service that is there in my architecture and we are going to make use of k8s now if I say Cube CTL get all you will see we have rabbit mq pogress Zipkin running in the kubernetes cluster okay now what we need to do is we need to deploy the job

    
    10:21:25
    microservice review microservice and the company microservice so I'm going to say Cube CTL apply and I'm going to say k8s and I'm going to say job first so ke it as bootstrap and then job okay and it is throwing an error it says Cube CTL hyphen H for help and examples okay so we missed the hyphen f flag like this flag that is what we missed over here so I'm just going to add the flag F and I'm going to save say enter and you can see deployment apps SL job is created and service SL job is created so two things are created now

    
    10:22:14
    after job I can say company and that will also be created and here I can say review and that will also be created so you can see how with the help of organizing things we have been able to deploy everything to kubernetes so we just had to change the folder and everything was deployed and it's pretty organized and now if you say Cube CTL get all you will see you have Job review and Company up and running okay so these are the apps apps slash so these are replica set and these are deployments service and then we have

    
    10:22:56
    pods as well okay so we have everything up and running you can see the status is running for everything now what we can do is we need to start testing our application so what we are going to do is we are going to start accessing our application one by one okay so I'm going to first get the URL for job now you cannot directly access the services because they actually running in kubernetes cluster and you need to get the URL first so I'm going to say mini Cube I'm going to say service job and I'll say hyphen URL so this is going

    
    10:23:39
    to give me the URL for job service so you can see over here it has given this particular URL here now I cannot close this terminal if I close this this URL won't be accessible okay so what I will do is I'll open another instance of the same terminal I'll zoom in a bit and I'll run the command again but this time for company so I have the company URL as well now I'll duplicate the terminal again and I'll get the URL for review over here so I'll say review like so so we have the URLs for three of our microservices and

    
    10:24:23
    we can now start accessing them so I'll copy the one for jobs over here now let us head over to postman so here in Postman I'll go to job micros service I can let's see if we can duplicate this all so I can duplicate this entire folder over here okay and here I can simply say k8s Okay instead of copy I can say k8s like so okay and here I can now start replacing the URL so this is URL and this will not be constant it will forever be changing so I'll now create the job first so let's say this is the URL and this is

    
    10:25:09
    the request body and let's say I create this so you can see job has been added successfully okay now if you switch over to your terminal okay let me open one more instance or one more window over here and let me run this command get all okay so with this you can get everything like all the pods like everything that is running like pod service deployment and replica sets okay now let's say I want to check the logs for chobs microservice so I can copy this and I can say Cube CTL logs and I can just paste the name

    
    10:25:52
    over here and you will see like here we have the logs and you can see the insert query was triggered over here because we just did a post request okay and this is within kubernetes okay and if you scroll up here you can see all the logs that have happened over here you can see the service was started and then you can see like different logs over here you can just go through and see what's happening over here okay so yeah so this is the this is how it's working right now and if we switch over here we can like add company as well so

    
    10:26:30
    what I will do is I will just duplicate this so instead of changing the working URLs I'll just duplicate I'll add k8s over here like so and from here I'll go to company and I'll copy this and I'll switch over here and here I'll add in the post request like so and I'll get a company created as well so I'll say company 1 and let me trigger again so Company 2 now if I trigger a get request over here and if I change this to the new URL and if I run this you see I have the logs or not the logs actually this is a response

    
    10:27:20
    from the company microservice so it's working in kubernetes cluster okay now if I try a get request over here so let me copy this URL here and let me paste it over here like so and let me say get so you will see you have the job as well as the company and the reviews as well so the services are able to communicate as well amongst themselves okay so it's indeed working perfectly fine we can also test with review so I'll just duplicate this particular folder here okay and I'll change this name to

    
    10:28:02
    k8s okay and let us get the URL for review I'll copy this and here I'll paste this okay and you can see this is the post request and the review was added successfully now if I try to get jobs you'll see we have review coming in so this is working perfectly fine all our microservices are toing good now what we can do is let us see everything in Zipkin so here in terminal I'm going to say service cuber mini Cube service and I'll generate the URL for zipin here so you can see this is the URL so I'll copy

    
    10:28:45
    this URL and I'll head over to the browser and I'll paste it over here so you can see I'm able to access Zipkin and if I say run query you will see all the like traces and all the requests that we have just executed Ed some time back so everything is working perfectly fine as you can see if I expand all you should be able to trace all the requests and see what's happening with every request right so it is working perfectly fine as well now here in the terminal what I can do is I can open a new terminal over here and

    
    10:29:24
    let us log in to the database and let us see the changes that we just did so to log to the database I have this command already cop CED like written over here so I'll copy this and I'll paste it and we are connecting to this particular user here okay so I'm here so the command was forward slash l or backward SL L I'm sorry it was backward SL L I just forgot the command and you can see over here we have the list of all the databases now what I can do is we can switch to the respective database and we

    
    10:30:01
    can see the tables from within the database okay now how do we switch to this database so you can say backward slash C and I let's go to job over here okay so you are now connected to job database as user Embark X okay now we need to run one more command over here to get the list of tables and this is the select query so I can just copy so this select query if we execute we'll get the list of all the tables within a particular database okay so I get an error and it says syntax error near list so let me

    
    10:30:43
    see what the error is okay I just run the query again and it seems to have worked fine now and you can see over here we have one table job now I can say select star I can say from job and I can press enter so you can see this is the job that we have ADD added over here okay so the data is being added to the database and I can switch to a different database I can say backward slash C company okay so we are now in company now let us run the same query wherein we are querying information schema. tables

    
    10:31:24
    and we are getting the list of all the tables so here we have the single table and if I run select star on this table you will see two companies appear because we had added two companies so you can see over here two companies have been added okay now we can even switch to review over here okay so we can go to review and we can run this query you will have a review table and then you can say select star from review like so and you will have review appear over here okay so this way you can check the changes as well within the

    
    10:32:07
    database so indeed everything is working perfectly fine and the requests are being accessible from postmen and we are seeing the changes propagate to the database so our application is working on kubernetes cluster so that's about this class and I shall see you all soon thank you

    
